"""
User Task Scheduler - ç”¨æˆ·å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨

åŸºäº APScheduler çš„äº‹ä»¶é©±åŠ¨è°ƒåº¦ï¼ˆæ›¿ä»£è½®è¯¢æ¨¡å¼ï¼‰ã€‚

èŒè´£ï¼š
- å¯åŠ¨æ—¶ä»æ•°æ®åº“åŠ è½½æ´»è·ƒä»»åŠ¡ï¼Œæ³¨å†Œåˆ° APScheduler
- åŠ¨æ€æ·»åŠ /ç§»é™¤ä»»åŠ¡ï¼ˆåˆ›å»ºã€å–æ¶ˆæ—¶å®æ—¶ç”Ÿæ•ˆï¼‰
- æ‰§è¡Œä»»åŠ¡åŠ¨ä½œï¼ˆå‘é€æ¶ˆæ¯ã€æ‰§è¡Œ Agent ä»»åŠ¡ç­‰ï¼‰
- æ‰§è¡Œåæ›´æ–°æ•°æ®åº“çŠ¶æ€ï¼Œè‡ªåŠ¨é‡æ–°è°ƒåº¦ cron/interval ä»»åŠ¡

ä¸ç³»ç»Ÿçº§ TaskScheduler çš„åŒºåˆ«ï¼š
- TaskScheduler: ç³»ç»Ÿçº§åå°ä»»åŠ¡ï¼ˆå¦‚ Mem0 æ‰¹é‡æ›´æ–°ï¼‰ï¼Œé…ç½®æ¥è‡ª YAML
- UserTaskScheduler: ç”¨æˆ·é€šè¿‡ AI åˆ›å»ºçš„å®šæ—¶ä»»åŠ¡ï¼Œæ•°æ®æ¥è‡ª SQLite
"""

import asyncio
from datetime import datetime
from typing import Any, Dict, List, Optional

from logger import get_logger

logger = get_logger(__name__)


class UserTaskScheduler:
    """
    ç”¨æˆ·å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨ï¼ˆAPScheduler äº‹ä»¶é©±åŠ¨ï¼‰

    æ¯ä¸ªç”¨æˆ·ä»»åŠ¡æ³¨å†Œä¸ºä¸€ä¸ªç‹¬ç«‹çš„ APScheduler Jobï¼Œ
    åˆ° next_run_at æ—¶åˆ»ç²¾å‡†è§¦å‘ï¼Œæ— éœ€è½®è¯¢ã€‚

    Agent task execution is offloaded via asyncio.create_task with a
    timeout guard, so long-running LLM loops do not starve Telegram
    long-polling or Feishu WebSocket heartbeats on the main event loop.

    ä½¿ç”¨æ–¹å¼:
        scheduler = UserTaskScheduler()
        await scheduler.start()
        # ... åº”ç”¨è¿è¡Œ ...
        await scheduler.shutdown()
    """

    # Maximum time a single agent_task execution is allowed (seconds)
    AGENT_TASK_TIMEOUT = 300  # 5 minutes

    def __init__(self):
        self._running = False
        self._scheduler = None
        self._workspace = None
        self._running_tasks: Dict[str, asyncio.Task] = {}  # task_id â†’ asyncio.Task

    async def start(self):
        """å¯åŠ¨è°ƒåº¦å™¨ï¼šåˆ›å»º APScheduler å®ä¾‹å¹¶åŠ è½½æ´»è·ƒä»»åŠ¡"""
        if self._running:
            logger.warning("ç”¨æˆ·ä»»åŠ¡è°ƒåº¦å™¨å·²åœ¨è¿è¡Œ")
            return

        try:
            from apscheduler.schedulers.asyncio import AsyncIOScheduler
        except ImportError:
            logger.warning(
                "APScheduler æœªå®‰è£…ï¼Œç”¨æˆ·ä»»åŠ¡è°ƒåº¦ä¸å¯ç”¨ã€‚"
                "å®‰è£…: pip install apscheduler"
            )
            return

        # è·å– Workspaceï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–å½“å‰å®ä¾‹åï¼‰
        import os
        from infra.local_store import get_workspace

        instance_name = os.getenv("AGENT_INSTANCE", "default")
        self._workspace = await get_workspace(instance_name)

        # åˆ›å»ºå¹¶å¯åŠ¨è°ƒåº¦å™¨
        self._scheduler = AsyncIOScheduler()

        # æ·»åŠ é”™è¯¯ç›‘å¬å™¨ï¼šæ•è· job æ‰§è¡Œå¼‚å¸¸å’Œ missed job
        from apscheduler.events import (
            EVENT_JOB_ERROR,
            EVENT_JOB_EXECUTED,
            EVENT_JOB_MISSED,
        )

        self._scheduler.add_listener(self._on_job_event, EVENT_JOB_EXECUTED | EVENT_JOB_ERROR | EVENT_JOB_MISSED)

        self._scheduler.start()
        self._running = True

        # ä»æ•°æ®åº“åŠ è½½æ´»è·ƒä»»åŠ¡
        loaded = await self._load_active_tasks()
        logger.info(f"âœ… ç”¨æˆ·ä»»åŠ¡è°ƒåº¦å™¨å·²å¯åŠ¨ï¼ˆ{loaded} ä¸ªæ´»è·ƒä»»åŠ¡, instance={instance_name}ï¼‰")

    def _on_job_event(self, event):
        """APScheduler job äº‹ä»¶ç›‘å¬å™¨"""
        from apscheduler.events import EVENT_JOB_ERROR, EVENT_JOB_MISSED

        if event.code == EVENT_JOB_ERROR:
            # event.traceback æ˜¯æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²ï¼Œä¸èƒ½ç›´æ¥ä¼ ç»™ exc_info
            tb_str = event.traceback if hasattr(event, 'traceback') else ''
            logger.error(
                f"âŒ [Scheduler] Job æ‰§è¡Œå¼‚å¸¸: job_id={event.job_id}, "
                f"error={event.exception}\n{tb_str}"
            )
        elif event.code == EVENT_JOB_MISSED:
            logger.warning(
                f"âš ï¸ [Scheduler] Job è¢«è·³è¿‡ï¼ˆé”™è¿‡æ‰§è¡Œæ—¶é—´ï¼‰: "
                f"job_id={event.job_id}, scheduled_run_time={event.scheduled_run_time}"
            )
        else:
            logger.info(f"âœ… [Scheduler] Job æ‰§è¡Œå®Œæˆ: job_id={event.job_id}")

    async def shutdown(self):
        """å…³é—­è°ƒåº¦å™¨"""
        if not self._running:
            return

        # Cancel any in-flight agent task executions
        for tid, t in list(self._running_tasks.items()):
            if not t.done():
                t.cancel()
                logger.info(f"ğŸ›‘ [Scheduler] å–æ¶ˆè¿è¡Œä¸­çš„ä»»åŠ¡: task_id={tid}")
        self._running_tasks.clear()

        if self._scheduler:
            self._scheduler.shutdown(wait=False)
            self._scheduler = None

        self._running = False
        logger.info("ç”¨æˆ·ä»»åŠ¡è°ƒåº¦å™¨å·²å…³é—­")

    def is_running(self) -> bool:
        """è°ƒåº¦å™¨æ˜¯å¦åœ¨è¿è¡Œ"""
        return self._running

    # ==================== ä»»åŠ¡æ³¨å†Œ ====================

    async def _load_active_tasks(self) -> int:
        """å¯åŠ¨æ—¶ä»æ•°æ®åº“åŠ è½½æ‰€æœ‰æ´»è·ƒä»»åŠ¡å¹¶æ³¨å†Œåˆ° APScheduler"""
        if not self._workspace or not self._workspace.is_running:
            return 0

        try:
            from sqlalchemy import select

            from infra.local_store.models import LocalScheduledTask

            assert self._workspace._session_factory is not None, "Workspace not started"
            async with self._workspace._session_factory() as session:
                result = await session.execute(
                    select(LocalScheduledTask).where(
                        LocalScheduledTask.status == "active",
                        LocalScheduledTask.next_run_at.isnot(None),
                    )
                )
                active_tasks = list(result.scalars().all())

                # Deduplicate by (title, trigger_type, next_run_at) â€”
                # prevents the same logical task from firing twice.
                seen = set()
                count = 0
                for task in active_tasks:
                    dedup_key = (
                        task.title or "",
                        task.trigger_type or "",
                        str(task.next_run_at or ""),
                    )
                    if dedup_key in seen:
                        logger.warning(
                            f"âš ï¸ [Scheduler] è·³è¿‡é‡å¤ä»»åŠ¡: id={task.id}, "
                            f"title={task.title}, trigger={task.trigger_type}"
                        )
                        continue
                    seen.add(dedup_key)
                    if self._register_job(task):
                        count += 1

                return count

        except Exception as e:
            logger.error(f"åŠ è½½æ´»è·ƒä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
            return 0

    def _register_job(self, task) -> bool:
        """
        å°†ä¸€ä¸ªä»»åŠ¡æ³¨å†Œåˆ° APScheduler

        ç­–ç•¥ï¼šç»Ÿä¸€ä½¿ç”¨ DateTrigger(next_run_at)ï¼Œåœ¨æ‰§è¡Œåç”±
        _execute_and_reschedule æ ¹æ® trigger_type é‡æ–°è°ƒåº¦ã€‚
        """
        if not self._scheduler:
            logger.warning(f"âš ï¸ [Scheduler] è°ƒåº¦å™¨æœªåˆå§‹åŒ–ï¼Œæ— æ³•æ³¨å†Œä»»åŠ¡: id={task.id}")
            return False

        if not self._scheduler.running:
            logger.warning(f"âš ï¸ [Scheduler] è°ƒåº¦å™¨æœªè¿è¡Œï¼Œæ— æ³•æ³¨å†Œä»»åŠ¡: id={task.id}")
            return False

        from apscheduler.triggers.date import DateTrigger

        job_id = f"user_task_{task.id}"

        try:
            # ç§»é™¤å·²æœ‰çš„åŒ ID Jobï¼ˆé¿å…é‡å¤ï¼‰
            existing = self._scheduler.get_job(job_id)
            if existing:
                self._scheduler.remove_job(job_id)
                logger.info(f"â™»ï¸ [Scheduler] ç§»é™¤æ—§ Job: {job_id}")

            # è®¡ç®—è§¦å‘æ—¶é—´
            now = datetime.now()
            run_at = task.next_run_at

            if not run_at:
                logger.warning(f"âš ï¸ [Scheduler] ä»»åŠ¡æ—  next_run_atï¼Œè·³è¿‡æ³¨å†Œ: id={task.id}")
                return False

            # å¤„ç† timezone-aware datetimeï¼šç»Ÿä¸€è½¬ä¸º naiveï¼ˆæœ¬åœ°æ—¶é—´ï¼‰
            if hasattr(run_at, 'tzinfo') and run_at.tzinfo is not None:
                run_at = run_at.replace(tzinfo=None)
                logger.info(
                    f"ğŸ”„ [Scheduler] æ—¶åŒºè½¬æ¢: åŸå§‹={task.next_run_at} â†’ naive={run_at}"
                )

            # å·²è¿‡æœŸçš„ä»»åŠ¡ç«‹å³æ‰§è¡Œï¼ˆå»¶è¿Ÿ 2 ç§’é¿å…è°ƒåº¦ç«äº‰ï¼‰
            if run_at <= now:
                from datetime import timedelta
                old_run_at = run_at
                run_at = now + timedelta(seconds=2)
                logger.info(
                    f"â© [Scheduler] ä»»åŠ¡å·²è¿‡æœŸï¼Œç«‹å³è°ƒåº¦: id={task.id}, "
                    f"åŸå®š={old_run_at:%H:%M:%S} â†’ æ”¹ä¸º={run_at:%H:%M:%S}"
                )

            self._scheduler.add_job(
                self._execute_and_reschedule,
                trigger=DateTrigger(run_date=run_at),
                args=[task.id],
                id=job_id,
                name=task.title or task.id,
                replace_existing=True,
            )

            # éªŒè¯æ³¨å†ŒæˆåŠŸ
            registered_job = self._scheduler.get_job(job_id)
            if registered_job:
                logger.info(
                    f"âœ… [Scheduler] ä»»åŠ¡å·²æ³¨å†Œåˆ° APScheduler: "
                    f"id={task.id}, title={task.title}, "
                    f"trigger={task.trigger_type}, "
                    f"fire_at={run_at:%Y-%m-%d %H:%M:%S}, "
                    f"job_id={job_id}"
                )
            else:
                logger.error(f"âŒ [Scheduler] æ³¨å†ŒåéªŒè¯å¤±è´¥ï¼ŒJob ä¸å­˜åœ¨: {job_id}")
                return False

            return True

        except Exception as e:
            logger.error(f"âŒ [Scheduler] æ³¨å†Œä»»åŠ¡å¤±è´¥: id={task.id}, error={e}", exc_info=True)
            return False

    async def register_task(self, task) -> bool:
        """
        åŠ¨æ€æ³¨å†Œæ–°ä»»åŠ¡ï¼ˆä¼ å…¥ ORM å¯¹è±¡ï¼‰

        åœ¨ scheduled_task_tool åˆ›å»ºä»»åŠ¡åè°ƒç”¨ï¼Œ
        ä½¿æ–°ä»»åŠ¡ç«‹å³åŠ å…¥è°ƒåº¦ï¼ˆæ— éœ€ç­‰å¾…è½®è¯¢ï¼‰ã€‚
        """
        if not self._running:
            logger.warning(
                f"âš ï¸ [Scheduler] è°ƒåº¦å™¨æœªè¿è¡Œï¼Œæ— æ³•æ³¨å†Œä»»åŠ¡: "
                f"id={task.id}, title={task.title}"
            )
            return False

        result = self._register_job(task)
        if result:
            self._log_scheduler_status()
        return result

    async def register_task_by_id(self, task_id: str) -> bool:
        """
        é€šè¿‡ task_id ä»æ•°æ®åº“è¯»å–ä»»åŠ¡å¹¶æ³¨å†Œåˆ°è°ƒåº¦å™¨ã€‚

        åŒ…å«é‡è¯•æœºåˆ¶ï¼Œåº”å¯¹ SQLite WAL å¯è§æ€§å»¶è¿Ÿï¼š
        pool_size=1 + aiosqlite çº¿ç¨‹å±‚å¯èƒ½å¯¼è‡´åˆšæäº¤çš„æ•°æ®
        åœ¨æçŸ­æ—¶é—´çª—å£å†…å¯¹æ–° session ä¸å¯è§ã€‚

        æ¨èï¼šå¦‚æœè°ƒç”¨æ–¹å·²æŒæœ‰ ORM å¯¹è±¡ï¼Œä¼˜å…ˆä½¿ç”¨ register_task(orm_obj)
        é¿å…é‡æ–°æŸ¥è¯¢ã€‚
        """
        if not self._running:
            logger.warning(
                f"âš ï¸ [Scheduler] è°ƒåº¦å™¨æœªè¿è¡Œï¼Œæ— æ³•æ³¨å†Œä»»åŠ¡: id={task_id}"
            )
            return False

        if not self._workspace or not self._workspace.is_running:
            logger.error(
                f"âŒ [Scheduler] Workspace ä¸å¯ç”¨: task_id={task_id}"
            )
            return False

        from infra.local_store.crud.scheduled_task import get_scheduled_task

        assert self._workspace._session_factory is not None

        # Retry with exponential backoff for WAL visibility delay
        max_retries = 3
        retry_delay = 0.5  # seconds

        for attempt in range(1, max_retries + 1):
            async with self._workspace._session_factory() as session:
                task = await get_scheduled_task(session, task_id)
                if task:
                    result = self._register_job(task)
                    if result:
                        self._log_scheduler_status()
                    return result

            if attempt < max_retries:
                logger.warning(
                    f"âš ï¸ [Scheduler] register_task_by_id ä»»åŠ¡æœªæ‰¾åˆ°ï¼Œ"
                    f"é‡è¯• {attempt}/{max_retries}: task_id={task_id}, "
                    f"ç­‰å¾… {retry_delay}sï¼ˆWAL å¯è§æ€§å»¶è¿Ÿï¼‰"
                )
                await asyncio.sleep(retry_delay)
                retry_delay *= 2  # exponential backoff

        logger.error(
            f"âŒ [Scheduler] register_task_by_id åœ¨ {max_retries} æ¬¡é‡è¯•å"
            f"ä»æŸ¥ä¸åˆ°ä»»åŠ¡: task_id={task_id}"
        )
        return False

    async def unregister_task(self, task_id: str) -> bool:
        """
        ç§»é™¤ä»»åŠ¡

        åœ¨å–æ¶ˆ/åˆ é™¤ä»»åŠ¡æ—¶è°ƒç”¨ï¼Œç«‹å³åœæ­¢è°ƒåº¦ã€‚
        """
        if not self._scheduler:
            return False

        job_id = f"user_task_{task_id}"
        try:
            if self._scheduler.get_job(job_id):
                self._scheduler.remove_job(job_id)
                logger.info(f"ğŸ—‘ï¸ [Scheduler] å·²ç§»é™¤ä»»åŠ¡: id={task_id}")
            return True
        except Exception as e:
            logger.error(f"âŒ [Scheduler] ç§»é™¤ä»»åŠ¡å¤±è´¥: id={task_id}, error={e}", exc_info=True)
            return False

    def _log_scheduler_status(self):
        """Log current scheduler status for debugging."""
        if not self._scheduler:
            return
        jobs = self._scheduler.get_jobs()
        job_info = [f"{j.id}(next={j.next_run_time})" for j in jobs]
        logger.info(f"ğŸ“Š [Scheduler] å½“å‰ Jobs: {len(jobs)} ä¸ª â†’ {job_info}")

    # ==================== ä»»åŠ¡æ‰§è¡Œ ====================

    async def _execute_and_reschedule(self, task_id: str):
        """
        æ‰§è¡Œä»»åŠ¡ï¼Œç„¶åæ ¹æ® trigger_type å†³å®šæ˜¯å¦é‡æ–°è°ƒåº¦ã€‚

        å…³é”®è®¾è®¡ï¼š
        1. åˆ†æ®µå¼ session ç®¡ç†ï¼Œé¿å… SQLite pool_size=1 çš„è¿æ¥ç«äº‰
        2. Agent task æ‰§è¡Œé€šè¿‡ asyncio.create_task + wait_for éš”ç¦»ï¼Œ
           ä¸é˜»å¡ Telegram/Feishu é•¿è¿æ¥çš„å¿ƒè·³å’Œæ¶ˆæ¯æ¥æ”¶

        Phase 1: Session A: åŠ è½½ä»»åŠ¡æ•°æ® â†’ å…³é—­
        Phase 2: æ‰§è¡Œä»»åŠ¡ï¼ˆagent_task ä¼šè¢« offload åˆ°ç‹¬ç«‹ Taskï¼‰
        Phase 3: Session B: æ ‡è®°ä»»åŠ¡å®Œæˆ â†’ å…³é—­
        """
        logger.info(f"ğŸ”” [Scheduler] ä»»åŠ¡è§¦å‘: task_id={task_id}")

        if not self._workspace or not self._workspace.is_running:
            logger.error(
                f"âŒ [Scheduler] Workspace ä¸å¯ç”¨ï¼Œæ— æ³•æ‰§è¡Œä»»åŠ¡: "
                f"task_id={task_id}, workspace={self._workspace}, "
                f"is_running={self._workspace.is_running if self._workspace else 'N/A'}"
            )
            return

        from infra.local_store.crud.scheduled_task import (
            get_scheduled_task,
            mark_task_executed,
        )

        # ---- Phase 1: åŠ è½½ä»»åŠ¡ï¼ˆå¸¦é‡è¯•ï¼Œé˜²æ­¢ SQLite WAL å¯è§æ€§å»¶è¿Ÿï¼‰ ----
        assert self._workspace._session_factory is not None, "Workspace not started"

        max_retries = 3
        retry_delay = 1.0  # seconds
        task_snapshot = None

        for attempt in range(1, max_retries + 1):
            async with self._workspace._session_factory() as session:
                task = await get_scheduled_task(session, task_id)

                if task:
                    if task.status != "active":
                        logger.info(
                            f"â­ï¸ [Scheduler] ä»»åŠ¡éæ´»è·ƒçŠ¶æ€ï¼Œè·³è¿‡: "
                            f"task_id={task_id}, status={task.status}"
                        )
                        return

                    # æå–æ‰§è¡Œæ‰€éœ€æ•°æ®ï¼ˆåœ¨ session å†…å®Œæˆï¼Œé¿å… lazy-load é—®é¢˜ï¼‰
                    task_snapshot = {
                        "id": task.id,
                        "title": task.title,
                        "trigger_type": task.trigger_type,
                        "user_id": task.user_id,
                        "conversation_id": task.conversation_id,
                        "action": task.action,  # propertyï¼ŒJSON ååºåˆ—åŒ–
                    }
                    break
            # ---- session å·²é‡Šæ”¾ ----

            if attempt < max_retries:
                logger.warning(
                    f"âš ï¸ [Scheduler] ä»»åŠ¡æœªæ‰¾åˆ°ï¼Œé‡è¯• {attempt}/{max_retries}: "
                    f"task_id={task_id}, ç­‰å¾… {retry_delay}s"
                )
                await asyncio.sleep(retry_delay)
                retry_delay *= 2  # exponential backoff

        if not task_snapshot:
            logger.error(
                f"âŒ [Scheduler] ä»»åŠ¡åœ¨ {max_retries} æ¬¡é‡è¯•åä»æœªæ‰¾åˆ°: "
                f"task_id={task_id}, workspace_instance={self._workspace.instance_id}, "
                f"workspace_running={self._workspace.is_running}"
            )
            return

        # ---- Phase 2: æ‰§è¡Œä»»åŠ¡ ----
        # agent_task å¯èƒ½è·‘ 20+ è½® LLM è°ƒç”¨ï¼Œè€—æ—¶æ•°åˆ†é’Ÿã€‚
        # ç”¨ asyncio.create_task + wait_for éš”ç¦»æ‰§è¡Œï¼Œè®©ä¸»å¾ªç¯èƒ½
        # ç»§ç»­å¤„ç† Telegram é•¿è½®è¯¢å’Œé£ä¹¦ WebSocket å¿ƒè·³ã€‚
        execution_success = True
        execution_error = None
        response_text = None
        try:
            logger.info(
                f"ğŸš€ [Scheduler] å¼€å§‹æ‰§è¡Œä»»åŠ¡: id={task_snapshot['id']}, "
                f"title={task_snapshot['title']}, trigger={task_snapshot['trigger_type']}"
            )

            # Offload execution into a tracked Task with timeout
            exec_task = asyncio.create_task(
                self._execute_task(task_snapshot),
                name=f"scheduled_task_{task_id}",
            )
            self._running_tasks[task_id] = exec_task
            try:
                response_text = await asyncio.wait_for(
                    exec_task, timeout=self.AGENT_TASK_TIMEOUT
                )
            except asyncio.TimeoutError:
                exec_task.cancel()
                raise TimeoutError(
                    f"Agent task exceeded {self.AGENT_TASK_TIMEOUT}s timeout"
                )
            finally:
                self._running_tasks.pop(task_id, None)

        except Exception as e:
            execution_success = False
            execution_error = str(e)
            logger.error(
                f"âŒ [Scheduler] æ‰§è¡Œä»»åŠ¡å¤±è´¥: task_id={task_id}, error={e}",
                exc_info=True,
            )
            # æ‰§è¡Œå¤±è´¥ä¹Ÿè¦æ ‡è®°ï¼ˆé¿å…æ­»å¾ªç¯é‡è¯•ï¼‰

        # ---- Phase 2.5: å¹¿æ’­é€šçŸ¥åˆ°å‰ç«¯ï¼ˆé€šè¿‡ WebSocket ConnectionManagerï¼‰ ----
        await self._broadcast_task_notification(
            task_snapshot, execution_success, execution_error, response_text
        )

        # ---- Phase 3: æ ‡è®°æ‰§è¡Œå®Œæˆï¼ˆçŸ­æš‚æŒæœ‰ sessionï¼‰ ----
        try:
            assert self._workspace._session_factory is not None, "Workspace not started"
            async with self._workspace._session_factory() as session:
                updated_task = await mark_task_executed(session, task_id)

                if updated_task:
                    logger.info(
                        f"âœ… [Scheduler] ä»»åŠ¡æ‰§è¡Œå®Œæˆ: id={task_id}, "
                        f"run_count={updated_task.run_count}, status={updated_task.status}"
                    )

                    # cron / interval ä»»åŠ¡éœ€è¦é‡æ–°è°ƒåº¦
                    if updated_task.status == "active" and updated_task.next_run_at:
                        logger.info(f"ğŸ”„ [Scheduler] é‡æ–°è°ƒåº¦: id={task_id}, next_run={updated_task.next_run_at}")
                        self._register_job(updated_task)

        except Exception as e:
            logger.error(
                f"âŒ [Scheduler] æ ‡è®°ä»»åŠ¡å®Œæˆå¤±è´¥: task_id={task_id}, error={e}",
                exc_info=True,
            )

    async def _execute_task(self, task_data: Dict[str, Any]) -> Optional[str]:
        """
        Execute a single task.

        Args:
            task_data: Task snapshot dict (detached from session)

        Returns:
            AI response text (for agent_task type), or None.
        """
        action = task_data["action"]
        action_type = action.get("type", "send_message")
        task_id = task_data["id"]
        title = task_data["title"]

        logger.info(f"æ‰§è¡Œç”¨æˆ·ä»»åŠ¡: id={task_id}, title={title}, action={action_type}")

        if action_type == "send_message":
            await self._action_send_message(task_data, action)
            return action.get("content", "")
        elif action_type == "agent_task":
            return await self._action_agent_task(task_data, action)
        else:
            logger.warning(f"æœªçŸ¥çš„åŠ¨ä½œç±»å‹: {action_type}")
            return None

    async def _action_send_message(self, task_data: Dict[str, Any], action: Dict[str, Any]):
        """Send-message action: notification only, no conversation persistence.

        Scheduled reminders are displayed purely via the notification card;
        they should NOT pollute any existing conversation.
        """
        task_id = task_data["id"]
        title = task_data["title"]

        logger.info(
            f"âœ… [Scheduler] æé†’æ¶ˆæ¯å·²å‡†å¤‡ï¼ˆä»…é€šçŸ¥ï¼Œä¸å†™ä¼šè¯ï¼‰: "
            f"task_id={task_id}, title={title}"
        )

    async def _action_agent_task(self, task_data: Dict[str, Any], action: Dict[str, Any]) -> Optional[str]:
        """Execute Agent task in an isolated conversation and return response text.

        Each execution creates a dedicated hidden conversation so that the
        original conversation where the task was created is never polluted.
        Uses chat_service.conversation_service to create the conversation,
        ensuring the same session factory is used for both conversation and
        message creation (avoids FOREIGN KEY constraint failures from
        cross-engine session mismatch).
        """
        prompt = action.get("prompt", "")
        user_id = task_data["user_id"]
        task_id = task_data["id"]
        title = task_data["title"]

        if not prompt:
            logger.warning(f"Agent ä»»åŠ¡ç¼ºå°‘ prompt: task_id={task_id}")
            return None

        logger.info(f"æ‰§è¡Œ Agent ä»»åŠ¡: task_id={task_id}, prompt={prompt[:50]}...")

        try:
            from services.chat_service import get_chat_service

            chat_service = get_chat_service()

            # Create an isolated conversation via conversation_service
            # (same session factory as create_message in process_scheduled_task)
            exec_conv = await chat_service.conversation_service.create_conversation(
                user_id=user_id,
                title=f"å®šæ—¶ä»»åŠ¡: {title}",
                metadata={
                    "source": "scheduled_task",
                    "task_id": task_id,
                    "hidden": True,
                },
            )
            exec_conversation_id = exec_conv.id

            result = await chat_service.process_scheduled_task(
                user_id=user_id,
                conversation_id=exec_conversation_id,
                prompt=prompt,
                task_id=task_id,
            )

            _resp = result.get("response", "") if result else None
            logger.info(
                f"Agent ä»»åŠ¡æ‰§è¡Œå®Œæˆ: task_id={task_id}, "
                f"response_len={len(_resp) if _resp else 0}, "
                f"response_preview={(_resp or '')[:100]!r}"
            )
            return _resp

        except Exception as e:
            logger.error(
                f"Agent ä»»åŠ¡æ‰§è¡Œå¤±è´¥: task_id={task_id}, error={e}",
                exc_info=True,
            )
            raise

    async def _broadcast_task_notification(
        self,
        task_data: Dict[str, Any],
        success: bool,
        error: Optional[str] = None,
        response_text: Optional[str] = None,
    ):
        """
        Broadcast task execution notification to frontend via WebSocket.

        Args:
            task_data: Task snapshot
            success: Whether execution succeeded
            error: Error message on failure
            response_text: AI response text (for expandable preview)
        """
        try:
            from routers.websocket import get_connection_manager

            manager = get_connection_manager()

            action_type = task_data["action"].get("type", "send_message")
            now_str = datetime.now().strftime("%H:%M")

            if success:
                if action_type == "send_message":
                    title = f"å®šæ—¶æé†’: {task_data['title']}"
                    message = task_data["action"].get("content", "å®šæ—¶æé†’")
                    ntype = "message"
                else:
                    title = f"å®šæ—¶ä»»åŠ¡å®Œæˆ: {task_data['title']}"
                    message = f"Agent å·²æ‰§è¡Œ: {task_data['action'].get('prompt', '')[:60]}"
                    ntype = "success"
            else:
                title = f"å®šæ—¶ä»»åŠ¡å¤±è´¥: {task_data['title']}"
                message = error or "æœªçŸ¥é”™è¯¯"
                ntype = "error"

            payload: Dict[str, Any] = {
                "notification_type": ntype,
                "title": title,
                "message": message[:200],
                "task_id": task_data["id"],
                "triggered_at": now_str,
            }

            # Include AI response for expandable preview in notification card
            if response_text:
                payload["full_content"] = response_text[:2000]

            logger.info(
                f"ğŸ“¤ [Scheduler] å¹¿æ’­ payload keys={list(payload.keys())}, "
                f"has_full_content={'full_content' in payload}, "
                f"full_content_len={len(payload.get('full_content', ''))}"
            )

            await manager.broadcast_notification("notification", payload)

            logger.info(
                f"ğŸ“¢ [Scheduler] é€šçŸ¥å·²å¹¿æ’­: task_id={task_data['id']}, "
                f"type={ntype}, connections={manager.active_count}"
            )

        except Exception as e:
            # é€šçŸ¥å¤±è´¥ä¸åº”å½±å“ä»»åŠ¡æœ¬èº«çš„æ‰§è¡Œæµç¨‹
            logger.warning(
                f"âš ï¸ [Scheduler] å¹¿æ’­é€šçŸ¥å¤±è´¥: task_id={task_data['id']}, error={e}"
            )


# ==================== å…¨å±€å®ä¾‹ ====================

_user_task_scheduler: Optional[UserTaskScheduler] = None


def get_user_task_scheduler() -> UserTaskScheduler:
    """è·å–ç”¨æˆ·ä»»åŠ¡è°ƒåº¦å™¨å•ä¾‹"""
    global _user_task_scheduler
    if _user_task_scheduler is None:
        _user_task_scheduler = UserTaskScheduler()
    return _user_task_scheduler


async def start_user_task_scheduler():
    """å¯åŠ¨ç”¨æˆ·ä»»åŠ¡è°ƒåº¦å™¨"""
    scheduler = get_user_task_scheduler()
    await scheduler.start()
    return scheduler


async def stop_user_task_scheduler():
    """åœæ­¢ç”¨æˆ·ä»»åŠ¡è°ƒåº¦å™¨"""
    scheduler = get_user_task_scheduler()
    await scheduler.shutdown()
