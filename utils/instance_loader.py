"""
å®ä¾‹åŠ è½½å™¨ - Instance Loader

èŒè´£ï¼š
- åŠ è½½ instances/ ç›®å½•ä¸‹çš„æ™ºèƒ½ä½“å®ä¾‹é…ç½®
- åˆå¹¶ prompt.md å’Œæ¡†æ¶é€šç”¨æç¤ºè¯
- è°ƒç”¨ AgentFactory åˆ›å»º Agent
- è‡ªåŠ¨æ³¨å†Œ Claude Skillsï¼ˆå¯åŠ¨æ—¶ï¼‰

è®¾è®¡åŸåˆ™ï¼š
- Prompt-Firstï¼šæç¤ºè¯æ˜¯é…ç½®çš„æ ¸å¿ƒ
- æ— ä»£ç åŒ–ï¼šè¿è¥åªéœ€ç¼–è¾‘é…ç½®æ–‡ä»¶
- åˆ©ç”¨ç°æœ‰ AgentFactory
- Skills è‡ªåŠ¨ç”Ÿå‘½å‘¨æœŸç®¡ç†
"""

import asyncio
import os
import sys
from dataclasses import dataclass, field, replace
from pathlib import Path
from typing import Any, Dict, List, Optional

import aiofiles

from utils.app_paths import get_bundle_dir, get_instances_dir as _get_instances_dir

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„ï¼ˆå…¼å®¹å¼€å‘æ¨¡å¼ï¼‰
PROJECT_ROOT = get_bundle_dir()
sys.path.insert(0, str(PROJECT_ROOT))

from logger import get_logger

logger = get_logger("instance_loader")


@dataclass
class SkillConfig:
    """Skill é…ç½®æ•°æ®ç±»ï¼ˆæœ¬åœ° Skill ç³»ç»Ÿï¼‰"""

    name: str
    enabled: bool = True
    description: str = ""
    skill_path: Optional[Path] = None  # Skill ç›®å½•è·¯å¾„


@dataclass
class ApiConfig:
    """API é…ç½®æ•°æ®ç±»ï¼ˆREST API æè¿°ï¼‰"""

    name: str
    base_url: str
    auth_type: str = "none"  # none / bearer / api_key / basic
    auth_header: str = "Authorization"  # è®¤è¯å¤´åç§°
    auth_env: Optional[str] = None  # è®¤è¯å¯†é’¥çš„ç¯å¢ƒå˜é‡å
    doc: Optional[str] = None  # æŒ‡å‘ api_desc/{doc}.md
    description: str = ""
    # è¿è¡Œæ—¶å¡«å……
    headers: Dict[str, str] = field(default_factory=dict)
    doc_content: str = ""
    # è¯·æ±‚ä½“é…ç½®ï¼ˆç”¨äº api_calling å·¥å…·è‡ªåŠ¨åˆæˆè¯·æ±‚ï¼‰
    request_body: Optional[Dict[str, Any]] = None  # è¯·æ±‚ä½“æ¨¡æ¿
    default_method: str = "POST"  # é»˜è®¤ HTTP æ–¹æ³•
    default_mode: str = "sync"  # é»˜è®¤æ¨¡å¼ï¼šsync / stream / async_poll
    poll_config: Optional[Dict[str, Any]] = None  # å¼‚æ­¥è½®è¯¢é…ç½®


@dataclass
class LLMParams:
    """LLM è¶…å‚æ•°é…ç½®"""

    temperature: Optional[float] = None  # æ¸©åº¦ï¼Œå½±å“è¾“å‡ºéšæœºæ€§ï¼ˆ0-1ï¼‰
    max_tokens: Optional[int] = None  # æœ€å¤§è¾“å‡º token æ•°
    enable_thinking: Optional[bool] = None  # å¯ç”¨ Extended Thinking
    thinking_budget: Optional[int] = None  # Thinking token é¢„ç®—
    enable_caching: Optional[bool] = None  # å¯ç”¨ Prompt Caching
    top_p: Optional[float] = None  # æ ¸é‡‡æ ·å‚æ•°
    thinking_mode: Optional[str] = None  # æ€è€ƒæ¨¡å¼: native/simulated/none


@dataclass
class InstanceConfig:
    """
    å®ä¾‹é…ç½®æ•°æ®ç±»

    é…ç½®ä¼˜å…ˆçº§ï¼ˆä»é«˜åˆ°ä½ï¼‰ï¼š
    1. config.yaml æ˜¾å¼é…ç½® - è¿è¥äººå‘˜çš„åœºæ™¯åŒ–å®šåˆ¶
    2. LLM æ¨æ–­çš„ Schema - åŸºäº prompt.md çš„æ™ºèƒ½æ¨æ–­
    3. DEFAULT_AGENT_SCHEMA - é«˜è´¨é‡çš„æ¡†æ¶é»˜è®¤å€¼ï¼ˆå…œåº•ï¼‰
    """

    name: str
    description: str = ""
    version: str = "1.0.0"

    # Agent åŸºç¡€é…ç½®
    model: Optional[str] = None
    max_turns: Optional[int] = None
    plan_manager_enabled: Optional[bool] = None
    allow_parallel_tools: Optional[bool] = None

    # LLM è¶…å‚æ•°
    llm_params: LLMParams = field(default_factory=LLMParams)

    # Skills é…ç½®ï¼ˆClaude Skills å®˜æ–¹ APIï¼‰
    skills: List[SkillConfig] = field(default_factory=list)

    # APIs é…ç½®ï¼ˆREST API æè¿°ï¼‰
    apis: List[ApiConfig] = field(default_factory=list)

    # é€šç”¨å·¥å…·å¯ç”¨é…ç½®ï¼ˆä» capabilities.yaml é€‰æ‹©ï¼‰
    enabled_capabilities: Dict[str, bool] = field(default_factory=dict)

    # ===== é«˜çº§é…ç½®ï¼ˆä» config.yaml çš„ advanced éƒ¨åˆ†è¯»å–ï¼‰=====
    # è¿™äº›é…ç½®å¯é€‰ï¼Œæœªé…ç½®æ—¶ä½¿ç”¨ DEFAULT_AGENT_SCHEMA çš„é«˜è´¨é‡é»˜è®¤å€¼

    # æ„å›¾åˆ†æå™¨é…ç½®
    intent_analyzer_enabled: Optional[bool] = None
    intent_analyzer_use_llm: Optional[bool] = None
    intent_analyzer_fast_mode: Optional[bool] = None
    intent_analyzer_semantic_cache_threshold: Optional[float] = None
    intent_analyzer_simplified_output: Optional[bool] = None

    # å¼€åœºç™½é…ç½®ï¼ˆPrefaceï¼‰
    preface_enabled: Optional[bool] = None
    preface_max_tokens: Optional[int] = None

    # è®¡åˆ’ç®¡ç†å™¨é…ç½®
    plan_manager_max_steps: Optional[int] = None
    plan_manager_granularity: Optional[str] = None

    # è¾“å‡ºæ ¼å¼é…ç½®ï¼ˆV6.3 ä½¿ç”¨ Pydanticï¼‰
    output_format: Optional[str] = None
    output_code_highlighting: Optional[bool] = None
    output_json_model_name: Optional[str] = None
    output_json_schema: Optional[Dict[str, Any]] = None
    output_strict_json_validation: Optional[bool] = None
    output_json_ensure_ascii: Optional[bool] = None
    output_json_indent: Optional[int] = None

    # è®°å¿†é…ç½®
    mem0_enabled: bool = True
    smart_retrieval: bool = True
    retention_policy: str = "user"

    # ===== å°æ­å­æ‰©å±•é…ç½®ï¼ˆV11ï¼‰=====
    # æœªé…ç½®æ—¶ä¸º Noneï¼Œç”±å¯¹åº”æ¨¡å—ä½¿ç”¨é»˜è®¤å€¼
    termination: Optional[Dict[str, Any]] = None  # ç»ˆæ­¢ç­–ç•¥ï¼ˆadaptive ç­‰ï¼‰
    skills_first_config: Optional[Dict[str, Any]] = None  # Skills-First ç»Ÿä¸€é…ç½®
    state_consistency: Optional[Dict[str, Any]] = None  # çŠ¶æ€ä¸€è‡´æ€§ï¼ˆå¿«ç…§ã€å›æ»šï¼‰

    # åŸå§‹é…ç½®
    raw_config: Dict[str, Any] = field(default_factory=dict)


def get_instances_dir() -> Path:
    """è·å– instances ç›®å½•è·¯å¾„"""
    return _get_instances_dir()


def list_instances() -> List[str]:
    """
    åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„å®ä¾‹

    Returns:
        å®ä¾‹åç§°åˆ—è¡¨ï¼ˆæ’é™¤ _templateï¼‰
    """
    instances_dir = get_instances_dir()
    if not instances_dir.exists():
        return []

    instances = []
    for item in instances_dir.iterdir():
        if item.is_dir() and not item.name.startswith("_"):
            # æ£€æŸ¥æ˜¯å¦æœ‰ prompt.md
            if (item / "prompt.md").exists():
                instances.append(item.name)

    return sorted(instances)


async def load_skill_registry(instance_name: str) -> List[SkillConfig]:
    """
    åŠ è½½å®ä¾‹çš„ Skills æ³¨å†Œè¡¨

    Args:
        instance_name: å®ä¾‹åç§°

    Returns:
        SkillConfig åˆ—è¡¨
    """
    import yaml

    skills_dir = get_instances_dir() / instance_name / "skills"
    registry_path = skills_dir / "skill_registry.yaml"

    if not registry_path.exists():
        return []

    async with aiofiles.open(registry_path, "r", encoding="utf-8") as f:
        content = await f.read()
        registry = yaml.safe_load(content) or {}

    skills_list = registry.get("skills", [])
    if not isinstance(skills_list, list):
        return []

    result = []
    for skill_data in skills_list:
        if not isinstance(skill_data, dict):
            continue

        name = skill_data.get("name")
        if not name:
            continue

        # è§£æ Skill ç›®å½•ï¼šå…ˆå®ä¾‹ç›®å½•ï¼Œå†å…¨å±€ libraryï¼ˆä¸ SkillsLoader ä¸€è‡´ï¼‰
        skill_path = skills_dir / name
        if not skill_path.exists():
            library_dir = PROJECT_ROOT / "skills" / "library"
            fallback = library_dir / name
            if fallback.exists():
                skill_path = fallback
            else:
                logger.warning(f"âš ï¸ Skill ç›®å½•ä¸å­˜åœ¨: {skills_dir / name} ä¸” library æ— : {fallback}")
                continue

        # æ£€æŸ¥ SKILL.md æ˜¯å¦å­˜åœ¨
        skill_md = skill_path / "SKILL.md"
        if not skill_md.exists():
            logger.warning(f"âš ï¸ Skill å…¥å£æ–‡ä»¶ä¸å­˜åœ¨: {skill_md}")
            continue

        result.append(
            SkillConfig(
                name=name,
                enabled=skill_data.get("enabled", True),
                description=skill_data.get("description", ""),
                skill_path=skill_path,
            )
        )

    return result


async def _load_yaml(path: Path) -> dict:
    """Load a YAML file, return empty dict if not found."""
    if not path.exists():
        return {}
    async with aiofiles.open(path, "r", encoding="utf-8") as f:
        content = await f.read()
    return __import__("yaml").safe_load(content) or {}


def _resolve_llm_profiles(
    provider_name: str,
    provider_templates: Dict[str, Any],
    raw_profiles: Dict[str, Any],
) -> Dict[str, Dict[str, Any]]:
    """
    Resolve tier-based LLM profiles into fully-qualified profiles.

    Each profile specifies a ``tier`` ("heavy" / "light") which is expanded
    using the matching provider template.  If a profile already has an
    explicit ``provider`` key, the tier template is skipped (manual
    override).

    Args:
        provider_name: Active provider key (e.g. "qwen", "claude").
        provider_templates: The ``provider_templates`` section from
            llm_profiles.yaml.
        raw_profiles: The ``llm_profiles`` section (profile_name -> params).

    Returns:
        Dict of fully-resolved profiles ready for ``set_instance_profiles``.
    """
    template = provider_templates.get(provider_name)
    if not template:
        available = ", ".join(provider_templates.keys()) if provider_templates else "(empty)"
        raise ValueError(
            f"Provider '{provider_name}' not found in provider_templates. "
            f"Available: {available}"
        )

    resolved: Dict[str, Dict[str, Any]] = {}
    for name, params in raw_profiles.items():
        params = dict(params)  # shallow copy
        tier = params.pop("tier", None)

        if "provider" not in params and tier:
            # Merge tier template (provider/model/api_key_env/region)
            tier_cfg = template.get(tier, {})
            merged = {**tier_cfg, **params}  # profile params override template
            resolved[name] = merged
        else:
            # Explicit provider or no tier -> use as-is
            resolved[name] = params

    return resolved


async def load_instance_config(instance_name: str) -> InstanceConfig:
    """
    Load instance configuration from up to 3 files:

    1. ``config.yaml``              - user config (required)
    2. ``config/skills.yaml``       - skills & skill_groups
    3. ``config/llm_profiles.yaml`` - provider templates & LLM profiles

    Each config key lives in exactly ONE file. The loader merges them into
    a single ``raw_config`` dict for downstream processing.

    Args:
        instance_name: Instance directory name.

    Returns:
        InstanceConfig dataclass.

    Raises:
        FileNotFoundError: Instance directory missing.
        ValueError: Invalid configuration.
    """
    import yaml

    instance_dir = get_instances_dir() / instance_name

    if not instance_dir.exists():
        raise FileNotFoundError(f"å®ä¾‹ä¸å­˜åœ¨: {instance_name}")

    # â”€â”€ 1. Load & merge config files â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    raw_config = await _load_yaml(instance_dir / "config.yaml")

    # Skills config (skill_groups + skills)
    skills_file = await _load_yaml(instance_dir / "config" / "skills.yaml")
    if skills_file:
        if "skills" in skills_file:
            raw_config["skills"] = skills_file["skills"]
        if "skill_groups" in skills_file:
            raw_config["skill_groups"] = skills_file["skill_groups"]
        logger.info(f"   å·²åˆå¹¶ config/skills.yaml")

    # LLM profiles (provider templates + profiles with tier)
    llm_file = await _load_yaml(instance_dir / "config" / "llm_profiles.yaml")

    # â”€â”€ 2. Resolve provider templates â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    agent_config = raw_config.get("agent", {})
    provider_name = agent_config.get("provider", "")

    # Allow env var override (for E2E model compatibility testing)
    import os
    env_provider = os.environ.get("AGENT_PROVIDER")
    if env_provider:
        provider_name = env_provider
        agent_config["provider"] = env_provider
        # Clear explicit model so provider template auto-sets it
        agent_config.pop("model", None)
        raw_config["agent"] = agent_config
        logger.info(f"   âš¡ provider è¢«ç¯å¢ƒå˜é‡è¦†ç›–: {env_provider}")

    if llm_file and provider_name:
        provider_templates = llm_file.get("provider_templates", {})
        raw_profiles = llm_file.get("llm_profiles", {})

        if provider_templates and raw_profiles:
            resolved_profiles = _resolve_llm_profiles(
                provider_name, provider_templates, raw_profiles
            )
            raw_config["llm_profiles"] = resolved_profiles
            logger.info(
                f"   å·²åˆå¹¶ config/llm_profiles.yaml "
                f"(provider={provider_name}, {len(resolved_profiles)} profiles)"
            )

            tmpl = provider_templates.get(provider_name, {})

            # Auto-set agent.model from provider template if not explicit
            if not agent_config.get("model"):
                default_model = tmpl.get("agent_model")
                if default_model:
                    agent_config["model"] = default_model
                    logger.info(f"   agent.model è‡ªåŠ¨è®¾ç½®: {default_model}")

            # Auto-set agent.llm from provider template (user overrides win)
            template_llm = tmpl.get("agent_llm", {})
            if template_llm:
                user_llm = agent_config.get("llm", {})
                # template defaults + user overrides
                merged_llm = {**template_llm, **{k: v for k, v in user_llm.items() if v is not None}}
                agent_config["llm"] = merged_llm
                if user_llm:
                    logger.info(f"   agent.llm: æ¨¡æ¿é»˜è®¤ + ç”¨æˆ·è¦†ç›– {list(user_llm.keys())}")
                else:
                    logger.info(f"   agent.llm: ä½¿ç”¨ {provider_name} æ¨¡æ¿é»˜è®¤å€¼")

            raw_config["agent"] = agent_config
    elif llm_file:
        # No provider set but file exists: load raw profiles, strip tier hints
        raw_profiles = llm_file.get("llm_profiles", {})
        if raw_profiles:
            stripped = {}
            for name, params in raw_profiles.items():
                params = dict(params)
                params.pop("tier", None)
                stripped[name] = params
            raw_config["llm_profiles"] = stripped

    # â”€â”€ 2b. Fallback: å¦‚æœ provider/model ä»ä¸ºç©ºï¼Œä»å·²æ¿€æ´»æ¨¡å‹è·å– â”€â”€
    if not agent_config.get("provider") or not agent_config.get("model"):
        try:
            from core.llm.model_registry import ModelRegistry
            activated = ModelRegistry.list_activated()
            if activated:
                first = activated[0]
                if not agent_config.get("provider"):
                    agent_config["provider"] = first.provider
                    logger.info(f"   agent.provider ä»å·²æ¿€æ´»æ¨¡å‹è‡ªåŠ¨è®¾ç½®: {first.provider}")
                if not agent_config.get("model"):
                    agent_config["model"] = first.model_name
                    logger.info(f"   agent.model ä»å·²æ¿€æ´»æ¨¡å‹è‡ªåŠ¨è®¾ç½®: {first.model_name}")
                raw_config["agent"] = agent_config

                # é‡æ–°è§£æ provider templatesï¼ˆå¦‚æœæœ‰ llm_file ä¸”åˆšè®¾ç½®äº† providerï¼‰
                if llm_file and agent_config.get("provider"):
                    _pname = agent_config["provider"]
                    _templates = (llm_file.get("provider_templates") or {})
                    _profiles = (llm_file.get("llm_profiles") or {})
                    if _templates and _profiles:
                        resolved = _resolve_llm_profiles(_pname, _templates, _profiles)
                        raw_config["llm_profiles"] = resolved
                        _tmpl = _templates.get(_pname, {})
                        _tmpl_llm = _tmpl.get("agent_llm", {})
                        if _tmpl_llm:
                            agent_config["llm"] = {**_tmpl_llm, **agent_config.get("llm", {})}
                            raw_config["agent"] = agent_config
            else:
                logger.warning("   âš ï¸ æœªé…ç½® provider/model ä¸”æ— å·²æ¿€æ´»æ¨¡å‹ï¼ŒAgent å¯èƒ½æ— æ³•å¯åŠ¨")
        except Exception as e:
            logger.warning(f"   âš ï¸ ä»å·²æ¿€æ´»æ¨¡å‹è·å–é»˜è®¤å€¼å¤±è´¥: {e}")

    # â”€â”€ 3. Parse config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    instance_info = raw_config.get("instance", {})
    memory_config = raw_config.get("memory", {})

    # è§£æ LLM è¶…å‚æ•°
    llm_config = agent_config.get("llm", {})
    llm_params = LLMParams(
        temperature=llm_config.get("temperature"),
        max_tokens=llm_config.get("max_tokens"),
        enable_thinking=llm_config.get("enable_thinking"),
        thinking_budget=llm_config.get("thinking_budget"),
        enable_caching=llm_config.get("enable_caching"),
        top_p=llm_config.get("top_p"),
        thinking_mode=llm_config.get("thinking_mode"),  # æ€è€ƒæ¨¡å¼: native/simulated/none
    )

    # è§£æé€šç”¨å·¥å…·å¯ç”¨é…ç½®
    # V11: æ£€æµ‹ Skills-First æ–°æ ¼å¼ï¼ˆskills å« common/darwin ç­‰ OS é”®ï¼‰
    skills_raw = raw_config.get("skills", {})
    skills_first_config = None
    is_skills_first = isinstance(skills_raw, dict) and any(
        k in skills_raw for k in ("common", "darwin", "win32", "linux")
    )

    # ä»…é Skills-First æ—¶ä» skill_registry.yaml åŠ è½½ï¼Œé¿å…å¯¹ plan-todo/hitl ç­‰æ¡†æ¶å·¥å…·æŠ¥ã€Œç›®å½•ä¸å­˜åœ¨ã€
    if is_skills_first:
        skills = []
    else:
        skills = await load_skill_registry(instance_name)

    # åŠ è½½ APIs é…ç½®ï¼ˆREST API æè¿°ï¼‰
    apis = await _load_apis_config(instance_name, raw_config.get("apis", []))

    if is_skills_first:
        # Skills-First æ–°æ ¼å¼ï¼šä» SkillsLoader æ´¾ç”Ÿ enabled_capabilities
        skills_first_config = skills_raw
        logger.info("   æ£€æµ‹åˆ° Skills-First é…ç½®æ ¼å¼ï¼Œä½¿ç”¨ SkillsLoader")

        from core.skill import create_skills_loader

        _loader = create_skills_loader(
            skills_config=skills_raw,
            instance_skills_dir=instance_dir / "skills",
            instance_name=instance_name,
        )
        # å¼‚æ­¥åŠ è½½ï¼ˆload_instance_config æœ¬èº«æ˜¯ asyncï¼‰
        _entries = await _loader.load()
        enabled_capabilities = _loader.get_enabled_capabilities()

        logger.info(
            f"   Skills-First: {len(_entries)} ä¸ª Skills, "
            f"æ´¾ç”Ÿ {len(enabled_capabilities)} ä¸ª enabled_capabilities"
        )
    else:
        # æ—§æ ¼å¼ï¼šç›´æ¥ä» enabled_capabilities å­—æ®µè¯»å–
        enabled_capabilities_raw = raw_config.get("enabled_capabilities", {})
        enabled_capabilities = {}
        if isinstance(enabled_capabilities_raw, dict):
            for tool_name, enabled in enabled_capabilities_raw.items():
                if isinstance(enabled, bool):
                    enabled_capabilities[tool_name] = enabled
                elif isinstance(enabled, int):
                    enabled_capabilities[tool_name] = bool(enabled)
                else:
                    logger.warning(f"âš ï¸ å·¥å…· {tool_name} çš„å¯ç”¨é…ç½®å€¼æ— æ•ˆ: {enabled}ï¼Œå°†è¢«å¿½ç•¥")

    # è§£æ advanced é…ç½®ï¼ˆé«˜çº§é…ç½®ï¼Œå¯é€‰ï¼‰
    # æœªé…ç½®æ—¶ä½¿ç”¨ DEFAULT_AGENT_SCHEMA çš„é«˜è´¨é‡é»˜è®¤å€¼å…œåº•
    advanced_config = raw_config.get("advanced", {})
    intent_config = advanced_config.get("intent_analyzer", {})
    preface_config = advanced_config.get("preface", {})
    plan_config = advanced_config.get("plan_manager", {})
    output_config = advanced_config.get("output_formatter", {})

    return InstanceConfig(
        name=instance_info.get("name", instance_name),
        description=instance_info.get("description", ""),
        version=instance_info.get("version", "1.0.0"),
        model=agent_config.get("model"),
        max_turns=agent_config.get("max_turns"),
        plan_manager_enabled=agent_config.get("plan_manager_enabled"),
        allow_parallel_tools=agent_config.get("allow_parallel_tools"),
        llm_params=llm_params,
        skills=skills,
        apis=apis,
        enabled_capabilities=enabled_capabilities,
        # é«˜çº§é…ç½®ï¼ˆä» advanced éƒ¨åˆ†è¯»å–ï¼‰
        intent_analyzer_enabled=intent_config.get("enabled"),
        intent_analyzer_use_llm=intent_config.get("use_llm"),
        intent_analyzer_fast_mode=intent_config.get("fast_mode"),
        intent_analyzer_semantic_cache_threshold=intent_config.get("semantic_cache_threshold"),
        intent_analyzer_simplified_output=intent_config.get("simplified_output"),
        preface_enabled=preface_config.get("enabled"),
        preface_max_tokens=preface_config.get("max_tokens"),
        plan_manager_max_steps=plan_config.get("max_steps"),
        plan_manager_granularity=plan_config.get("granularity"),
        output_format=output_config.get("default_format"),
        output_code_highlighting=output_config.get("code_highlighting"),
        output_json_model_name=output_config.get("json_model_name"),
        output_json_schema=output_config.get("json_schema"),
        output_strict_json_validation=output_config.get("strict_json_validation"),
        output_json_ensure_ascii=output_config.get("json_ensure_ascii"),
        output_json_indent=output_config.get("json_indent"),
        # è®°å¿†é…ç½®
        mem0_enabled=memory_config.get("mem0_enabled", True),
        smart_retrieval=memory_config.get("smart_retrieval", True),
        retention_policy=memory_config.get("retention_policy", "user"),
        # å°æ­å­æ‰©å±•é…ç½®ï¼ˆV11ï¼‰
        termination=raw_config.get("termination") if isinstance(raw_config.get("termination"), dict) else None,
        skills_first_config=skills_first_config,
        state_consistency=raw_config.get("state_consistency") if isinstance(raw_config.get("state_consistency"), dict) else None,
        raw_config=raw_config,
    )


async def _load_apis_config(instance_name: str, apis_raw: List[Dict]) -> List[ApiConfig]:
    """
    åŠ è½½å¹¶è§£æ APIs é…ç½®

    Args:
        instance_name: å®ä¾‹åç§°
        apis_raw: config.yaml ä¸­çš„ apis é…ç½®åˆ—è¡¨

    Returns:
        ApiConfig åˆ—è¡¨
    """
    if not isinstance(apis_raw, list):
        return []

    result = []
    api_desc_dir = get_instances_dir() / instance_name / "api_desc"

    for api_data in apis_raw:
        if not isinstance(api_data, dict):
            continue

        name = api_data.get("name")
        base_url = api_data.get("base_url")

        if not name or not base_url:
            logger.warning(f"âš ï¸ API é…ç½®ç¼ºå°‘ name æˆ– base_urlï¼Œè·³è¿‡")
            continue

        # è§£æè®¤è¯é…ç½®
        auth = api_data.get("auth", {})
        auth_type = auth.get("type", "none") if isinstance(auth, dict) else "none"
        auth_header = (
            auth.get("header", "Authorization") if isinstance(auth, dict) else "Authorization"
        )
        auth_env = auth.get("env") if isinstance(auth, dict) else None

        # åŠ è½½ API æè¿°æ–‡æ¡£
        doc_name = api_data.get("doc")
        doc_content = ""
        if doc_name:
            doc_path = api_desc_dir / f"{doc_name}.md"
            if doc_path.exists():
                async with aiofiles.open(doc_path, "r", encoding="utf-8") as f:
                    doc_content = await f.read()
                logger.info(f"   ğŸ“„ å·²åŠ è½½ API æ–‡æ¡£: {doc_path.name}")
            else:
                logger.warning(f"âš ï¸ API æ–‡æ¡£ä¸å­˜åœ¨: {doc_path}")

        result.append(
            ApiConfig(
                name=name,
                base_url=base_url,
                auth_type=auth_type,
                auth_header=auth_header,
                auth_env=auth_env,
                doc=doc_name,
                description=api_data.get("description", ""),
                doc_content=doc_content,
                # è¯·æ±‚ä½“é…ç½®ï¼ˆç”¨äº api_calling å·¥å…·è‡ªåŠ¨åˆæˆè¯·æ±‚ï¼‰
                request_body=api_data.get("request_body"),
                default_method=api_data.get("default_method", "POST"),
                default_mode=api_data.get("default_mode", "sync"),
                poll_config=api_data.get("poll_config"),
            )
        )

    return result


def _prepare_apis(apis: List[ApiConfig]) -> List[ApiConfig]:
    """
    å‡†å¤‡ APIs è¿è¡Œæ—¶å‚æ•°ï¼ˆæ„å»º headersï¼‰

    Args:
        apis: ApiConfig åˆ—è¡¨

    Returns:
        å¡«å……äº† headers çš„ ApiConfig åˆ—è¡¨
    """
    for api in apis:
        headers = {}

        # æ„å»ºè®¤è¯å¤´
        if api.auth_type in ("bearer", "api_key", "token") and api.auth_env:
            auth_value = os.getenv(api.auth_env)
            if auth_value:
                if api.auth_type == "bearer":
                    headers[api.auth_header] = f"Bearer {auth_value}"
                else:  # api_key æˆ– tokenï¼šç›´æ¥ä½¿ç”¨å€¼
                    headers[api.auth_header] = auth_value
                # ğŸ” è°ƒè¯•ï¼šæ˜¾ç¤º token çš„å‰ 10 ä½å’Œå 4 ä½
                masked_value = (
                    f"{auth_value[:10]}...{auth_value[-4:]}" if len(auth_value) > 14 else "***"
                )
                logger.info(f"   ğŸ”‘ API {api.name}: å·²é…ç½®è®¤è¯ (token: {masked_value})")
            else:
                logger.warning(
                    f"âš ï¸ API {api.name}: ç¯å¢ƒå˜é‡ {api.auth_env} æœªè®¾ç½®ï¼ˆå½“å‰ç¯å¢ƒå˜é‡åˆ—è¡¨ä¸­æ— æ­¤é¡¹ï¼‰"
                )

        api.headers = headers

    return apis


def _build_apis_prompt_section(apis: List[ApiConfig]) -> str:
    """
    æ„å»º APIs æç¤ºè¯ç‰‡æ®µï¼ˆæ³¨å…¥åˆ° System Promptï¼‰

    Args:
        apis: ApiConfig åˆ—è¡¨

    Returns:
        APIs æè¿°çš„ Markdown æ–‡æœ¬
    """
    if not apis:
        return ""

    sections = ["# å¯ç”¨çš„ REST APIs\n"]

    for api in apis:
        sections.append(f"## {api.name}")
        sections.append(f"- Base URL: `{api.base_url}`")
        if api.description:
            sections.append(f"- æè¿°: {api.description}")

        # æ·»åŠ æ–‡æ¡£å†…å®¹
        if api.doc_content:
            sections.append(f"\n{api.doc_content}")

        sections.append("")  # ç©ºè¡Œåˆ†éš”

    sections.append(
        """
> ğŸ’¡ è°ƒç”¨ API æ—¶ï¼Œä½¿ç”¨ `api_calling` å·¥å…·ï¼š
> - `url`: å®Œæ•´ URLï¼ˆbase_url + è·¯å¾„ï¼‰
> - `method`: HTTP æ–¹æ³•
> - `body`: è¯·æ±‚ä½“ï¼ˆJSONï¼‰
> - è®¤è¯å¤´å·²è‡ªåŠ¨é…ç½®
"""
    )

    return "\n".join(sections)


def _build_persona_prompt(persona: dict) -> str:
    """
    å°†ç”¨æˆ·ä¸ªæ€§åŒ–é…ç½®ï¼ˆpersonaï¼‰è½¬æ¢ä¸ºæç¤ºè¯ç‰‡æ®µ

    æ‰€æœ‰å­—æ®µå¯é€‰ï¼Œç©ºå€¼è·³è¿‡ã€‚åªæ„å»ºç”¨æˆ·å®é™…å¡«å†™çš„éƒ¨åˆ†ã€‚
    æ³¨å…¥åˆ° runtime_context["persona_prompt"]ï¼Œåœ¨ system prompt åŠ¨æ€å±‚ä½¿ç”¨ã€‚

    Args:
        persona: config.yaml ä¸­çš„ persona å­—æ®µ

    Returns:
        ä¸ªæ€§åŒ–æç¤ºè¯ç‰‡æ®µï¼Œç©ºé…ç½®è¿”å›ç©ºå­—ç¬¦ä¸²
    """
    if not persona or not isinstance(persona, dict):
        return ""

    parts = []

    nickname = (persona.get("nickname") or "").strip()
    if nickname:
        parts.append(f"- ç§°å‘¼ç”¨æˆ·ä¸ºã€Œ{nickname}ã€")

    tone = (persona.get("tone") or "").strip()
    if tone:
        parts.append(f"- è¯´è¯é£æ ¼ï¼š{tone}")

    language = (persona.get("language") or "").strip()
    if language and language != "ä¸­æ–‡":
        parts.append(f"- å›å¤è¯­è¨€ï¼š{language}")

    detail_level = (persona.get("detail_level") or "").strip()
    if detail_level and detail_level != "é€‚ä¸­":
        detail_map = {"ç®€æ´": "å°½é‡ç®€çŸ­ï¼Œè¦ç‚¹å³å¯", "è¯¦ç»†": "ç»™å‡ºè¯¦ç»†è§£é‡Šå’Œæ­¥éª¤"}
        if detail_level in detail_map:
            parts.append(f"- å›ç­”è¯¦ç»†åº¦ï¼š{detail_map[detail_level]}")

    work_dirs = persona.get("work_dirs") or []
    if work_dirs and isinstance(work_dirs, list):
        dirs_str = "ã€".join(str(d) for d in work_dirs[:5])
        parts.append(f"- ç”¨æˆ·å¸¸ç”¨å·¥ä½œç›®å½•ï¼š{dirs_str}ï¼ˆä¼˜å…ˆåœ¨è¿™äº›ç›®å½•æŸ¥æ‰¾æ–‡ä»¶ï¼‰")

    custom_rules = persona.get("custom_rules") or []
    if custom_rules and isinstance(custom_rules, list):
        for rule in custom_rules[:10]:
            rule_str = str(rule).strip()
            if rule_str:
                parts.append(f"- {rule_str}")

    if not parts:
        return ""

    return "<user_preferences>\n" + "\n".join(parts) + "\n</user_preferences>"


async def load_instance_prompt(instance_name: str) -> str:
    """
    åŠ è½½å®ä¾‹æç¤ºè¯

    Args:
        instance_name: å®ä¾‹åç§°

    Returns:
        å®ä¾‹æç¤ºè¯å†…å®¹

    Raises:
        FileNotFoundError: prompt.md ä¸å­˜åœ¨
    """
    prompt_path = get_instances_dir() / instance_name / "prompt.md"

    if not prompt_path.exists():
        raise FileNotFoundError(f"å®ä¾‹æç¤ºè¯ä¸å­˜åœ¨: {prompt_path}")

    async with aiofiles.open(prompt_path, "r", encoding="utf-8") as f:
        return await f.read()


def load_instance_env_from_config(instance_name: str) -> None:
    """
    ä»å®ä¾‹ç›®å½•åŠ è½½ç¯å¢ƒå˜é‡åˆ° os.environ

    åŠ è½½é¡ºåºï¼ˆååŠ è½½çš„è¦†ç›–å…ˆåŠ è½½çš„ï¼‰ï¼š
    1. å®ä¾‹ç›®å½•ä¸‹çš„ .env æ–‡ä»¶ï¼ˆé€šè¿‡ python-dotenvï¼‰
    2. å®ä¾‹ config.yaml çš„ env_vars æ®µï¼ˆä¼˜å…ˆçº§æ›´é«˜ï¼‰

    Args:
        instance_name: å®ä¾‹åç§°
    """
    import os

    import yaml

    instance_dir = get_instances_dir() / instance_name

    # Step 1: åŠ è½½å®ä¾‹ç›®å½•ä¸‹çš„ .env æ–‡ä»¶
    env_file = instance_dir / ".env"
    if env_file.exists():
        try:
            from dotenv import load_dotenv

            load_dotenv(dotenv_path=env_file, override=False)
            logger.info(f"ä»å®ä¾‹ {instance_name}/.env åŠ è½½ç¯å¢ƒå˜é‡")
        except ImportError:
            logger.warning("python-dotenv æœªå®‰è£…ï¼Œè·³è¿‡ .env åŠ è½½ã€‚å®‰è£…: pip install python-dotenv")

    # Step 2: åŠ è½½ config.yaml çš„ env_vars æ®µï¼ˆä¼˜å…ˆçº§æ›´é«˜ï¼Œä¼šè¦†ç›– .envï¼‰
    config_path = instance_dir / "config.yaml"
    if not config_path.exists():
        if not env_file.exists():
            logger.warning(f"å®ä¾‹é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        return

    try:
        with open(config_path, "r", encoding="utf-8") as f:
            raw_config = yaml.safe_load(f) or {}
    except Exception as e:
        logger.error(f"åŠ è½½å®ä¾‹é…ç½®å¤±è´¥: {e}", exc_info=True)
        return

    env_vars = raw_config.get("env_vars", {})
    if not isinstance(env_vars, dict) or not env_vars:
        return

    injected_count = 0
    for key, value in env_vars.items():
        if value is not None and str(value).strip():
            os.environ[key] = str(value).strip()
            injected_count += 1

    if injected_count > 0:
        logger.info(f"ä»å®ä¾‹ {instance_name}/config.yaml æ³¨å…¥ {injected_count} ä¸ªç¯å¢ƒå˜é‡")


def _merge_config_to_schema(base_schema, config: InstanceConfig):
    """
    å°† config.yaml é…ç½®åˆå¹¶åˆ° AgentSchema

    åˆå¹¶ç­–ç•¥ï¼š
    - config.yaml æœ‰æ˜¾å¼é…ç½® â†’ è¦†ç›– Schema é»˜è®¤å€¼
    - config.yaml æœªé…ç½®ï¼ˆNoneï¼‰â†’ ä¿ç•™ Schema çš„é«˜è´¨é‡é»˜è®¤å€¼

    è¿™æ ·å³ä½¿è¿è¥é…ç½®ä¸å…¨æˆ–é…ç½®é”™è¯¯ï¼Œä¹Ÿèƒ½ä¾èµ– DEFAULT_AGENT_SCHEMA å…œåº•ã€‚

    Args:
        base_schema: åŸºç¡€ Schemaï¼ˆæ¥è‡ª LLM æ¨æ–­æˆ– DEFAULT_AGENT_SCHEMAï¼‰
        config: InstanceConfigï¼ˆä» config.yaml è¯»å–ï¼‰

    Returns:
        åˆå¹¶åçš„ AgentSchema
    """
    # æ·±æ‹·è´ Schemaï¼Œé¿å…ä¿®æ”¹åŸå§‹é»˜è®¤å€¼
    merged = base_schema.copy(deep=True)

    # === åŸºç¡€é…ç½®è¦†ç›– ===
    if config.model:
        merged.model = config.model
    if config.max_turns:
        merged.max_turns = config.max_turns
    if config.allow_parallel_tools is not None:
        merged.allow_parallel_tools = config.allow_parallel_tools

    # === è®¡åˆ’ç®¡ç†å™¨é…ç½®è¦†ç›– ===
    if config.plan_manager_enabled is not None:
        merged.plan_manager.enabled = config.plan_manager_enabled
    if config.plan_manager_max_steps is not None:
        merged.plan_manager.max_steps = config.plan_manager_max_steps
    if config.plan_manager_granularity is not None:
        merged.plan_manager.granularity = config.plan_manager_granularity

    # === æ„å›¾åˆ†æå™¨é…ç½®è¦†ç›– ===
    if config.intent_analyzer_enabled is not None:
        merged.intent_analyzer.enabled = config.intent_analyzer_enabled
    if config.intent_analyzer_use_llm is not None:
        merged.intent_analyzer.use_llm = config.intent_analyzer_use_llm
    if config.intent_analyzer_fast_mode is not None:
        merged.intent_analyzer.fast_mode = config.intent_analyzer_fast_mode
    if config.intent_analyzer_semantic_cache_threshold is not None:
        merged.intent_analyzer.semantic_cache_threshold = config.intent_analyzer_semantic_cache_threshold
    if config.intent_analyzer_simplified_output is not None:
        merged.intent_analyzer.simplified_output = config.intent_analyzer_simplified_output

    # === å¼€åœºç™½é…ç½®è¦†ç›–ï¼ˆPrefaceï¼‰===
    if config.preface_enabled is not None:
        if merged.prompts and merged.prompts.preface:
            merged.prompts.preface.enabled = config.preface_enabled
        elif config.preface_enabled:
            # å¦‚æœå¯ç”¨ä½†æ²¡æœ‰é»˜è®¤æ¨¡æ¿ï¼Œè®°å½•è­¦å‘Š
            logger.warning("âš ï¸ preface.enabled=true ä½†æ²¡æœ‰é…ç½® preface æ¨¡æ¿ï¼Œå°†è¢«å¿½ç•¥")
    if config.preface_max_tokens is not None:
        if merged.prompts and merged.prompts.preface:
            merged.prompts.preface.max_tokens = config.preface_max_tokens

    # === LLM å‚æ•°é…ç½®è¦†ç›– ===
    # æ³¨æ„ï¼šè¿™äº›å‚æ•°åªå½±å“é€šè¿‡ instance_config.llm_params åˆ›å»ºçš„ LLM service
    # ä¸ä¼šå½±å“å·²é€šè¿‡ provider æ¨¡æ¿è§£æçš„ LLM profiles
    # æ­¤å¤„ç”¨äºè®°å½•é…ç½®æ„å›¾ï¼Œå®é™… LLM service åˆ›å»ºæ—¶ä¼šä¼˜å…ˆä½¿ç”¨ profile
    llm_override_count = 0
    if config.llm_params.temperature is not None:
        llm_override_count += 1
    if config.llm_params.max_tokens is not None:
        llm_override_count += 1
    if config.llm_params.enable_thinking is not None:
        llm_override_count += 1
    if config.llm_params.thinking_budget is not None:
        llm_override_count += 1
    if config.llm_params.enable_caching is not None:
        llm_override_count += 1
    if config.llm_params.top_p is not None:
        llm_override_count += 1
    if config.llm_params.thinking_mode is not None:
        llm_override_count += 1
        # ğŸ†• V7.10: å°† thinking_mode åº”ç”¨åˆ° AgentSchema
        merged.thinking_mode = config.llm_params.thinking_mode
        logger.info(f"ğŸ§  thinking_mode é…ç½®: {config.llm_params.thinking_mode}")

    if llm_override_count > 0:
        logger.debug(
            f"ğŸ“ config.yaml è¦†ç›–äº† {llm_override_count} é¡¹ LLM å‚æ•° (æ³¨æ„ï¼šéœ€è¦æ£€æŸ¥æ˜¯å¦è¢« profile è¦†ç›–)"
        )

    # === è¾“å‡ºæ ¼å¼é…ç½®è¦†ç›–ï¼ˆV6.3 Pydantic æ”¯æŒï¼‰===
    if config.output_format:
        merged.output_formatter.default_format = config.output_format
    if config.output_code_highlighting is not None:
        merged.output_formatter.code_highlighting = config.output_code_highlighting
    if config.output_json_model_name:
        merged.output_formatter.json_model_name = config.output_json_model_name
    if config.output_json_schema:
        merged.output_formatter.json_schema = config.output_json_schema
    if config.output_strict_json_validation is not None:
        merged.output_formatter.strict_json_validation = config.output_strict_json_validation
    if config.output_json_ensure_ascii is not None:
        merged.output_formatter.json_ensure_ascii = config.output_json_ensure_ascii
    if config.output_json_indent is not None:
        merged.output_formatter.json_indent = config.output_json_indent

    # === å·¥å…·åˆ—è¡¨è¦†ç›–ï¼ˆä» enabled_capabilities ç”Ÿæˆï¼‰===
    # ğŸ†• V10.1: å°† enabled_capabilities è®¾ç½®åˆ° Schema.tools
    # ç¡®ä¿å®ä¾‹é…ç½®çš„å·¥å…·å…¨é‡æ³¨å…¥åˆ° LLM è°ƒç”¨ï¼Œè€Œä¸æ˜¯æ ¹æ® intent åŠ¨æ€è¿‡æ»¤
    if config.enabled_capabilities:
        enabled_tools = [
            tool_name for tool_name, enabled in config.enabled_capabilities.items() if enabled
        ]
        if enabled_tools:
            merged.tools = enabled_tools
            logger.info(
                f"ğŸ”§ ä» enabled_capabilities è®¾ç½® {len(enabled_tools)} ä¸ªå·¥å…·åˆ° Schema.tools"
            )

    # === è®°å½•åˆå¹¶ç»“æœ ===
    override_count = sum(
        [
            config.model is not None,
            config.max_turns is not None,
            config.allow_parallel_tools is not None,
            config.plan_manager_enabled is not None,
            config.plan_manager_max_steps is not None,
            config.plan_manager_granularity is not None,
            config.intent_analyzer_enabled is not None,
            config.intent_analyzer_use_llm is not None,
            config.preface_enabled is not None,
            config.preface_max_tokens is not None,
            config.output_format is not None,
            config.output_code_highlighting is not None,
            config.output_json_model_name is not None,
            config.output_json_schema is not None,
            config.output_strict_json_validation is not None,
            config.output_json_ensure_ascii is not None,
            config.output_json_indent is not None,
            bool(config.enabled_capabilities),  # ğŸ†• V10.1: å·¥å…·åˆ—è¡¨è¦†ç›–
        ]
    )

    if override_count > 0:
        logger.info(f"âœ… config.yaml è¦†ç›–äº† {override_count} é¡¹ Schema é…ç½®")
    else:
        logger.info("âœ… config.yaml æ— æ˜¾å¼é…ç½®ï¼Œä½¿ç”¨ Schema é»˜è®¤å€¼")

    return merged


async def create_agent_from_instance(
    instance_name: str,
    event_manager=None,
    conversation_service=None,
    skip_skills_registration: bool = False,
    force_refresh: bool = False,
):
    """
    ä»å®ä¾‹é…ç½®åˆ›å»º Agentï¼ˆæ ¸å¿ƒæ–¹æ³•ï¼‰

    é…ç½®ä¼˜å…ˆçº§ï¼ˆä»é«˜åˆ°ä½ï¼‰ï¼š
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 1. config.yaml æ˜¾å¼é…ç½®  - è¿è¥äººå‘˜çš„åœºæ™¯åŒ–å®šåˆ¶            â”‚
    â”‚ 2. LLM æ¨æ–­çš„ Schema     - åŸºäº prompt.md çš„æ™ºèƒ½æ¨æ–­       â”‚
    â”‚ 3. DEFAULT_AGENT_SCHEMA  - é«˜è´¨é‡çš„æ¡†æ¶é»˜è®¤å€¼ï¼ˆå…œåº•ï¼‰      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    è®¾è®¡ç†å¿µï¼š
    - config.yaml æœ‰é…ç½® â†’ ä½¿ç”¨ config.yaml çš„å€¼
    - config.yaml æœªé…ç½® â†’ ä½¿ç”¨ LLM æ¨æ–­æˆ–æ¡†æ¶é»˜è®¤å€¼å…œåº•
    - å³ä½¿è¿è¥é…ç½®ä¸å…¨/é”™è¯¯ï¼ŒAgent ä¹Ÿèƒ½ä»¥é«˜è´¨é‡é»˜è®¤è¡Œä¸ºè¿è¡Œ

    æµç¨‹ï¼š
    1. åŠ è½½ç¯å¢ƒå˜é‡
    2. åŠ è½½å®ä¾‹é…ç½®ï¼ˆconfig.yamlï¼‰
    3. åŠ è½½å®ä¾‹æç¤ºè¯ï¼ˆprompt.mdï¼‰
    4. åŠ è½½ InstancePromptCacheï¼ˆåŒ…å« LLM æ¨æ–­çš„ Schema å’Œæç¤ºè¯ç‰ˆæœ¬ï¼‰
    5. åˆå¹¶é…ç½®ï¼šconfig.yaml è¦†ç›– Schema é»˜è®¤å€¼
    6. è°ƒç”¨ AgentFactory.from_schema() åˆ›å»º Agent
    7. æ³¨å†Œ Claude Skills
    8. ä¿å­˜å·¥å…·æ¨æ–­ç¼“å­˜

    Args:
        instance_name: å®ä¾‹åç§°
        event_manager: äº‹ä»¶ç®¡ç†å™¨
        conversation_service: ä¼šè¯æœåŠ¡
        skip_skills_registration: æ˜¯å¦è·³è¿‡ Skills æ³¨å†Œ
        force_refresh: å¼ºåˆ¶åˆ·æ–°ç¼“å­˜ï¼Œé‡æ–°ç”Ÿæˆ Schema å’Œæ¨æ–­å·¥å…·

    Returns:
        é…ç½®å¥½çš„ Agent å®ä¾‹
    """
    from pathlib import Path

    from core.agent import AgentFactory
    from prompts.universal_agent_prompt import get_universal_agent_prompt

    logger.info(f"ğŸš€ å¼€å§‹åŠ è½½å®ä¾‹: {instance_name}")

    # 0. ç¡®ä¿ AGENT_INSTANCE ç¯å¢ƒå˜é‡ä¸å½“å‰å®ä¾‹ä¸€è‡´
    # è¿™æ˜¯æ‰€æœ‰å­˜å‚¨ç»„ä»¶ï¼ˆDB/Memory/Mem0/Playbook/Snapshotï¼‰
    # å®ä¾‹éš”ç¦»çš„åŸºç¡€ â€” å„ç»„ä»¶é€šè¿‡æ­¤å˜é‡è‡ªåŠ¨æ´¾ç”Ÿéš”ç¦»è·¯å¾„
    os.environ["AGENT_INSTANCE"] = instance_name

    # å‡†å¤‡ç¼“å­˜ç›®å½•
    instance_path = get_instances_dir() / instance_name
    cache_dir = instance_path / ".cache"

    if force_refresh:
        logger.info("ğŸ”„ å¼ºåˆ¶åˆ·æ–°ç¼“å­˜æ¨¡å¼")

    # 1. åŠ è½½å®ä¾‹ç¯å¢ƒå˜é‡ï¼ˆä» config.yaml çš„ env_vars æ®µï¼‰
    load_instance_env_from_config(instance_name)

    # 2. åŠ è½½å®ä¾‹é…ç½®
    config = await load_instance_config(instance_name)
    logger.info(f"   é…ç½®: {config.name} v{config.version}")
    logger.info(f"   æè¿°: {config.description}")

    # 2.0.1 æ³¨å†Œè‡ªå®šä¹‰æ•°æ®ç›®å½•ï¼ˆè‹¥ config.yaml é…ç½®äº† storage.data_dirï¼‰
    storage_cfg = (config.raw_config or {}).get("storage", {})
    custom_data_dir = storage_cfg.get("data_dir") if isinstance(storage_cfg, dict) else None
    if custom_data_dir:
        from utils.app_paths import register_instance_data_dir
        register_instance_data_dir(instance_name, custom_data_dir)
        logger.info(f"   è‡ªå®šä¹‰å­˜å‚¨è·¯å¾„: {custom_data_dir}")

    # 2.1 æ³¨å…¥å®ä¾‹ LLM Profilesï¼ˆå¿…é¡»åœ¨ InstancePromptCache åŠ è½½ä¹‹å‰ï¼‰
    from config.llm_config.loader import set_instance_profiles

    llm_profiles = (config.raw_config or {}).get("llm_profiles", {})
    if llm_profiles:
        set_instance_profiles(llm_profiles)
    else:
        logger.warning("âš ï¸ å®ä¾‹æœªé…ç½® llm_profilesï¼Œæ¡†æ¶å†…éƒ¨ LLM è°ƒç”¨å°†ä¸å¯ç”¨")

    # V11: Skills-First åŠ è½½å™¨ï¼ˆç»Ÿä¸€å¤„ç† Skills äºŒç»´åˆ†ç±»ï¼‰
    skills_loader = None
    if config.skills_first_config:
        from core.skill import create_skills_loader

        skills_loader = create_skills_loader(
            skills_config=config.skills_first_config,
            instance_skills_dir=instance_path / "skills",
            instance_name=instance_name,
        )
        skill_entries = await skills_loader.load()
        available_count = len(skills_loader.get_available_skills())
        logger.info(
            f"   Skills-First: {len(skill_entries)} ä¸ª Skills, "
            f"{available_count} ä¸ªå¯ç”¨"
        )
    logger.info(f"   Skills: {len(config.skills)} ä¸ª")
    logger.info(f"   APIs: {len(config.apis)} ä¸ª")

    # 3. åŠ è½½å®ä¾‹æç¤ºè¯
    instance_prompt = await load_instance_prompt(instance_name)

    # åˆå¹¶ç”¨æˆ·ä¸ªæ€§åŒ–é…ç½®ï¼ˆpersona + user_promptï¼‰åˆ°å®ä¾‹æç¤ºè¯
    # å¯åŠ¨æ—¶ä¸€æ¬¡æ€§åˆå¹¶ï¼Œèµ° Prompt Caching STABLE å±‚ï¼ˆLayer 2ï¼‰
    persona_prompt = _build_persona_prompt(config.raw_config.get("persona", {}))
    user_prompt = (config.raw_config.get("user_prompt") or "").strip()

    user_config_parts = []
    if persona_prompt:
        user_config_parts.append(persona_prompt)
    if user_prompt:
        user_config_parts.append(f"<user_instructions>\n{user_prompt}\n</user_instructions>")

    if user_config_parts:
        instance_prompt = instance_prompt + "\n\n" + "\n\n".join(user_config_parts)
        logger.info(f"   ç”¨æˆ·é…ç½®å·²åˆå¹¶: persona={bool(persona_prompt)}, user_prompt={bool(user_prompt)}")

    logger.info(f"   æç¤ºè¯é•¿åº¦: {len(instance_prompt)} å­—ç¬¦")

    # ğŸ†• V5.0: ä¸€æ¬¡æ€§åŠ è½½ InstancePromptCacheï¼ˆæ ¸å¿ƒæ”¹åŠ¨ï¼‰
    # è¿™ä¼šåœ¨å¯åŠ¨æ—¶ï¼š
    # 1. ğŸ†• ä¼˜å…ˆä»ç£ç›˜ç¼“å­˜åŠ è½½ï¼ˆ< 100msï¼‰
    # 2. ç¼“å­˜æ— æ•ˆæ—¶æ‰§è¡Œ LLM åˆ†æï¼ˆ2-3ç§’ï¼‰
    # ç”Ÿæˆå†…å®¹ï¼š
    # - PromptSchemaï¼ˆæç¤ºè¯ç»“æ„ï¼‰
    # - AgentSchemaï¼ˆAgent é…ç½®ï¼‰
    # - ä¸‰ä¸ªç‰ˆæœ¬çš„ç³»ç»Ÿæç¤ºè¯ï¼ˆSimple/Medium/Complexï¼‰
    # - æ„å›¾è¯†åˆ«æç¤ºè¯
    from core.prompt import InstancePromptCache, load_instance_cache

    prompt_cache = await load_instance_cache(
        instance_name=instance_name,
        raw_prompt=instance_prompt,
        config=config.raw_config,
        cache_dir=str(cache_dir),  # ğŸ†• V5.0: å¯ç”¨ç£ç›˜æŒä¹…åŒ–
        force_refresh=force_refresh,
    )

    # æ‰“å°ç¼“å­˜çŠ¶æ€
    cache_status = prompt_cache.get_status()
    persistence_info = cache_status.get("persistence", {})
    metrics = cache_status.get("metrics", {})

    logger.info(f"âœ… InstancePromptCache åŠ è½½å®Œæˆ")
    logger.info(
        f"   Agent: {prompt_cache.agent_schema.name if prompt_cache.agent_schema else 'Default'}"
    )
    logger.info(
        f"   æç¤ºè¯ç‰ˆæœ¬: Simple={len(prompt_cache.system_prompt_simple or '')}å­—ç¬¦, "
        f"Medium={len(prompt_cache.system_prompt_medium or '')}å­—ç¬¦, "
        f"Complex={len(prompt_cache.system_prompt_complex or '')}å­—ç¬¦"
    )

    # ğŸ†• V5.0: æ˜¾ç¤ºæŒä¹…åŒ–çŠ¶æ€
    if persistence_info.get("enabled"):
        if metrics.get("disk_hits", 0) > 0:
            logger.info(f"   ğŸ’¾ ä»ç£ç›˜ç¼“å­˜åŠ è½½ï¼ˆ{metrics.get('disk_load_time_ms', 0):.0f}msï¼‰")
        else:
            logger.info(f"   ğŸ”„ LLM åˆ†æç”Ÿæˆï¼ˆ{metrics.get('llm_analysis_time_ms', 0):.0f}msï¼‰")
            logger.info(f"   ğŸ’¾ å·²ä¿å­˜åˆ°ç£ç›˜ç¼“å­˜: {cache_dir}")

    # 4. å‡†å¤‡ APIs è¿è¡Œæ—¶å‚æ•°
    if config.apis:
        config.apis = _prepare_apis(config.apis)

    # ğŸ†• V5.1: å‡†å¤‡è¿è¡Œæ—¶ä¸Šä¸‹æ–‡ï¼ˆAPIs + æ¡†æ¶åè®®ï¼‰
    # ä¸å†å°†å®Œæ•´ prompt.md ä¸æ¡†æ¶æç¤ºè¯åˆå¹¶
    # è€Œæ˜¯è®© Agent è¿è¡Œæ—¶æ ¹æ®ä»»åŠ¡å¤æ‚åº¦åŠ¨æ€è·å–ç¼“å­˜ç‰ˆæœ¬
    apis_prompt = _build_apis_prompt_section(config.apis)
    framework_prompt = await get_universal_agent_prompt()

    # å­˜å‚¨è¿è¡Œæ—¶ä¸Šä¸‹æ–‡åˆ° prompt_cacheï¼ˆä¾› Agent åŠ¨æ€è¿½åŠ ï¼‰
    prompt_cache.runtime_context = {
        "apis_prompt": apis_prompt,
        "framework_prompt": framework_prompt,
    }

    # ğŸ†• V5.1: ä»…åœ¨ fallback æ—¶ä½¿ç”¨å®Œæ•´æ‹¼æ¥ç‰ˆæœ¬
    # æ­£å¸¸æµç¨‹ä½¿ç”¨ç¼“å­˜çš„ç²¾ç®€ç‰ˆæœ¬ + è¿è¡Œæ—¶è¿½åŠ 
    fallback_prompt = f"""# å®ä¾‹é…ç½®

{instance_prompt}

---

{apis_prompt}

---

# æ¡†æ¶èƒ½åŠ›åè®®

{framework_prompt}
"""

    logger.info(
        f"   è¿è¡Œæ—¶ä¸Šä¸‹æ–‡: APIs={len(apis_prompt)} å­—ç¬¦, Framework={len(framework_prompt)} å­—ç¬¦"
    )
    logger.info(
        f"   ç¼“å­˜ç‰ˆæœ¬: Simple={len(prompt_cache.system_prompt_simple or '')} å­—ç¬¦, "
        f"Medium={len(prompt_cache.system_prompt_medium or '')} å­—ç¬¦, "
        f"Complex={len(prompt_cache.system_prompt_complex or '')} å­—ç¬¦"
    )

    # 6. åˆ›å»ºäº‹ä»¶ç®¡ç†å™¨ï¼ˆå¦‚æœæœªæä¾›ï¼‰
    if event_manager is None:
        from core.events import create_event_manager, get_memory_storage

        # ä½¿ç”¨å†…å­˜å­˜å‚¨ï¼ˆé€‚åˆå•æœºæµ‹è¯•ï¼‰
        storage = get_memory_storage()
        event_manager = create_event_manager(storage)

    # ä½¿ç”¨ç¼“å­˜çš„ AgentSchema åˆ›å»º Agent
    # ç³»ç»Ÿæç¤ºè¯è¿è¡Œæ—¶æ ¹æ®ä»»åŠ¡å¤æ‚åº¦åŠ¨æ€è·å–
    if prompt_cache.is_loaded and prompt_cache.agent_schema:
        # è·å–åŸºç¡€ Schemaï¼ˆæ¥è‡ª LLM æ¨æ–­ï¼‰
        base_schema = prompt_cache.agent_schema

        # åˆå¹¶ config.yaml é…ç½®åˆ° Schema
        # ç­–ç•¥ï¼šconfig.yaml æ˜¾å¼é…ç½®è¦†ç›– Schemaï¼Œæœªé…ç½®åˆ™ä½¿ç”¨ Schema é»˜è®¤å€¼
        merged_schema = _merge_config_to_schema(base_schema, config)

        # æ›´æ–° prompt_cache ä¸­çš„ agent_schemaï¼ˆä¾›åç»­ä½¿ç”¨ï¼‰
        prompt_cache.agent_schema = merged_schema

        # V11: ç»ˆæ­¢ç­–ç•¥ï¼ˆå§‹ç»ˆå¯ç”¨ adaptiveï¼Œä½¿ç”¨æ¡†æ¶é»˜è®¤å€¼ï¼Œæ— éœ€é…ç½®ï¼‰
        terminator = None
        try:
            from core.termination import AdaptiveTerminator, AdaptiveTerminatorConfig, HITLConfig

            # ä» config è¯»å–è¦†ç›–å€¼ï¼Œæœªé…ç½®åˆ™ä½¿ç”¨é»˜è®¤å€¼
            t = config.termination or {}
            hitl_raw = t.get("hitl", {}) if isinstance(t, dict) else {}

            terminator = AdaptiveTerminator(
                AdaptiveTerminatorConfig(
                    max_turns=t.get("max_turns", 100) if isinstance(t, dict) else 100,
                    max_duration_seconds=t.get("max_duration_seconds", 1800) if isinstance(t, dict) else 1800,
                    idle_timeout_seconds=t.get("idle_timeout_seconds", 120) if isinstance(t, dict) else 120,
                    consecutive_failure_limit=t.get("consecutive_failure_limit", 5) if isinstance(t, dict) else 5,
                    long_running_confirm_after_turns=t.get("long_running_confirm_after_turns", 20) if isinstance(t, dict) else 20,
                    hitl=HITLConfig(
                        enabled=hitl_raw.get("enabled", True),
                        require_confirmation=hitl_raw.get("require_confirmation", [
                            "delete", "overwrite", "send_email", "publish", "payment",
                        ]),
                        on_rejection=hitl_raw.get("on_rejection", "ask_rollback"),
                        show_rollback_on_error=hitl_raw.get("show_rollback_on_error", True),
                    ),
                )
            )
            logger.info("   ç»ˆæ­¢ç­–ç•¥: adaptiveï¼ˆæ¡†æ¶å†…ç½®ï¼Œå§‹ç»ˆå¯ç”¨ï¼‰")
        except ImportError:
            logger.warning("   ç»ˆæ­¢ç­–ç•¥: æœªå®‰è£… core.terminationï¼Œä½¿ç”¨æ¡†æ¶é»˜è®¤")
            terminator = None

        # åˆ›å»º Agentï¼Œä½¿ç”¨åˆå¹¶åçš„ Schema
        # prompt_cache åŒ…å«ï¼š
        # - system_prompt_simple/medium/complexï¼ˆç¼“å­˜ç‰ˆæœ¬ï¼‰
        # - runtime_contextï¼ˆAPIs + framework è¿è¡Œæ—¶è¿½åŠ ï¼‰
        agent = await AgentFactory.from_schema(
            schema=merged_schema,
            system_prompt=None,  # è¿è¡Œæ—¶ä» prompt_cache åŠ¨æ€è·å–
            event_manager=event_manager,
            conversation_service=conversation_service,
            prompt_cache=prompt_cache,
            terminator=terminator,
        )

        # V11: çŠ¶æ€ä¸€è‡´æ€§ï¼ˆä»…å½“å®ä¾‹é…ç½®äº† state_consistency ä¸” enabled ä¸º true æ—¶å¯ç”¨ï¼‰
        try:
            from core.state import (
                ConsistencyCheckConfig,
                RollbackConfig,
                SnapshotConfig,
                StateConsistencyConfig,
                StateConsistencyManager,
            )

            sc_raw = config.state_consistency if isinstance(config.state_consistency, dict) else {}
            enabled = bool(sc_raw and sc_raw.get("enabled", True))
            snap_raw = sc_raw.get("snapshot") if isinstance(sc_raw.get("snapshot"), dict) else {}
            rb_raw = sc_raw.get("rollback") if isinstance(sc_raw.get("rollback"), dict) else {}
            cc_raw = sc_raw.get("consistency_check") if isinstance(sc_raw.get("consistency_check"), dict) else {}

            sc_config = StateConsistencyConfig(
                enabled=bool(enabled),
                snapshot=SnapshotConfig(
                    storage_path=snap_raw.get("storage_path", ""),  # Empty = auto from AGENT_INSTANCE
                    retention_hours=int(snap_raw.get("retention_hours", 24)),
                    max_size_mb=int(snap_raw.get("max_size_mb", 500)),
                    capture_cwd=bool(snap_raw.get("capture_cwd", True)),
                    capture_files=bool(snap_raw.get("capture_files", True)),
                    capture_clipboard=bool(snap_raw.get("capture_clipboard", True)),
                ),
                rollback=RollbackConfig(
                    auto_rollback_on_consecutive_failures=int(
                        rb_raw.get("auto_rollback_on_consecutive_failures", 3)
                    ),
                    auto_rollback_on_critical_error=bool(
                        rb_raw.get("auto_rollback_on_critical_error", True)
                    ),
                    rollback_timeout_seconds=int(rb_raw.get("rollback_timeout_seconds", 60)),
                ),
                consistency_check=ConsistencyCheckConfig(
                    pre_task_disk_space_mb=int(cc_raw.get("pre_task_disk_space_mb", 100)),
                    pre_task_check_permissions=bool(cc_raw.get("pre_task_check_permissions", True)),
                    post_task_check_integrity=bool(cc_raw.get("post_task_check_integrity", True)),
                ),
            )
            agent._state_consistency_manager = StateConsistencyManager(config=sc_config)
            agent._state_consistency_enabled = sc_config.enabled
            if sc_config.enabled:
                logger.info(
                    f"   çŠ¶æ€ä¸€è‡´æ€§: å·²å¯ç”¨ï¼ˆå¿«ç…§={sc_config.snapshot.storage_path}, "
                    f"è‡ªåŠ¨å›æ»š={sc_config.rollback.auto_rollback_on_critical_error}ï¼‰"
                )
            else:
                logger.info("   çŠ¶æ€ä¸€è‡´æ€§: æœªå¯ç”¨")
        except Exception as e:
            logger.warning(f"çŠ¶æ€ä¸€è‡´æ€§åˆå§‹åŒ–å¤±è´¥ï¼ˆä¸é˜»æ–­å¯åŠ¨ï¼‰: {e}", exc_info=True)

        logger.info("âœ… Agent åˆ›å»ºæˆåŠŸï¼ˆä½¿ç”¨åŠ¨æ€æç¤ºè¯è·¯ç”±ï¼‰")
    else:
        # Fallback: å¦‚æœç¼“å­˜åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨å®Œæ•´æ‹¼æ¥ç‰ˆæœ¬
        # æ­¤æ—¶ä½¿ç”¨ DEFAULT_AGENT_SCHEMA ä½œä¸ºå…œåº•
        logger.warning("âš ï¸ InstancePromptCache åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨ fallback å®Œæ•´æç¤ºè¯")

        from core.schemas import DEFAULT_AGENT_SCHEMA

        fallback_schema = _merge_config_to_schema(DEFAULT_AGENT_SCHEMA, config)

        agent = await AgentFactory.from_prompt(
            system_prompt=fallback_prompt,
            event_manager=event_manager,
            conversation_service=conversation_service,
            use_default_if_failed=True,
            cache_dir=str(cache_dir),
            instance_path=str(instance_path),
            force_refresh=force_refresh,
            prompt_schema=prompt_cache.prompt_schema,
        )

    logger.info(f"âœ… Agent åˆ›å»ºæˆåŠŸ")

    # V12: æ³¨å…¥ SkillsLoader + SkillGroupRegistryï¼ˆä¾› tool_provider åŠ¨æ€ç”Ÿæˆ skills_promptï¼‰
    if skills_loader:
        agent._skills_loader = skills_loader
        agent._instance_skills = []  # æ–°æ ¼å¼ç”± skills_loader ç®¡ç†

        # æ„å»º SkillGroupRegistryï¼ˆå•ä¸€æ•°æ®æºï¼‰
        from core.skill.group_registry import SkillGroupRegistry

        skill_groups_cfg = (config.raw_config or {}).get("skill_groups", {})
        group_registry = SkillGroupRegistry(skill_groups_cfg)

        # å¯åŠ¨æ—¶æ ¡éªŒï¼šæ£€æµ‹æœªå½’å…¥ä»»ä½•åˆ†ç»„çš„ skill
        all_non_system = {
            e.name for e in skills_loader.get_enabled_skills()
            if e.backend_type.value != "tool"
            and not (e.raw_config or {}).get("system", False)
        }
        group_registry.validate_and_warn(all_non_system)

        # æ„å»º Skills æç¤ºè¯å¹¶æ³¨å…¥åˆ°è¿è¡Œæ—¶ä¸Šä¸‹æ–‡
        skills_prompt = await skills_loader.build_skills_prompt()
        if skills_prompt and hasattr(prompt_cache, "runtime_context") and prompt_cache.runtime_context:
            prompt_cache.runtime_context["skills_prompt"] = skills_prompt
            logger.info(f"   Skills æç¤ºè¯: {len(skills_prompt)} å­—ç¬¦å·²æ³¨å…¥ï¼ˆFallback ç”¨ï¼‰")

            # V12: æ³¨å…¥ loader å¼•ç”¨å’Œ group_registry
            prompt_cache.runtime_context["_skills_loader"] = skills_loader
            prompt_cache.runtime_context["_skill_group_registry"] = group_registry
            logger.info(
                f"   SkillGroupRegistry å·²æ³¨å…¥: {group_registry}"
            )
    elif config.skills:
        # æ—§æ ¼å¼å…¼å®¹
        agent._skills_loader = None
        agent._instance_skills = config.skills
        enabled_instance_skills = [s for s in config.skills if s.enabled]
        if enabled_instance_skills:
            logger.info(f"   æ³¨å…¥å®ä¾‹çº§ Skills: {len(enabled_instance_skills)} ä¸ªå·²å¯ç”¨")
            for skill in enabled_instance_skills:
                logger.debug(f"      â€¢ {skill.name}")
    else:
        agent._skills_loader = None
        agent._instance_skills = []

    # 9. ğŸ†• åˆ›å»ºå®ä¾‹çº§å·¥å…·æ³¨å†Œè¡¨
    from core.tool import InstanceRegistry, create_tool_loader, get_capability_registry

    global_registry = get_capability_registry()

    # ğŸ†• V5.1: ä½¿ç”¨ ToolLoader ç»Ÿä¸€åŠ è½½å·¥å…·
    tool_loader = create_tool_loader(global_registry)

    # åŠ è½½æ‰€æœ‰å·¥å…·ï¼ˆé€šç”¨å·¥å…·ã€Claude Skillsï¼‰ï¼ˆå¼‚æ­¥ï¼‰
    load_result = await tool_loader.load_tools(
        enabled_capabilities=config.enabled_capabilities,
        skills=config.skills,
    )

    # åˆ›å»ºè¿‡æ»¤åçš„æ³¨å†Œè¡¨
    filtered_registry = tool_loader.create_filtered_registry(config.enabled_capabilities)

    # ä½¿ç”¨è¿‡æ»¤åçš„ registry åˆ›å»ºå®ä¾‹çº§æ³¨å†Œè¡¨
    instance_registry = InstanceRegistry(global_registry=filtered_registry)
    agent._instance_registry = instance_registry  # æ³¨å…¥åˆ° Agent

    # ğŸ”§ FIX: æ›´æ–° capability_registryã€tool_executorã€tool_selector ä½¿ç”¨ filtered_registry
    # åŸé—®é¢˜ï¼štool_executor ä½¿ç”¨å…¨å±€ Registryï¼Œå¯¼è‡´è¢«è¿‡æ»¤æ‰çš„å·¥å…·ï¼ˆå¦‚ hitlï¼‰æ‰¾ä¸åˆ°
    # ä¿®å¤ï¼šé‡æ–°åˆ›å»º tool_executor å’Œ tool_selectorï¼Œä½¿ç”¨ filtered_registry
    from core.tool import create_tool_executor, create_tool_selector
    from core.tool.types import create_tool_context

    agent.capability_registry = filtered_registry

    # é‡æ–°åˆ›å»º tool_executor
    agent._tool_executor = create_tool_executor(
        registry=filtered_registry,
        tool_context=create_tool_context(
            event_manager=agent.event_manager, apis_config=getattr(agent, "apis_config", None)
        ),
        enable_compaction=(
            getattr(agent._tool_executor, "enable_compaction", True)
            if agent._tool_executor
            else True
        ),
    )

    # é‡æ–°åˆ›å»º tool_selectorï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if hasattr(agent, "tool_selector") and agent.tool_selector is not None:
        agent.tool_selector = create_tool_selector(registry=filtered_registry)

    logger.info(
        f"   âœ… ToolExecutor/ToolSelector å·²æ›´æ–°ï¼Œä½¿ç”¨è¿‡æ»¤åçš„ Registry ({len(filtered_registry.capabilities)} ä¸ªå·¥å…·)"
    )

    # ğŸ†• V4.6: åŠ è½½å·¥å…·æ¨æ–­ç¼“å­˜ï¼ˆç”¨äºå¢é‡æ¨æ–­ï¼‰
    tools_cache_file = cache_dir / "tools_inference.json"
    if tools_cache_file.exists() and not force_refresh:
        await instance_registry.load_inference_cache(tools_cache_file)
        logger.info("âœ… å·²åŠ è½½å·¥å…·æ¨æ–­ç¼“å­˜")

    # 10. æ³¨å†Œ Claude Skillsï¼ˆå¦‚æœé…ç½®äº†ï¼‰
    if not skip_skills_registration and config.skills:
        enabled_skills = [s for s in config.skills if s.enabled]
        if enabled_skills:
            # TODO: _register_skills å‡½æ•°æœªå®ç°ï¼Œéœ€è¦è¡¥å……
            logger.warning(
                f"âš ï¸ Claude Skills æ³¨å†ŒåŠŸèƒ½æœªå®ç°: {[s.skill_name for s in enabled_skills]}"
            )

    # ğŸ†• V4.6: ä¿å­˜å·¥å…·æ¨æ–­ç¼“å­˜ï¼ˆåŒ…å«æ–°æ¨æ–­çš„å·¥å…·ï¼‰
    cache_dir.mkdir(parents=True, exist_ok=True)
    await instance_registry.save_inference_cache(tools_cache_file)
    logger.info("âœ… å·²ä¿å­˜å·¥å…·æ¨æ–­ç¼“å­˜")

    # 11. ç»Ÿä¸€å·¥å…·ç»Ÿè®¡ï¼ˆä»…ç”¨äºè°ƒè¯•æ—¥å¿—ï¼‰
    # æ³¨æ„ï¼šPlan é˜¶æ®µåªä½¿ç”¨ capability_categoriesï¼Œä¸ä½¿ç”¨å…·ä½“å·¥å…·åˆ—è¡¨
    all_tools = instance_registry.get_all_tools_unified()
    logger.info(f"ğŸ“‹ å·¥å…·ç»Ÿè®¡: {len(all_tools)} ä¸ªï¼ˆå…¨å±€+å®ä¾‹ï¼‰ï¼Œä»…ä¾›è°ƒè¯•")
    logger.debug(f"   å·¥å…·åˆ—è¡¨: {[t['name'] for t in all_tools]}")

    logger.info(f"ğŸ‰ å®ä¾‹ {instance_name} åŠ è½½å®Œæˆ")

    return agent


async def validate_skill_directory(skill_path: Path) -> Dict[str, Any]:
    """
    éªŒè¯ Skill ç›®å½•ç»“æ„

    å‚è€ƒå®˜æ–¹æ–‡æ¡£ï¼šhttps://platform.claude.com/docs/en/agents-and-tools/agent-skills/best-practices

    æ£€æŸ¥é¡¹ï¼š
    - SKILL.md å­˜åœ¨
    - YAML frontmatter æ ¼å¼æ­£ç¡®
    - name å­—æ®µï¼šæœ€å¤§ 64 å­—ç¬¦ï¼Œåªèƒ½åŒ…å«å°å†™å­—æ¯ã€æ•°å­—å’Œè¿å­—ç¬¦ï¼Œä¸èƒ½åŒ…å«ä¿ç•™è¯
    - description å­—æ®µï¼šå¿…é¡»éç©ºï¼Œæœ€å¤§ 1024 å­—ç¬¦ï¼Œä¸èƒ½åŒ…å« XML æ ‡ç­¾
    - æ€»å¤§å°ä¸è¶…è¿‡ 8MB
    - SKILL.md æ­£æ–‡æ¨èä¸è¶…è¿‡ 500 è¡Œ

    Args:
        skill_path: Skill ç›®å½•è·¯å¾„

    Returns:
        éªŒè¯ç»“æœå­—å…¸ï¼š
        {
            "valid": bool,
            "errors": List[str],
            "warnings": List[str],
            "info": Dict[str, Any]
        }
    """
    import re

    import yaml

    result = {"valid": True, "errors": [], "warnings": [], "info": {}}

    # ä¿ç•™è¯ï¼ˆä¸èƒ½ç”¨äº nameï¼‰
    RESERVED_WORDS = ["anthropic", "claude"]

    # æ£€æŸ¥ç›®å½•å­˜åœ¨
    if not skill_path.exists():
        result["valid"] = False
        result["errors"].append(f"ç›®å½•ä¸å­˜åœ¨: {skill_path}")
        return result

    # æ£€æŸ¥ SKILL.md å­˜åœ¨
    skill_md = skill_path / "SKILL.md"
    if not skill_md.exists():
        result["valid"] = False
        result["errors"].append("SKILL.md æ–‡ä»¶ä¸å­˜åœ¨")
        return result

    # è¯»å–å¹¶éªŒè¯ SKILL.md
    async with aiofiles.open(skill_md, "r", encoding="utf-8") as f:
        content = await f.read()

    # æ£€æŸ¥ YAML frontmatter æ ¼å¼
    if not content.startswith("---"):
        result["valid"] = False
        result["errors"].append("SKILL.md å¿…é¡»ä»¥ YAML frontmatter (---) å¼€å¤´")
    else:
        try:
            # æå– frontmatter
            end_idx = content.index("---", 3)
            frontmatter_str = content[3:end_idx].strip()
            body_content = content[end_idx + 3 :].strip()

            # è§£æ YAML
            try:
                frontmatter = yaml.safe_load(frontmatter_str) or {}
            except yaml.YAMLError as e:
                result["valid"] = False
                result["errors"].append(f"YAML è§£æé”™è¯¯: {str(e)}")
                frontmatter = {}

            # ===== name å­—æ®µéªŒè¯ï¼ˆå®˜æ–¹æ–‡æ¡£è¦æ±‚ï¼‰=====
            name = frontmatter.get("name", "")

            if not name:
                result["valid"] = False
                result["errors"].append("YAML frontmatter ç¼ºå°‘ 'name' å­—æ®µ")
            else:
                # æœ€å¤§ 64 å­—ç¬¦
                if len(name) > 64:
                    result["valid"] = False
                    result["errors"].append(f"name è¶…è¿‡ 64 å­—ç¬¦ (å½“å‰: {len(name)})")

                # åªèƒ½åŒ…å«å°å†™å­—æ¯ã€æ•°å­—å’Œè¿å­—ç¬¦
                if not re.match(r"^[a-z0-9-]+$", name):
                    result["valid"] = False
                    result["errors"].append(f"name åªèƒ½åŒ…å«å°å†™å­—æ¯ã€æ•°å­—å’Œè¿å­—ç¬¦: '{name}'")

                # ä¸èƒ½åŒ…å« XML æ ‡ç­¾
                if re.search(r"<[^>]+>", name):
                    result["valid"] = False
                    result["errors"].append("name ä¸èƒ½åŒ…å« XML æ ‡ç­¾")

                # ä¸èƒ½åŒ…å«ä¿ç•™è¯
                for reserved in RESERVED_WORDS:
                    if reserved in name.lower():
                        result["valid"] = False
                        result["errors"].append(f"name ä¸èƒ½åŒ…å«ä¿ç•™è¯ '{reserved}'")

            result["info"]["name"] = name

            # ===== description å­—æ®µéªŒè¯ï¼ˆå®˜æ–¹æ–‡æ¡£è¦æ±‚ï¼‰=====
            description = frontmatter.get("description") or ""

            # ç¡®ä¿æ˜¯å­—ç¬¦ä¸²ç±»å‹
            if not isinstance(description, str):
                description = str(description) if description else ""

            if not description.strip():
                result["valid"] = False
                result["errors"].append("YAML frontmatter ç¼ºå°‘ 'description' å­—æ®µæˆ–ä¸ºç©º")
            else:
                # æœ€å¤§ 1024 å­—ç¬¦
                if len(description) > 1024:
                    result["valid"] = False
                    result["errors"].append(
                        f"description è¶…è¿‡ 1024 å­—ç¬¦ (å½“å‰: {len(description)})"
                    )

                # ä¸èƒ½åŒ…å« XML æ ‡ç­¾
                if re.search(r"<[^>]+>", description):
                    result["valid"] = False
                    result["errors"].append("description ä¸èƒ½åŒ…å« XML æ ‡ç­¾")

            result["info"]["description"] = (
                (description[:100] + "...")
                if description and len(description) > 100
                else description
            )
            result["info"]["frontmatter_size"] = len(frontmatter_str)

            # ===== SKILL.md æ­£æ–‡è¡Œæ•°æ£€æŸ¥ï¼ˆå®˜æ–¹æ¨èï¼‰=====
            body_lines = len(body_content.split("\n"))
            result["info"]["body_lines"] = body_lines

            if body_lines > 500:
                result["warnings"].append(
                    f"SKILL.md æ­£æ–‡è¶…è¿‡ 500 è¡Œ (å½“å‰: {body_lines})ï¼Œå»ºè®®æ‹†åˆ†åˆ°å•ç‹¬æ–‡ä»¶"
                )

        except ValueError:
            result["valid"] = False
            result["errors"].append("YAML frontmatter æ ¼å¼æ— æ•ˆï¼ˆç¼ºå°‘ç»“æŸ ---ï¼‰")

    # æ£€æŸ¥æ€»å¤§å°ï¼ˆ8MB é™åˆ¶ï¼‰
    total_size = sum(f.stat().st_size for f in skill_path.rglob("*") if f.is_file())
    result["info"]["total_size_mb"] = total_size / (1024 * 1024)

    if total_size > 8 * 1024 * 1024:
        result["valid"] = False
        result["errors"].append(f"æ€»å¤§å°è¶…è¿‡ 8MB (å½“å‰: {total_size / (1024 * 1024):.2f} MB)")

    # ç»Ÿè®¡æ–‡ä»¶ä¿¡æ¯
    files = list(skill_path.rglob("*"))
    result["info"]["file_count"] = len([f for f in files if f.is_file()])
    result["info"]["has_scripts"] = (skill_path / "scripts").exists()
    result["info"]["has_reference"] = (skill_path / "REFERENCE.md").exists()

    return result


async def _update_skill_registry(instance_name: str, skills: List[SkillConfig]) -> None:
    """
    æ›´æ–° skill_registry.yaml

    Args:
        instance_name: å®ä¾‹åç§°
        skills: æ›´æ–°åçš„ Skill é…ç½®åˆ—è¡¨
    """
    import yaml

    registry_path = get_instances_dir() / instance_name / "skills" / "skill_registry.yaml"

    if not registry_path.exists():
        return

    async with aiofiles.open(registry_path, "r", encoding="utf-8") as f:
        content = await f.read()
        registry = yaml.safe_load(content) or {}

    # æ›´æ–° skills åˆ—è¡¨
    skills_data = []
    for skill in skills:
        skill_dict = {
            "name": skill.name,
            "enabled": skill.enabled,
            "description": skill.description,
        }
        skills_data.append(skill_dict)

    registry["skills"] = skills_data

    # å¼‚æ­¥å†™å›æ–‡ä»¶
    output = yaml.dump(registry, default_flow_style=False, allow_unicode=True, sort_keys=False)
    async with aiofiles.open(registry_path, "w", encoding="utf-8") as f:
        await f.write(output)


# ============================================================
# Skills ç®¡ç†åŠŸèƒ½
# ============================================================


async def scan_skills_directory(instance_name: str) -> List[SkillConfig]:
    """
    æ‰«æå®ä¾‹ç›®å½•ä¸­çš„æ‰€æœ‰ Skills

    Args:
        instance_name: å®ä¾‹åç§°

    Returns:
        SkillConfig åˆ—è¡¨
    """
    import yaml

    skills_dir = get_instances_dir() / instance_name / "skills"

    if not skills_dir.exists():
        return []

    # åŠ è½½ç°æœ‰æ³¨å†Œè¡¨
    registry_path = skills_dir / "skill_registry.yaml"
    registered_skills = {}
    if registry_path.exists():
        async with aiofiles.open(registry_path, "r", encoding="utf-8") as f:
            content = await f.read()
            registry = yaml.safe_load(content) or {}
        for s in registry.get("skills", []):
            if isinstance(s, dict):
                registered_skills[s.get("name")] = s

    skills = []

    # æ‰«æ skills ç›®å½•
    for skill_dir in skills_dir.iterdir():
        if not skill_dir.is_dir():
            continue

        # è·³è¿‡ç‰¹æ®Šç›®å½•
        if skill_dir.name.startswith("_") or skill_dir.name == "__pycache__":
            continue

        # æ£€æŸ¥ SKILL.md æ˜¯å¦å­˜åœ¨
        skill_md = skill_dir / "SKILL.md"
        if not skill_md.exists():
            continue

        # è·å–å·²æ³¨å†Œä¿¡æ¯
        registered_info = registered_skills.get(skill_dir.name, {})

        # ä» SKILL.md æå–æè¿°
        description = registered_info.get("description", "")
        if not description:
            try:
                async with aiofiles.open(skill_md, "r", encoding="utf-8") as f:
                    content = await f.read()
                if content.startswith("---"):
                    end_idx = content.index("---", 3)
                    frontmatter = content[3:end_idx].strip()
                    metadata = yaml.safe_load(frontmatter)
                    description = metadata.get("description", skill_dir.name)
            except (FileNotFoundError, ValueError, yaml.YAMLError) as e:
                logger.debug(f"æ— æ³•è¯»å– skill å…ƒæ•°æ®: {e}")
                description = skill_dir.name

        skills.append(
            SkillConfig(
                name=skill_dir.name,
                enabled=registered_info.get("enabled", True),
                description=description,
                skill_path=skill_dir,
            )
        )

    return skills


async def get_skills_status(instance_name: Optional[str] = None) -> Dict[str, List[Dict[str, Any]]]:
    """
    è·å– Skills çŠ¶æ€

    Args:
        instance_name: å®ä¾‹åç§°ï¼ˆNone åˆ™è·å–æ‰€æœ‰å®ä¾‹ï¼‰

    Returns:
        {instance_name: [{"name": ..., "enabled": ..., "status": ...}, ...]}
    """
    status = {}

    instances = [instance_name] if instance_name else list_instances()

    for inst in instances:
        skills = await scan_skills_directory(inst)
        inst_status = []

        for skill in skills:
            skill_status = "enabled" if skill.enabled else "disabled"

            inst_status.append(
                {
                    "name": skill.name,
                    "enabled": skill.enabled,
                    "description": skill.description,
                    "status": skill_status,
                }
            )

        status[inst] = inst_status

    return status


async def print_skills_status(instance_name: Optional[str] = None):
    """æ‰“å° Skills çŠ¶æ€"""
    print("\nğŸ“‹ Skills çŠ¶æ€æ€»è§ˆ")
    print("=" * 70)

    status = await get_skills_status(instance_name)

    if not status:
        print("  æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å®ä¾‹")
        return

    total_skills = 0

    for inst_name, skills in status.items():
        print(f"\nğŸ“¦ å®ä¾‹: {inst_name}")
        print("-" * 50)

        if not skills:
            print("  (æ—  Skills)")
            continue

        for skill in skills:
            total_skills += 1

            if skill["status"] == "enabled":
                icon = "âœ…"
                text = "å·²å¯ç”¨"
            else:
                icon = "â¸ï¸"
                text = "å·²ç¦ç”¨"

            desc = (
                skill["description"][:40] + "..."
                if len(skill["description"]) > 40
                else skill["description"]
            )
            print(f"  {icon} {skill['name']}")
            print(f"     æè¿°: {desc}")
            print(f"     çŠ¶æ€: {text}")

    print("\n" + "=" * 70)
    print(f"ğŸ“Š æ€»è®¡: {total_skills} ä¸ª Skills")


# ============================================================
# ä¾¿æ·å‡½æ•°
# ============================================================


async def quick_load(instance_name: str):
    """
    å¿«é€ŸåŠ è½½å®ä¾‹ï¼ˆä¾¿æ·å‡½æ•°ï¼‰

    Args:
        instance_name: å®ä¾‹åç§°

    Returns:
        Agent å®ä¾‹
    """
    return await create_agent_from_instance(instance_name)


def print_available_instances():
    """æ‰“å°æ‰€æœ‰å¯ç”¨å®ä¾‹"""
    instances = list_instances()

    if not instances:
        print("ğŸ“­ æ²¡æœ‰å¯ç”¨çš„å®ä¾‹")
        print(f"   è¯·åœ¨ {get_instances_dir()} ç›®å½•ä¸‹åˆ›å»ºå®ä¾‹")
        return

    print(f"ğŸ“¦ å¯ç”¨å®ä¾‹ ({len(instances)} ä¸ª):")
    for name in instances:
        try:
            config = asyncio.run(load_instance_config(name))
            print(f"   â€¢ {name}: {config.description or '(æ— æè¿°)'}")
        except Exception as e:
            print(f"   â€¢ {name}: âš ï¸ é…ç½®åŠ è½½å¤±è´¥ ({str(e)})")


# ============================================================
# CLI å…¥å£
# ============================================================

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(
        description="æ™ºèƒ½ä½“å®ä¾‹åŠ è½½å™¨ & Skills ç®¡ç†å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # å®ä¾‹ç®¡ç†
  python utils/instance_loader.py --list                     # åˆ—å‡ºæ‰€æœ‰å®ä¾‹
  python utils/instance_loader.py -i dazee_agent --info      # æ˜¾ç¤ºå®ä¾‹è¯¦æƒ…
  
  # Skills ç®¡ç†
  python utils/instance_loader.py --skills-status            # æŸ¥çœ‹æ‰€æœ‰å®ä¾‹çš„ Skills çŠ¶æ€
  python utils/instance_loader.py -i dazee_agent --skills-status  # æŸ¥çœ‹æŒ‡å®šå®ä¾‹
        """,
    )

    # å®ä¾‹ç›¸å…³å‚æ•°
    parser.add_argument("--list", "-l", action="store_true", help="åˆ—å‡ºæ‰€æœ‰å¯ç”¨å®ä¾‹")
    parser.add_argument("--instance", "-i", type=str, help="æŒ‡å®šå®ä¾‹åç§°")
    parser.add_argument("--info", action="store_true", help="æ˜¾ç¤ºå®ä¾‹è¯¦ç»†ä¿¡æ¯")

    # Skills ç®¡ç†å‚æ•°
    parser.add_argument("--skills-status", action="store_true", help="æ˜¾ç¤º Skills çŠ¶æ€")

    args = parser.parse_args()

    try:
        # ==================== å®ä¾‹ç®¡ç† ====================
        if args.list:
            print_available_instances()

        # ==================== Skills çŠ¶æ€ ====================
        elif args.skills_status:
            print_skills_status(args.instance)

        # ==================== æ˜¾ç¤ºå®ä¾‹ä¿¡æ¯ ====================
        elif args.instance and args.info:
            config = asyncio.run(load_instance_config(args.instance))
            print(f"ğŸ“‹ å®ä¾‹ä¿¡æ¯: {args.instance}")
            print(f"   åç§°: {config.name}")
            print(f"   æè¿°: {config.description}")
            print(f"   ç‰ˆæœ¬: {config.version}")
            print(f"   æ¨¡å‹: {config.model or 'é»˜è®¤'}")
            print(f"   Mem0: {'å¯ç”¨' if config.mem0_enabled else 'ç¦ç”¨'}")

            # LLM è¶…å‚æ•°
            llm = config.llm_params
            llm_info = []
            if llm.temperature is not None:
                llm_info.append(f"temperature={llm.temperature}")
            if llm.max_tokens is not None:
                llm_info.append(f"max_tokens={llm.max_tokens}")
            if llm.enable_thinking is not None:
                llm_info.append(f"thinking={'å¼€' if llm.enable_thinking else 'å…³'}")
            if llm.thinking_mode is not None:
                llm_info.append(f"thinking_mode={llm.thinking_mode}")
            if llm.enable_caching is not None:
                llm_info.append(f"caching={'å¼€' if llm.enable_caching else 'å…³'}")

            if llm_info:
                print(f"   LLM å‚æ•°: {', '.join(llm_info)}")

            # Skills ä¿¡æ¯ï¼ˆæœ¬åœ° Skill ç³»ç»Ÿï¼‰
            enabled_skills = [s for s in config.skills if s.enabled]
            print(f"   Skills: {len(config.skills)} ä¸ª ({len(enabled_skills)} å¯ç”¨)")
            for skill in config.skills:
                status = "âœ…" if skill.enabled else "â¬œ"
                print(f"      {status} {skill.name}")

            # APIs ä¿¡æ¯ï¼ˆREST API æè¿°ï¼‰
            print(f"   APIs: {len(config.apis)} ä¸ª")
            for api in config.apis:
                doc_status = f"æ–‡æ¡£: {api.doc}" if api.doc else "æ— æ–‡æ¡£"
                print(f"      â€¢ {api.name}: {api.base_url} ({doc_status})")

        else:
            parser.print_help()

    except Exception as e:
        print(f"âŒ é”™è¯¯: {str(e)}")
        import traceback

        traceback.print_exc()
        exit(1)
