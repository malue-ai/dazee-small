"""
æ¨èé—®é¢˜ç”Ÿæˆä»»åŠ¡ - ç”Ÿæˆç”¨æˆ·å¯èƒ½æ„Ÿå…´è¶£çš„åç»­é—®é¢˜

è§¦å‘æ¡ä»¶ï¼š
- æœ‰ç”¨æˆ·æ¶ˆæ¯
- æœ‰åŠ©æ‰‹å›å¤

å®ç°ï¼š
- ä½¿ç”¨ LLM ç”Ÿæˆé—®é¢˜
- JSON è§£æå’Œå›é€€æ–¹æ¡ˆ
- é€šè¿‡ SSE æ¨é€ç»™å‰ç«¯
"""

import json
import re
from typing import TYPE_CHECKING, List, Optional

from logger import get_logger
from utils.json_utils import extract_json_list

from ..registry import background_task

if TYPE_CHECKING:
    from ..context import TaskContext
    from ..service import BackgroundTaskService

from core.llm.base import Message

logger = get_logger("background_tasks.recommended_questions")


@background_task("recommended_questions")
async def generate_recommended_questions_task(
    ctx: "TaskContext", service: "BackgroundTaskService"
) -> None:
    """
    æ¨èé—®é¢˜ç”Ÿæˆä»»åŠ¡

    æ ¹æ®å¯¹è¯å†…å®¹ç”Ÿæˆç”¨æˆ·å¯èƒ½æ„Ÿå…´è¶£çš„åç»­é—®é¢˜
    """
    if not ctx.user_message or not ctx.assistant_response:
        logger.debug("â—‹ è·³è¿‡æ¨èé—®é¢˜ç”Ÿæˆï¼ˆç¼ºå°‘ç”¨æˆ·æ¶ˆæ¯æˆ–åŠ©æ‰‹å›å¤ï¼‰")
        return

    await _generate_recommended_questions(
        session_id=ctx.session_id,
        conversation_id=ctx.conversation_id,
        message_id=ctx.message_id,
        user_message=ctx.user_message,
        assistant_response=ctx.assistant_response,
        event_manager=ctx.event_manager,
        service=service,
    )


async def _generate_recommended_questions(
    session_id: str,
    conversation_id: str,
    message_id: str,
    user_message: str,
    assistant_response: str,
    event_manager,
    service: "BackgroundTaskService",
) -> Optional[List[str]]:
    """
    ç”Ÿæˆæ¨èé—®é¢˜ï¼ˆåå°ä»»åŠ¡ï¼‰

    æ ¹æ®å¯¹è¯å†…å®¹ç”Ÿæˆç”¨æˆ·å¯èƒ½æ„Ÿå…´è¶£çš„åç»­é—®é¢˜ï¼Œ
    é€šè¿‡ SSE æ¨é€åˆ°å‰ç«¯æ˜¾ç¤ºåœ¨æ¶ˆæ¯åº•éƒ¨
    """
    try:
        logger.info(f"ğŸ’¡ å¼€å§‹ç”Ÿæˆæ¨èé—®é¢˜: session_id={session_id}, message_id={message_id}")

        # 1. æˆªå–å†…å®¹ï¼ˆé¿å…è¿‡é•¿ï¼‰
        user_preview = user_message[:300] if len(user_message) > 300 else user_message
        assistant_preview = (
            assistant_response[:500] if len(assistant_response) > 500 else assistant_response
        )

        # 2. ä½¿ç”¨ LLM ç”Ÿæˆæ¨èé—®é¢˜
        questions = await _generate_questions_with_llm(user_preview, assistant_preview, service)

        if not questions:
            logger.warning("âš ï¸ LLM è¿”å›ç©ºçš„æ¨èé—®é¢˜")
            return None

        logger.info(f"âœ… æ¨èé—®é¢˜å·²ç”Ÿæˆ: {len(questions)} ä¸ª")

        # 3. é€šè¿‡ SSE æ¨é€ç»™å‰ç«¯
        if session_id and event_manager:
            # ğŸ†• ä½¿ç”¨ event_manager å·²é…ç½®çš„ output_format å’Œ adapter
            await event_manager.message.emit_message_delta(
                session_id=session_id,
                conversation_id=conversation_id,
                delta={"type": "recommended", "content": {"questions": questions}},
                message_id=message_id,
                output_format=getattr(event_manager, "output_format", "zenflux"),
                adapter=getattr(event_manager, "adapter", None),
            )
            logger.info(f"ğŸ“¤ æ¨èé—®é¢˜å·²æ¨é€åˆ°å‰ç«¯")

        return questions

    except Exception as e:
        logger.warning(f"âš ï¸ ç”Ÿæˆæ¨èé—®é¢˜å¤±è´¥: {str(e)}")
        return None


async def _generate_questions_with_llm(
    user_message: str, assistant_response: str, service: "BackgroundTaskService"
) -> Optional[List[str]]:
    """ä½¿ç”¨ LLM ç”Ÿæˆæ¨èé—®é¢˜"""
    try:
        llm = await service.get_llm()

        prompt = service.recommended_questions_prompt.format(
            user_message=user_message, assistant_response=assistant_response
        )

        response = await llm.create_message_async(
            messages=[Message(role="user", content=prompt)],
        )

        if response and hasattr(response, "content") and response.content:
            content = response.content

            # æå–åŸå§‹æ–‡æœ¬ï¼šæ”¯æŒå­—ç¬¦ä¸²æˆ– TextBlock åˆ—è¡¨
            raw_text = None
            if isinstance(content, str):
                # content ç›´æ¥æ˜¯å­—ç¬¦ä¸²
                raw_text = content.strip()
            elif isinstance(content, list):
                # content æ˜¯ TextBlock åˆ—è¡¨
                for block in content:
                    if hasattr(block, "text"):
                        raw_text = block.text.strip()
                        break

            if raw_text:
                logger.debug(f"ğŸ“ LLM åŸå§‹è¿”å›: {raw_text[:300]}...")

                # ä½¿ç”¨ JSON æå–å™¨
                questions = extract_json_list(raw_text, key="questions")
                logger.debug(f"ğŸ“‹ JSON æå–ç»“æœ: {questions}")

                if questions:
                    cleaned = []
                    for q in questions[:3]:
                        q = q.strip().strip("\"'ã€Œã€ã€ã€,")

                        # è¿‡æ»¤æ‰æ˜æ˜¾ä¸æ˜¯é—®é¢˜çš„å†…å®¹ï¼ˆmarkdown/JSON è¯­æ³•ï¼‰
                        if _is_invalid_question(q):
                            logger.debug(f"âš ï¸ è·³è¿‡æ— æ•ˆé—®é¢˜: {q}")
                            continue

                        if len(q) > 30:
                            q = q[:27] + "..."
                        if q and len(q) >= 5:
                            cleaned.append(q)

                    if cleaned:
                        return cleaned

                # JSON æå–å¤±è´¥æˆ–ç»“æœæ— æ•ˆï¼Œå›é€€åˆ°é€è¡Œè§£æ
                logger.debug("JSON æå–å¤±è´¥æˆ–ç»“æœæ— æ•ˆï¼Œå›é€€åˆ°é€è¡Œè§£æ")
                return _parse_questions_fallback(raw_text)

        return None

    except Exception as e:
        logger.error(f"âŒ LLM ç”Ÿæˆæ¨èé—®é¢˜å¤±è´¥: {str(e)}", exc_info=True)
        return None


def _is_invalid_question(text: str) -> bool:
    """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦æ˜¯æ— æ•ˆçš„é—®é¢˜ï¼ˆmarkdown/JSON è¯­æ³•ç­‰ï¼‰"""
    if not text:
        return True

    # æ— æ•ˆæ¨¡å¼
    invalid_patterns = [
        r"^```",  # markdown ä»£ç å—
        r'^"?questions"?\s*:',  # JSON key
        r"^\[",  # JSON æ•°ç»„
        r"^\]",
        r"^\{",  # JSON å¯¹è±¡
        r"^\}",
        r"^json$",  # å•ç‹¬çš„ json æ ‡è®°
    ]

    for pattern in invalid_patterns:
        if re.match(pattern, text, re.IGNORECASE):
            return True

    return False


def _parse_questions_fallback(raw_text: str) -> List[str]:
    """å›é€€æ–¹æ¡ˆï¼šé€è¡Œè§£æ LLM è¿”å›çš„é—®é¢˜æ–‡æœ¬"""
    questions = []

    # éœ€è¦è·³è¿‡çš„æ¨¡å¼ï¼ˆmarkdown ä»£ç å—ã€JSON è¯­æ³•ç­‰ï¼‰
    skip_patterns = [
        r"^```",  # markdown ä»£ç å—æ ‡è®°
        r'^"?questions"?\s*:',  # JSON key
        r"^\[",  # JSON æ•°ç»„å¼€å§‹
        r"^\]",  # JSON æ•°ç»„ç»“æŸ
        r"^\{",  # JSON å¯¹è±¡å¼€å§‹
        r"^\}",  # JSON å¯¹è±¡ç»“æŸ
    ]

    for line in raw_text.split("\n"):
        line = line.strip()

        if not line:
            continue

        # è·³è¿‡ markdown å’Œ JSON è¯­æ³•
        should_skip = False
        for pattern in skip_patterns:
            if re.match(pattern, line, re.IGNORECASE):
                should_skip = True
                break
        if should_skip:
            continue

        line = re.sub(r"^[\d]+[.ã€)\]]\s*", "", line)
        line = re.sub(r"^[-â€¢Â·]\s*", "", line)
        line = line.strip().strip("\"'ã€Œã€ã€ã€,")  # ä¹Ÿå»æ‰å°¾éƒ¨é€—å·

        # è¿‡æ»¤æ‰å¤ªçŸ­æˆ–åŒ…å« JSON è¯­æ³•çš„å†…å®¹
        if len(line) < 5:
            continue

        if len(line) > 30:
            line = line[:27] + "..."

        if line:
            questions.append(line)

    return questions[:3]
