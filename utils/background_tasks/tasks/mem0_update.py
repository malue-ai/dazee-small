"""
Mem0 è®°å¿†æ›´æ–°ä»»åŠ¡ - æ›´æ–°ç”¨æˆ·çš„é•¿æœŸè®°å¿†

è§¦å‘æ¡ä»¶ï¼š
- æœ‰ç”¨æˆ· ID

å®žçŽ°ï¼š
- å•ç”¨æˆ·è®°å¿†æ›´æ–°
- æ‰¹é‡æ›´æ–°ï¼ˆå®šæ—¶ä»»åŠ¡ç”¨ï¼‰
- æ•°æ®åº“æŸ¥è¯¢
- æƒ…ç»ªèšåˆ
"""

import asyncio
import json
from datetime import datetime, timedelta
from typing import TYPE_CHECKING, Any, Dict, List, Optional

from logger import get_logger

from ..context import Mem0BatchUpdateResult, Mem0UpdateResult
from ..registry import background_task

if TYPE_CHECKING:
    from ..context import TaskContext
    from ..service import BackgroundTaskService

logger = get_logger("background_tasks.mem0_update")


@background_task("mem0_update")
async def update_mem0_memories_task(ctx: "TaskContext", service: "BackgroundTaskService") -> None:
    """
    Mem0 è®°å¿†æ›´æ–°ä»»åŠ¡

    æ›´æ–°ç”¨æˆ·åœ¨æœ€è¿‘ä¸€æ®µæ—¶é—´å†…çš„ä¼šè¯è®°å¿†
    """
    if not ctx.user_id:
        logger.debug("â—‹ è·³è¿‡ Mem0 æ›´æ–°ï¼ˆæ— ç”¨æˆ· IDï¼‰")
        return

    await update_user_memories(
        user_id=ctx.user_id,
        since_hours=24,
        session_id=ctx.session_id,
        event_manager=ctx.event_manager,
        service=service,
    )


# ==================== å•ç”¨æˆ·è®°å¿†æ›´æ–° ====================


async def update_user_memories(
    user_id: str,
    since_hours: int = 24,
    session_id: Optional[str] = None,
    event_manager=None,
    service: "BackgroundTaskService" = None,
) -> Mem0UpdateResult:
    """
    æ›´æ–°å•ä¸ªç”¨æˆ·çš„ Mem0 è®°å¿†ï¼ˆåŽå°ä»»åŠ¡ï¼‰

    ä»Žæ•°æ®åº“èŽ·å–ç”¨æˆ·åœ¨æŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„ä¼šè¯ï¼Œæå–è®°å¿†å¹¶æ›´æ–°
    """
    start_time = datetime.now()

    try:
        logger.info(f"ðŸ§  å¼€å§‹æ›´æ–°ç”¨æˆ·è®°å¿†: user_id={user_id}, since={since_hours}h")

        pool = service.get_mem0_pool() if service else None
        if not pool:
            return Mem0UpdateResult(
                user_id=user_id,
                success=False,
                error="mem0 æ¨¡å—æœªå®‰è£…",
                duration_ms=_calc_duration_ms(start_time),
            )

        # èŽ·å–ç”¨æˆ·ä¼šè¯
        since = datetime.now() - timedelta(hours=since_hours)
        conversations = await _fetch_user_conversations(user_id, since)

        if not conversations:
            logger.info(f"â—‹ ç”¨æˆ· {user_id} æ— éœ€æ›´æ–°ï¼ˆæ— ç¬¦åˆæ¡ä»¶çš„ä¼šè¯ï¼‰")
            return Mem0UpdateResult(
                user_id=user_id,
                success=True,
                memories_added=0,
                conversations_processed=0,
                duration_ms=_calc_duration_ms(start_time),
            )

        # æå–æ‰€æœ‰æ¶ˆæ¯
        all_messages = []
        for conv in conversations:
            all_messages.extend(conv.get("messages", []))

        if not all_messages:
            return Mem0UpdateResult(
                user_id=user_id,
                success=True,
                memories_added=0,
                conversations_processed=len(conversations),
                duration_ms=_calc_duration_ms(start_time),
            )

        # è°ƒç”¨ Mem0 æ·»åŠ è®°å¿†ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼‰
        result = await asyncio.to_thread(pool.add, user_id=user_id, messages=all_messages)

        memories_added = len(result.get("results", []))

        logger.info(
            f"âœ… ç”¨æˆ· {user_id} è®°å¿†æ›´æ–°å®Œæˆ: "
            f"ä¼šè¯æ•°={len(conversations)}, æ¶ˆæ¯æ•°={len(all_messages)}, "
            f"æ–°å¢žè®°å¿†={memories_added}"
        )

        return Mem0UpdateResult(
            user_id=user_id,
            success=True,
            memories_added=memories_added,
            conversations_processed=len(conversations),
            duration_ms=_calc_duration_ms(start_time),
        )

    except Exception as e:
        logger.warning(f"âš ï¸ æ›´æ–°ç”¨æˆ·è®°å¿†å¤±è´¥: user_id={user_id}, error={str(e)}")
        return Mem0UpdateResult(
            user_id=user_id, success=False, error=str(e), duration_ms=_calc_duration_ms(start_time)
        )


# ==================== æ‰¹é‡è®°å¿†æ›´æ–° ====================


async def batch_update_all_memories(
    since_hours: int = 24, max_concurrent: int = 5, service: "BackgroundTaskService" = None
) -> Mem0BatchUpdateResult:
    """
    æ‰¹é‡æ›´æ–°æ‰€æœ‰ç”¨æˆ·çš„ Mem0 è®°å¿†ï¼ˆåŽå°ä»»åŠ¡ï¼‰

    å…¸åž‹ç”¨é€”ï¼šå®šæ—¶ä»»åŠ¡ï¼ˆå¦‚å‡Œæ™¨æ‰¹é‡å¤„ç†å½“å¤©ä¼šè¯ï¼‰
    """
    batch_result = Mem0BatchUpdateResult(
        total_users=0, successful=0, failed=0, start_time=datetime.now()
    )

    try:
        logger.info(
            f"ðŸš€ å¼€å§‹æ‰¹é‡æ›´æ–°ç”¨æˆ·è®°å¿†: since={since_hours}h, max_concurrent={max_concurrent}"
        )

        pool = service.get_mem0_pool() if service else None
        if not pool:
            batch_result.failed = 1
            batch_result.end_time = datetime.now()
            batch_result.results.append(
                Mem0UpdateResult(user_id="batch", success=False, error="mem0 æ¨¡å—æœªå®‰è£…")
            )
            return batch_result

        # èŽ·å–æ‰€æœ‰ç”¨æˆ·çš„ä¼šè¯
        since = datetime.now() - timedelta(hours=since_hours)
        user_conversations = await _fetch_all_user_conversations(since)

        if not user_conversations:
            logger.info(f"â—‹ æ— éœ€æ›´æ–°ï¼ˆæ— ç¬¦åˆæ¡ä»¶çš„ä¼šè¯ï¼‰")
            batch_result.end_time = datetime.now()
            return batch_result

        batch_result.total_users = len(user_conversations)

        # ä½¿ç”¨ä¿¡å·é‡æŽ§åˆ¶å¹¶å‘
        semaphore = asyncio.Semaphore(max_concurrent)

        async def update_with_limit(user_id: str, convs: List[Dict]):
            async with semaphore:
                return await _update_user_memories_internal(user_id, convs, service)

        # å¹¶å‘æ‰§è¡Œ
        tasks = [update_with_limit(user_id, convs) for user_id, convs in user_conversations.items()]

        results = await asyncio.gather(*tasks, return_exceptions=True)

        for result in results:
            if isinstance(result, Exception):
                batch_result.failed += 1
                batch_result.results.append(
                    Mem0UpdateResult(user_id="unknown", success=False, error=str(result))
                )
            elif isinstance(result, Mem0UpdateResult):
                batch_result.results.append(result)
                if result.success:
                    batch_result.successful += 1
                    batch_result.total_memories_added += result.memories_added
                else:
                    batch_result.failed += 1

        batch_result.end_time = datetime.now()

        logger.info(
            f"âœ… æ‰¹é‡æ›´æ–°å®Œæˆ: "
            f"æ€»æ•°={batch_result.total_users}, "
            f"æˆåŠŸ={batch_result.successful}, "
            f"å¤±è´¥={batch_result.failed}, "
            f"æ–°å¢žè®°å¿†={batch_result.total_memories_added}, "
            f"è€—æ—¶={batch_result.duration_seconds:.2f}s"
        )

        # æƒ…ç»ªèšåˆï¼šä¸ºæˆåŠŸæ›´æ–°çš„ç”¨æˆ·ç”Ÿæˆå‘¨æ±‡æ€»
        await _aggregate_weekly_summaries(
            user_ids=[r.user_id for r in batch_result.results if r.success], pool=pool
        )

        return batch_result

    except Exception as e:
        logger.warning(f"âš ï¸ æ‰¹é‡æ›´æ–°å¤±è´¥: {str(e)}")
        batch_result.failed = 1
        batch_result.end_time = datetime.now()
        batch_result.results.append(Mem0UpdateResult(user_id="batch", success=False, error=str(e)))
        return batch_result


async def _update_user_memories_internal(
    user_id: str, conversations: List[Dict[str, Any]], service: "BackgroundTaskService"
) -> Mem0UpdateResult:
    """å†…éƒ¨æ–¹æ³•ï¼šæ›´æ–°å•ç”¨æˆ·è®°å¿†ï¼ˆå·²æœ‰ä¼šè¯æ•°æ®ï¼‰"""
    start_time = datetime.now()

    try:
        pool = service.get_mem0_pool() if service else None
        if not pool:
            return Mem0UpdateResult(
                user_id=user_id,
                success=False,
                error="mem0 æ¨¡å—æœªå®‰è£…",
                duration_ms=_calc_duration_ms(start_time),
            )

        all_messages = []
        for conv in conversations:
            all_messages.extend(conv.get("messages", []))

        if not all_messages:
            return Mem0UpdateResult(
                user_id=user_id,
                success=True,
                memories_added=0,
                conversations_processed=len(conversations),
                duration_ms=_calc_duration_ms(start_time),
            )

        result = await asyncio.to_thread(pool.add, user_id=user_id, messages=all_messages)

        memories_added = len(result.get("results", []))

        return Mem0UpdateResult(
            user_id=user_id,
            success=True,
            memories_added=memories_added,
            conversations_processed=len(conversations),
            duration_ms=_calc_duration_ms(start_time),
        )

    except Exception as e:
        return Mem0UpdateResult(
            user_id=user_id, success=False, error=str(e), duration_ms=_calc_duration_ms(start_time)
        )


# ==================== æ•°æ®åº“æŸ¥è¯¢ ====================


async def _fetch_user_conversations(user_id: str, since: datetime) -> List[Dict[str, Any]]:
    """ä»Žæ•°æ®åº“èŽ·å–å•ä¸ªç”¨æˆ·çš„ä¼šè¯"""
    try:
        # TODO: è¿ç§»åˆ° local_store
        from infra.database import AsyncSessionLocal, crud
    except ImportError:
        logger.warning("âš ï¸ æ•°æ®åº“æ¨¡å—å·²åˆ é™¤ï¼Œæ— æ³•èŽ·å–ç”¨æˆ·ä¼šè¯")
        return []

    try:
        async with AsyncSessionLocal() as session:
            conversations = await crud.get_conversations_since(
                session, since=since, user_id=user_id
            )

            result = []
            for conv in conversations:
                messages = await crud.get_messages_by_conversation(session, conversation_id=conv.id)
                result.append(
                    {
                        "id": conv.id,
                        "created_at": conv.created_at.isoformat() if conv.created_at else None,
                        "messages": [
                            {"role": msg.role, "content": msg.content} for msg in messages
                        ],
                    }
                )

            return result

    except Exception as e:
        logger.warning(f"âš ï¸ èŽ·å–ç”¨æˆ·ä¼šè¯å¤±è´¥: {e}")
        return []


async def _fetch_all_user_conversations(since: datetime) -> Dict[str, List[Dict[str, Any]]]:
    """ä»Žæ•°æ®åº“èŽ·å–æ‰€æœ‰ç”¨æˆ·çš„ä¼šè¯ï¼ˆæŒ‰ç”¨æˆ·åˆ†ç»„ï¼‰"""
    try:
        # TODO: è¿ç§»åˆ° local_store
        from infra.database import AsyncSessionLocal, crud
    except ImportError:
        logger.warning("âš ï¸ æ•°æ®åº“æ¨¡å—å·²åˆ é™¤ï¼Œæ— æ³•èŽ·å–æ‰€æœ‰ç”¨æˆ·ä¼šè¯")
        return {}

    try:
        async with AsyncSessionLocal() as session:
            conversations = await crud.get_conversations_since(session, since=since)

            user_conversations: Dict[str, List[Dict[str, Any]]] = {}

            for conv in conversations:
                user_id = conv.user_id
                if not user_id:
                    continue

                messages = await crud.get_messages_by_conversation(session, conversation_id=conv.id)

                conv_data = {
                    "id": conv.id,
                    "created_at": conv.created_at.isoformat() if conv.created_at else None,
                    "messages": [{"role": msg.role, "content": msg.content} for msg in messages],
                }

                if user_id not in user_conversations:
                    user_conversations[user_id] = []
                user_conversations[user_id].append(conv_data)

            return user_conversations

    except Exception as e:
        logger.warning(f"âš ï¸ èŽ·å–æ‰€æœ‰ç”¨æˆ·ä¼šè¯å¤±è´¥: {e}")
        return {}


# ==================== æƒ…ç»ªèšåˆ ====================


async def _aggregate_weekly_summaries(user_ids: List[str], pool) -> None:
    """
    ä¸ºç”¨æˆ·ç”Ÿæˆå‘¨æ±‡æ€»ï¼ˆæƒ…ç»ª + å·¥ä½œé‡ç‚¹ï¼‰

    åœ¨æ‰¹é‡æ›´æ–°åŽè°ƒç”¨ï¼Œå°†èšåˆç»“æžœå­˜å…¥ Mem0

    Args:
        user_ids: éœ€è¦èšåˆçš„ç”¨æˆ· ID åˆ—è¡¨
        pool: Mem0 Pool å®žä¾‹
    """
    if not user_ids:
        return

    try:
        from core.memory.mem0.aggregator import (
            aggregate_user_emotion,
            aggregate_work_summary,
        )

        # è®¡ç®—æœ¬å‘¨æ—¶é—´çª—å£
        today = datetime.now()
        start_of_week = today - timedelta(days=today.weekday())
        start_of_week = start_of_week.replace(hour=0, minute=0, second=0, microsecond=0)

        logger.info(f"ðŸ“Š å¼€å§‹æƒ…ç»ªèšåˆ: {len(user_ids)} ä¸ªç”¨æˆ·")

        for user_id in user_ids:
            try:
                # æ£€ç´¢ç”¨æˆ·è®°å¿†
                memories = pool.get_all(user_id=user_id, limit=100)

                if not memories:
                    continue

                # èšåˆæƒ…ç»ª
                emotion_result = await aggregate_user_emotion(
                    user_id=user_id, start_date=start_of_week, end_date=today, memories=memories
                )

                # èšåˆå·¥ä½œé‡ç‚¹
                work_result = await aggregate_work_summary(
                    user_id=user_id, start_date=start_of_week, end_date=today, memories=memories
                )

                # å­˜å‚¨æƒ…ç»ªæ‘˜è¦
                if emotion_result.get("summary") and emotion_result.get("dominant") != "neutral":
                    pool.add(
                        user_id=user_id,
                        messages=[
                            {"role": "user", "content": f"[æƒ…ç»ªæ‘˜è¦] {emotion_result['summary']}"}
                        ],
                        metadata={
                            "type": "emotion_weekly",
                            "time_window": emotion_result.get("time_window"),
                            "dominant": emotion_result.get("dominant"),
                        },
                    )

                # å­˜å‚¨å·¥ä½œæ‘˜è¦
                if work_result.get("summary") and work_result.get("highlights"):
                    pool.add(
                        user_id=user_id,
                        messages=[
                            {"role": "user", "content": f"[å·¥ä½œæ‘˜è¦] {work_result['summary']}"}
                        ],
                        metadata={
                            "type": "work_weekly",
                            "time_window": work_result.get("time_window"),
                            "next_steps": work_result.get("next_steps", []),
                        },
                    )

                logger.debug(f"  âœ“ ç”¨æˆ· {user_id} èšåˆå®Œæˆ")

            except Exception as e:
                logger.warning(f"  âš ï¸ ç”¨æˆ· {user_id} èšåˆå¤±è´¥: {e}")
                continue

        logger.info(f"âœ… æƒ…ç»ªèšåˆå®Œæˆ")

    except ImportError:
        logger.debug("æƒ…ç»ªèšåˆæ¨¡å—æœªåŠ è½½ï¼Œè·³è¿‡")
    except Exception as e:
        logger.warning(f"âš ï¸ æƒ…ç»ªèšåˆå¤±è´¥: {e}")


# ==================== å·¥å…·æ–¹æ³• ====================


def _calc_duration_ms(start_time: datetime) -> int:
    """è®¡ç®—è€—æ—¶ï¼ˆæ¯«ç§’ï¼‰"""
    return int((datetime.now() - start_time).total_seconds() * 1000)
