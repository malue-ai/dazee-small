"""
æ–‡ä»¶å¤„ç†å·¥å…· - æ”¯æŒå›¾ç‰‡å’Œæ–‡æ¡£çš„ç¼–ç ä¸å¤„ç†ï¼ˆå¼‚æ­¥ç‰ˆæœ¬ï¼‰
ç”¨äº Claude API çš„å¤šæ¨¡æ€è¾“å…¥
"""

import asyncio
import base64
import io
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import aiofiles

from logger import get_logger

logger = get_logger(__name__)

try:
    from PIL import Image

    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    logger.warning("PIL æœªå®‰è£…ï¼Œå›¾ç‰‡å‹ç¼©åŠŸèƒ½å°†ä¸å¯ç”¨ã€‚è¿è¡Œ: pip install Pillow")

try:
    import PyPDF2

    PYPDF2_AVAILABLE = True
except ImportError:
    PYPDF2_AVAILABLE = False
    logger.warning("PyPDF2 æœªå®‰è£…ï¼ŒPDF æ–‡æœ¬æå–åŠŸèƒ½å°†ä¸å¯ç”¨ã€‚è¿è¡Œ: pip install PyPDF2")


class FileHandler:
    """æ–‡ä»¶å¤„ç†å·¥å…·ç±»ï¼ˆå¼‚æ­¥ç‰ˆæœ¬ï¼‰"""

    # æ”¯æŒçš„å›¾ç‰‡æ ¼å¼
    SUPPORTED_IMAGE_FORMATS = {
        ".jpg": "image/jpeg",
        ".jpeg": "image/jpeg",
        ".png": "image/png",
        ".gif": "image/gif",
        ".webp": "image/webp",
    }

    # æ–‡ä»¶å¤§å°é™åˆ¶
    MAX_IMAGE_SIZE_MB = 5.0
    MAX_PDF_SIZE_MB = 30.0
    RECOMMENDED_IMAGE_SIZE_MB = 3.0

    def __init__(self, auto_compress: bool = True):
        """
        åˆå§‹åŒ–æ–‡ä»¶å¤„ç†å™¨

        Args:
            auto_compress: æ˜¯å¦è‡ªåŠ¨å‹ç¼©è¿‡å¤§çš„å›¾ç‰‡
        """
        self.auto_compress = auto_compress
        self._cache = {}  # ç®€å•çš„ç¼–ç ç¼“å­˜

    async def encode_image_to_base64(
        self, image_path: str, use_cache: bool = True
    ) -> Optional[Tuple[str, str]]:
        """
        å°†å›¾ç‰‡ç¼–ç ä¸º base64ï¼ˆå¼‚æ­¥ï¼‰

        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜

        Returns:
            (base64_data, media_type) æˆ– Noneï¼ˆå¦‚æœå¤±è´¥ï¼‰
        """
        try:
            path = Path(image_path)

            # æ£€æŸ¥ç¼“å­˜
            cache_key = f"image:{path.absolute()}"
            if use_cache and cache_key in self._cache:
                logger.debug(f"ä½¿ç”¨ç¼“å­˜çš„å›¾ç‰‡ç¼–ç : {image_path}")
                return self._cache[cache_key]

            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not path.exists():
                logger.error(f"âŒ å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
                return None

            # æ£€æŸ¥æ ¼å¼
            suffix = path.suffix.lower()
            if suffix not in self.SUPPORTED_IMAGE_FORMATS:
                logger.error(f"âŒ ä¸æ”¯æŒçš„å›¾ç‰‡æ ¼å¼: {suffix}")
                return None

            media_type = self.SUPPORTED_IMAGE_FORMATS[suffix]

            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            size_mb = path.stat().st_size / (1024 * 1024)

            if size_mb > self.MAX_IMAGE_SIZE_MB:
                if self.auto_compress and PIL_AVAILABLE:
                    logger.warning(f"âš ï¸ å›¾ç‰‡è¿‡å¤§ ({size_mb:.2f}MB)ï¼Œæ­£åœ¨å‹ç¼©...")
                    image_data = await self._compress_image(
                        image_path, target_size_mb=self.MAX_IMAGE_SIZE_MB
                    )
                    compressed_mb = len(image_data) / (1024 * 1024)
                    if compressed_mb > self.MAX_IMAGE_SIZE_MB:
                        logger.error(
                            f"âŒ å‹ç¼©åä»è¿‡å¤§ ({compressed_mb:.2f}MB)ï¼Œè¶…è¿‡é™åˆ¶ {self.MAX_IMAGE_SIZE_MB}MB"
                        )
                        return None
                    size_mb = compressed_mb
                    media_type = "image/jpeg"  # å‹ç¼©åç»Ÿä¸€ä¸º JPEG
                else:
                    logger.error(
                        f"âŒ å›¾ç‰‡è¿‡å¤§ ({size_mb:.2f}MB)ï¼Œè¶…è¿‡é™åˆ¶ {self.MAX_IMAGE_SIZE_MB}MB"
                    )
                    return None
            elif size_mb > self.RECOMMENDED_IMAGE_SIZE_MB and self.auto_compress and PIL_AVAILABLE:
                logger.info(f"ğŸ”§ å›¾ç‰‡è¾ƒå¤§ ({size_mb:.2f}MB)ï¼Œå»ºè®®å‹ç¼©ä»¥ä¼˜åŒ–æ€§èƒ½")
                image_data = await self._compress_image(
                    image_path, target_size_mb=self.RECOMMENDED_IMAGE_SIZE_MB
                )
                compressed_mb = len(image_data) / (1024 * 1024)
                if compressed_mb > self.MAX_IMAGE_SIZE_MB:
                    logger.error(
                        f"âŒ å‹ç¼©åä»è¿‡å¤§ ({compressed_mb:.2f}MB)ï¼Œè¶…è¿‡é™åˆ¶ {self.MAX_IMAGE_SIZE_MB}MB"
                    )
                    return None
                size_mb = compressed_mb
                media_type = "image/jpeg"
            else:
                # å¼‚æ­¥è¯»å–æ–‡ä»¶
                async with aiofiles.open(image_path, "rb") as f:
                    image_data = await f.read()

            # ç¼–ç ä¸º base64
            encoded = base64.standard_b64encode(image_data).decode("utf-8")

            result = (encoded, media_type)

            # ç¼“å­˜ç»“æœ
            if use_cache:
                self._cache[cache_key] = result

            logger.info(f"âœ… å›¾ç‰‡ç¼–ç æˆåŠŸ: {image_path} ({size_mb:.2f}MB)")
            return result

        except Exception as e:
            logger.error(f"âŒ ç¼–ç å›¾ç‰‡å¤±è´¥ ({image_path}): {e}")
            return None

    def _compress_image_sync(self, image_path: str, target_size_mb: float = None) -> bytes:
        """
        åŒæ­¥å‹ç¼©å›¾ç‰‡ï¼ˆCPU å¯†é›†å‹æ“ä½œï¼‰

        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            target_size_mb: ç›®æ ‡å¤§å°ï¼ˆMBï¼‰ï¼Œé»˜è®¤ä¸º RECOMMENDED_IMAGE_SIZE_MB

        Returns:
            å‹ç¼©åçš„å›¾ç‰‡æ•°æ®
        """
        if not PIL_AVAILABLE:
            raise ImportError("éœ€è¦å®‰è£… Pillow æ‰èƒ½å‹ç¼©å›¾ç‰‡")

        if target_size_mb is None:
            target_size_mb = self.RECOMMENDED_IMAGE_SIZE_MB

        img = Image.open(image_path)

        # è½¬æ¢ä¸º RGBï¼ˆå¦‚æœæ˜¯ RGBA æˆ–å…¶ä»–æ¨¡å¼ï¼‰
        if img.mode in ("RGBA", "LA", "P"):
            # åˆ›å»ºç™½è‰²èƒŒæ™¯
            background = Image.new("RGB", img.size, (255, 255, 255))
            if img.mode == "P":
                img = img.convert("RGBA")
            background.paste(img, mask=img.split()[-1] if img.mode in ("RGBA", "LA") else None)
            img = background
        elif img.mode != "RGB":
            img = img.convert("RGB")

        # å¦‚æœå›¾ç‰‡å¤ªå¤§ï¼Œå…ˆè°ƒæ•´åˆ†è¾¨ç‡
        max_dimension = 1568  # Claude æ¨èçš„æœ€å¤§åˆ†è¾¨ç‡
        if max(img.size) > max_dimension:
            ratio = max_dimension / max(img.size)
            new_size = tuple(int(dim * ratio) for dim in img.size)
            img = img.resize(new_size, Image.Resampling.LANCZOS)
            logger.info(f"   è°ƒæ•´åˆ†è¾¨ç‡: {img.size}")

        # é€æ­¥é™ä½è´¨é‡ç›´åˆ°æ»¡è¶³å¤§å°è¦æ±‚
        quality = 95
        buffer = io.BytesIO()
        while quality > 20:
            buffer = io.BytesIO()
            img.save(buffer, format="JPEG", quality=quality, optimize=True)
            size_mb = buffer.tell() / (1024 * 1024)

            if size_mb <= target_size_mb:
                logger.info(f"   å‹ç¼©å®Œæˆ: {size_mb:.2f}MB (è´¨é‡: {quality})")
                return buffer.getvalue()

            quality -= 5

        # å¦‚æœè¿˜æ˜¯å¤ªå¤§ï¼Œè¿”å›æœ€åçš„ç»“æœ
        logger.warning(f"   å‹ç¼©åä»è¾ƒå¤§: {size_mb:.2f}MB")
        return buffer.getvalue()

    async def _compress_image(self, image_path: str, target_size_mb: float = None) -> bytes:
        """
        å¼‚æ­¥å‹ç¼©å›¾ç‰‡ï¼ˆä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œ CPU å¯†é›†å‹æ“ä½œï¼‰

        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            target_size_mb: ç›®æ ‡å¤§å°ï¼ˆMBï¼‰ï¼Œé»˜è®¤ä¸º RECOMMENDED_IMAGE_SIZE_MB

        Returns:
            å‹ç¼©åçš„å›¾ç‰‡æ•°æ®
        """
        return await asyncio.to_thread(self._compress_image_sync, image_path, target_size_mb)

    async def encode_pdf_to_base64(self, pdf_path: str, use_cache: bool = True) -> Optional[str]:
        """
        å°† PDF ç¼–ç ä¸º base64ï¼ˆå¼‚æ­¥ï¼‰

        Args:
            pdf_path: PDF è·¯å¾„
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜

        Returns:
            base64_data æˆ– Noneï¼ˆå¦‚æœå¤±è´¥ï¼‰
        """
        try:
            path = Path(pdf_path)

            # æ£€æŸ¥ç¼“å­˜
            cache_key = f"pdf:{path.absolute()}"
            if use_cache and cache_key in self._cache:
                logger.debug(f"ä½¿ç”¨ç¼“å­˜çš„ PDF ç¼–ç : {pdf_path}")
                return self._cache[cache_key]

            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not path.exists():
                logger.error(f"âŒ PDF æ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}")
                return None

            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            size_mb = path.stat().st_size / (1024 * 1024)
            if size_mb > self.MAX_PDF_SIZE_MB:
                logger.error(f"âŒ PDF è¿‡å¤§ ({size_mb:.2f}MB)ï¼Œè¶…è¿‡é™åˆ¶ {self.MAX_PDF_SIZE_MB}MB")
                return None

            # å¼‚æ­¥è¯»å–å¹¶ç¼–ç 
            async with aiofiles.open(pdf_path, "rb") as f:
                pdf_content = await f.read()
                pdf_data = base64.standard_b64encode(pdf_content).decode("utf-8")

            # ç¼“å­˜ç»“æœ
            if use_cache:
                self._cache[cache_key] = pdf_data

            logger.info(f"âœ… PDF ç¼–ç æˆåŠŸ: {pdf_path} ({size_mb:.2f}MB)")
            return pdf_data

        except Exception as e:
            logger.error(f"âŒ ç¼–ç  PDF å¤±è´¥ ({pdf_path}): {e}")
            return None

    async def extract_text_from_pdf(self, pdf_path: str) -> Optional[str]:
        """
        ä» PDF æå–çº¯æ–‡æœ¬ï¼ˆå¼‚æ­¥ç‰ˆæœ¬ï¼‰

        ä½¿ç”¨ aiofiles å¼‚æ­¥è¯»å–æ–‡ä»¶ï¼Œç„¶åç”¨ PyPDF2 è§£æ

        Args:
            pdf_path: PDF è·¯å¾„

        Returns:
            æå–çš„æ–‡æœ¬ æˆ– Noneï¼ˆå¦‚æœå¤±è´¥ï¼‰
        """
        if not PYPDF2_AVAILABLE:
            logger.error("âŒ éœ€è¦å®‰è£… PyPDF2 æ‰èƒ½æå– PDF æ–‡æœ¬")
            return None

        try:
            path = Path(pdf_path)
            if not path.exists():
                logger.error(f"âŒ PDF æ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}")
                return None

            # å¼‚æ­¥è¯»å–æ–‡ä»¶å†…å®¹
            async with aiofiles.open(pdf_path, "rb") as f:
                content = await f.read()

            # ä½¿ç”¨ BytesIO ä¼ é€’ç»™ PyPDF2
            reader = PyPDF2.PdfReader(io.BytesIO(content))
            num_pages = len(reader.pages)

            logger.info(f"ğŸ“„ å¼€å§‹æå– PDF æ–‡æœ¬: {pdf_path} ({num_pages} é¡µ)")

            text_parts = []
            for i, page in enumerate(reader.pages):
                try:
                    page_text = page.extract_text()
                    if page_text and page_text.strip():
                        text_parts.append(f"=== ç¬¬ {i+1} é¡µ ===\n{page_text}\n")
                except Exception as e:
                    logger.warning(f"âš ï¸ æå–ç¬¬ {i+1} é¡µå¤±è´¥: {e}")

            full_text = "\n".join(text_parts)
            logger.info(f"âœ… PDF æ–‡æœ¬æå–å®Œæˆ: {len(full_text)} å­—ç¬¦")
            return full_text

        except Exception as e:
            logger.error(f"âŒ æå– PDF æ–‡æœ¬å¤±è´¥ ({pdf_path}): {e}")
            return None

    async def create_image_content_block(self, image_path: str) -> Optional[Dict[str, Any]]:
        """
        åˆ›å»ºå›¾ç‰‡å†…å®¹å—ï¼ˆç”¨äº Claude APIï¼‰ï¼ˆå¼‚æ­¥ï¼‰

        Args:
            image_path: å›¾ç‰‡è·¯å¾„

        Returns:
            å›¾ç‰‡å†…å®¹å—å­—å…¸ æˆ– None
        """
        result = await self.encode_image_to_base64(image_path)
        if not result:
            return None

        image_data, media_type = result

        return {
            "type": "image",
            "source": {"type": "base64", "media_type": media_type, "data": image_data},
        }

    async def create_pdf_content_block(self, pdf_path: str) -> Optional[Dict[str, Any]]:
        """
        åˆ›å»º PDF å†…å®¹å—ï¼ˆç”¨äº Claude APIï¼‰ï¼ˆå¼‚æ­¥ï¼‰

        Args:
            pdf_path: PDF è·¯å¾„

        Returns:
            PDF å†…å®¹å—å­—å…¸ æˆ– None
        """
        pdf_data = await self.encode_pdf_to_base64(pdf_path)
        if not pdf_data:
            return None

        return {
            "type": "document",
            "source": {"type": "base64", "media_type": "application/pdf", "data": pdf_data},
        }

    async def create_multimodal_content(
        self, text: str, image_paths: List[str] = None, pdf_paths: List[str] = None
    ) -> List[Dict[str, Any]]:
        """
        åˆ›å»ºå¤šæ¨¡æ€å†…å®¹å—åˆ—è¡¨ï¼ˆæ–‡æœ¬ + å›¾ç‰‡ + PDFï¼‰ï¼ˆå¼‚æ­¥ï¼‰

        Args:
            text: æ–‡æœ¬å†…å®¹
            image_paths: å›¾ç‰‡è·¯å¾„åˆ—è¡¨
            pdf_paths: PDF è·¯å¾„åˆ—è¡¨

        Returns:
            å†…å®¹å—åˆ—è¡¨
        """
        content_blocks = []

        # æ·»åŠ æ–‡æœ¬
        if text:
            content_blocks.append({"type": "text", "text": text})

        # æ·»åŠ  PDFï¼ˆé€šå¸¸æ”¾åœ¨å‰é¢ï¼‰
        if pdf_paths:
            for pdf_path in pdf_paths:
                block = await self.create_pdf_content_block(pdf_path)
                if block:
                    content_blocks.append(block)

        # æ·»åŠ å›¾ç‰‡
        if image_paths:
            for image_path in image_paths:
                block = await self.create_image_content_block(image_path)
                if block:
                    content_blocks.append(block)

        return content_blocks

    async def estimate_image_tokens(self, image_path: str) -> int:
        """
        ä¼°ç®—å›¾ç‰‡çš„ token æ¶ˆè€—ï¼ˆå¼‚æ­¥ï¼‰

        Args:
            image_path: å›¾ç‰‡è·¯å¾„

        Returns:
            ä¼°ç®—çš„ token æ•°é‡
        """
        if not PIL_AVAILABLE:
            # æ— æ³•å‡†ç¡®ä¼°ç®—ï¼Œè¿”å›å¹³å‡å€¼
            return 170

        try:
            # ä½¿ç”¨çº¿ç¨‹æ± æ‰“å¼€å›¾ç‰‡ï¼ˆI/O æ“ä½œï¼‰
            def _get_image_size():
                with Image.open(image_path) as img:
                    return img.size

            width, height = await asyncio.to_thread(_get_image_size)
            pixels = width * height

            # ç²—ç•¥ä¼°ç®—å…¬å¼ï¼ˆåŸºäº Claude å®˜æ–¹æŒ‡å—ï¼‰
            if pixels < 500000:  # å°å›¾ç‰‡ï¼ˆ< 500K åƒç´ ï¼‰
                return 85
            elif pixels < 1000000:  # ä¸­ç­‰å›¾ç‰‡ï¼ˆ< 1M åƒç´ ï¼‰
                return 170
            else:  # å¤§å›¾ç‰‡
                return 258
        except Exception as e:
            logger.warning(f"âš ï¸ æ— æ³•ä¼°ç®—å›¾ç‰‡ token: {e}")
            return 170

    def clear_cache(self):
        """æ¸…é™¤ç¼–ç ç¼“å­˜"""
        self._cache.clear()
        logger.info("ğŸ—‘ï¸ ç¼–ç ç¼“å­˜å·²æ¸…é™¤")


# ============================================================
# ä¾¿æ·å‡½æ•°ï¼ˆå¼‚æ­¥ï¼‰
# ============================================================

_default_handler = FileHandler()


async def encode_image(image_path: str) -> Optional[Tuple[str, str]]:
    """ä¾¿æ·å‡½æ•°ï¼šç¼–ç å›¾ç‰‡ï¼ˆå¼‚æ­¥ï¼‰"""
    return await _default_handler.encode_image_to_base64(image_path)


async def encode_pdf(pdf_path: str) -> Optional[str]:
    """ä¾¿æ·å‡½æ•°ï¼šç¼–ç  PDFï¼ˆå¼‚æ­¥ï¼‰"""
    return await _default_handler.encode_pdf_to_base64(pdf_path)


async def create_image_block(image_path: str) -> Optional[Dict[str, Any]]:
    """ä¾¿æ·å‡½æ•°ï¼šåˆ›å»ºå›¾ç‰‡å†…å®¹å—ï¼ˆå¼‚æ­¥ï¼‰"""
    return await _default_handler.create_image_content_block(image_path)


async def create_pdf_block(pdf_path: str) -> Optional[Dict[str, Any]]:
    """ä¾¿æ·å‡½æ•°ï¼šåˆ›å»º PDF å†…å®¹å—ï¼ˆå¼‚æ­¥ï¼‰"""
    return await _default_handler.create_pdf_content_block(pdf_path)


# ============================================================
# ä½¿ç”¨ç¤ºä¾‹
# ============================================================

if __name__ == "__main__":
    import logging

    # é…ç½®æ—¥å¿—
    logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

    async def main():
        # åˆ›å»ºå¤„ç†å™¨
        handler = FileHandler(auto_compress=True)

        # ç¤ºä¾‹ 1: ç¼–ç å•å¼ å›¾ç‰‡
        print("\n=== ç¤ºä¾‹ 1: ç¼–ç å›¾ç‰‡ ===")
        result = await handler.encode_image_to_base64("example.jpg")
        if result:
            base64_data, media_type = result
            print(f"Media Type: {media_type}")
            print(f"Base64 é•¿åº¦: {len(base64_data)} å­—ç¬¦")
            tokens = await handler.estimate_image_tokens("example.jpg")
            print(f"ä¼°ç®— Token: {tokens}")

        # ç¤ºä¾‹ 2: åˆ›å»ºå¤šæ¨¡æ€å†…å®¹
        print("\n=== ç¤ºä¾‹ 2: åˆ›å»ºå¤šæ¨¡æ€å†…å®¹ ===")
        content = await handler.create_multimodal_content(
            text="è¯·åˆ†æè¿™äº›æ–‡ä»¶çš„å†…å®¹",
            image_paths=["screenshot1.png", "screenshot2.png"],
            pdf_paths=["document.pdf"],
        )
        print(f"å†…å®¹å—æ•°é‡: {len(content)}")
        for i, block in enumerate(content):
            print(f"  å— {i+1}: {block['type']}")

        # ç¤ºä¾‹ 3: PDF æ–‡æœ¬æå–
        print("\n=== ç¤ºä¾‹ 3: PDF æ–‡æœ¬æå– ===")
        text = await handler.extract_text_from_pdf("large_document.pdf")
        if text:
            print(f"æå–çš„æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
            print(f"å‰ 200 å­—ç¬¦: {text[:200]}...")

    asyncio.run(main())
