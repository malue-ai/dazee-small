"""
æ ¼å¼é€‚é…å™¨æ¨¡å—

è´Ÿè´£ä¸åŒ LLM æ ¼å¼ä¹‹é—´çš„è½¬æ¢ï¼Œä»¥ Claude æ ¼å¼ä¸ºå†…éƒ¨æ ‡å‡†ã€‚

è®¾è®¡å‚è€ƒï¼š
- one-api / new-api çš„ Adaptor è®¾è®¡
- ç»Ÿä¸€ä½¿ç”¨ Claude æ ¼å¼ä½œä¸ºå†…éƒ¨å­˜å‚¨æ ¼å¼

æ ¼å¼å¯¹æ¯”ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Provider  â”‚              æ¶ˆæ¯æ ¼å¼                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Claude    â”‚ content: str | List[ContentBlock]           â”‚
â”‚             â”‚ ContentBlock: {type, text/thinking/tool_use}â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   OpenAI    â”‚ content: str | List[ContentPart]            â”‚
â”‚             â”‚ ContentPart: {type, text/image_url}         â”‚
â”‚             â”‚ tool_calls: List[{id, type, function}]      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Gemini    â”‚ parts: List[Part]                           â”‚
â”‚             â”‚ Part: {text} | {inline_data} | {function_call}â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
"""

import json
from abc import ABC, abstractmethod
from dataclasses import dataclass
from typing import Any, Dict, List, Optional, Union

from logger import get_logger

from .base import LLMResponse, Message, ToolType

logger = get_logger("adaptor")

# ============================================================
# æ ¼å¼è½¬æ¢å™¨åŸºç±»
# ============================================================


class BaseAdaptor(ABC):
    """
    æ ¼å¼é€‚é…å™¨åŸºç±»

    èŒè´£ï¼š
    1. å°†ç»Ÿä¸€æ ¼å¼ï¼ˆClaudeï¼‰è½¬æ¢ä¸ºç‰¹å®š Provider æ ¼å¼
    2. å°†ç‰¹å®š Provider å“åº”è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼ï¼ˆClaudeï¼‰
    """

    @abstractmethod
    def convert_messages_to_provider(
        self, messages: List[Message], system: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        å°† Claude æ ¼å¼æ¶ˆæ¯è½¬æ¢ä¸º Provider æ ¼å¼

        Args:
            messages: Claude æ ¼å¼çš„æ¶ˆæ¯åˆ—è¡¨
            system: ç³»ç»Ÿæç¤ºè¯

        Returns:
            Provider æ ¼å¼çš„è¯·æ±‚å‚æ•°
        """
        pass

    @abstractmethod
    def convert_response_to_claude(self, response: Any) -> LLMResponse:
        """
        å°† Provider å“åº”è½¬æ¢ä¸º Claude æ ¼å¼

        Args:
            response: Provider çš„åŸå§‹å“åº”

        Returns:
            Claude æ ¼å¼çš„ LLMResponse
        """
        pass

    @abstractmethod
    def convert_tools_to_provider(self, tools: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        å°† Claude æ ¼å¼å·¥å…·å®šä¹‰è½¬æ¢ä¸º Provider æ ¼å¼

        Args:
            tools: Claude æ ¼å¼çš„å·¥å…·å®šä¹‰

        Returns:
            Provider æ ¼å¼çš„å·¥å…·å®šä¹‰
        """
        pass


# ============================================================
# Claude é€‚é…å™¨
# ============================================================


class ClaudeAdaptor(BaseAdaptor):
    """
    Claude é€‚é…å™¨

    èŒè´£ï¼š
    1. åŠ è½½å†å²æ¶ˆæ¯æ—¶ï¼šæ¸…ç† thinking/indexï¼Œåˆ†ç¦» tool_result
    2. å‘é€ API å‰ï¼šç¡®ä¿æ¶ˆæ¯æ ¼å¼ç¬¦åˆ Claude API è¦æ±‚

    Claude API æ¶ˆæ¯æ ¼å¼è§„èŒƒï¼š
    - assistant æ¶ˆæ¯å¯åŒ…å«ï¼štext, thinking, tool_use
    - user æ¶ˆæ¯å¯åŒ…å«ï¼štext, tool_result
    - tool_result å¿…é¡»åœ¨ user æ¶ˆæ¯ä¸­ï¼Œä¸”ç´§è·Ÿå¯¹åº”çš„ tool_use
    """

    # ==================== åŠ è½½å†å²æ¶ˆæ¯ ====================

    @staticmethod
    def prepare_messages_from_db(db_messages: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        ä»æ•°æ®åº“åŠ è½½çš„æ¶ˆæ¯ â†’ LLM æ ¼å¼

        å¤„ç†é€»è¾‘ï¼š
        1. æŒ‰ index å­—æ®µæ’åºå†…å®¹å—
        2. æ¸…ç† thinking, redacted_thinking å—
        3. å»é‡ tool_use å’Œ tool_result
        4. ç§»é™¤ index å­—æ®µ
        5. **äº¤é”™åˆ†ç¦»**ï¼šé‡åˆ° tool_result æ—¶ç«‹å³åˆ›å»º user æ¶ˆæ¯
           - æ•°æ®åº“: assistant [text, tool_use, tool_result, tool_use, tool_result]
           - è¾“å‡º: assistant [text, tool_use] â†’ user [tool_result] â†’ assistant [tool_use] â†’ user [tool_result]
        6. ç¡®ä¿ tool_use/tool_result é…å¯¹

        Args:
            db_messages: æ•°æ®åº“æ¶ˆæ¯åˆ—è¡¨ [{"role": "...", "content": [...]}]

        Returns:
            ç¬¦åˆ Claude API æ ¼å¼çš„æ¶ˆæ¯åˆ—è¡¨
        """

        logger.info(f"ğŸ“¥ prepare_messages_from_db: è¾“å…¥ {len(db_messages)} æ¡æ¶ˆæ¯")

        result = []

        # ç”¨äºå…¨å±€å»é‡ï¼šè®°å½•å·²æ·»åŠ çš„ tool_use id å’Œ tool_result tool_use_id
        seen_tool_use_ids: set = set()
        seen_tool_result_ids: set = set()

        for msg in db_messages:
            role = msg.get("role", "")
            content = msg.get("content", [])

            # å¦‚æœ content æ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥æ·»åŠ 
            if isinstance(content, str):
                result.append({"role": role, "content": content})
                continue

            # å¦‚æœä¸æ˜¯åˆ—è¡¨ï¼Œè·³è¿‡
            if not isinstance(content, list):
                continue

            # æŒ‰ index å­—æ®µæ’åºï¼ˆç¡®ä¿é¡ºåºæ­£ç¡®ï¼‰
            sorted_content = sorted(
                content, key=lambda b: b.get("index", 999) if isinstance(b, dict) else 999
            )

            if role == "assistant":
                # ğŸ”§ å…³é”®æ”¹è¿›ï¼šäº¤é”™åˆ†ç¦» tool_result
                # éå†å†…å®¹å—ï¼Œé‡åˆ° tool_result æ—¶ç«‹å³åˆ›å»º user æ¶ˆæ¯
                current_assistant_blocks = []

                for block in sorted_content:
                    if not isinstance(block, dict):
                        current_assistant_blocks.append(block)
                        continue

                    block_type = block.get("type", "")

                    # è·³è¿‡ thinking å—
                    if block_type in ("thinking", "redacted_thinking"):
                        continue

                    # ç§»é™¤ index å­—æ®µ
                    clean_block = {k: v for k, v in block.items() if k != "index"}

                    # tool_use å»é‡æ£€æŸ¥
                    if block_type == "tool_use":
                        tool_id = block.get("id")
                        if tool_id in seen_tool_use_ids:
                            continue  # è·³è¿‡é‡å¤çš„ tool_use
                        seen_tool_use_ids.add(tool_id)
                        current_assistant_blocks.append(clean_block)

                    # tool_resultï¼šå…ˆä¿å­˜å½“å‰ assistant å—ï¼Œç„¶ååˆ›å»º user æ¶ˆæ¯
                    elif block_type == "tool_result":
                        tool_use_id = block.get("tool_use_id")
                        if tool_use_id in seen_tool_result_ids:
                            continue  # è·³è¿‡é‡å¤çš„ tool_result
                        seen_tool_result_ids.add(tool_use_id)

                        # å…ˆä¿å­˜å½“å‰ç´¯ç§¯çš„ assistant å—
                        if current_assistant_blocks:
                            result.append(
                                {"role": "assistant", "content": current_assistant_blocks}
                            )
                            current_assistant_blocks = []

                        # tool_result ä½œä¸ºç‹¬ç«‹çš„ user æ¶ˆæ¯
                        result.append({"role": "user", "content": [clean_block]})

                    else:
                        # text ç­‰å…¶ä»–ç±»å‹
                        current_assistant_blocks.append(clean_block)

                # ä¿å­˜æœ€åç´¯ç§¯çš„ assistant å—
                if current_assistant_blocks:
                    result.append({"role": "assistant", "content": current_assistant_blocks})

            else:
                # user/system æ¶ˆæ¯ï¼šè¿‡æ»¤å¹¶ä¿ç•™
                filtered_blocks = []
                for block in sorted_content:
                    if not isinstance(block, dict):
                        continue

                    block_type = block.get("type", "")

                    # è·³è¿‡ thinking å—
                    if block_type in ("thinking", "redacted_thinking"):
                        continue

                    # ç§»é™¤ index å­—æ®µ
                    clean_block = {k: v for k, v in block.items() if k != "index"}

                    # tool_result å»é‡
                    if block_type == "tool_result":
                        tool_use_id = block.get("tool_use_id")
                        if tool_use_id in seen_tool_result_ids:
                            continue
                        seen_tool_result_ids.add(tool_use_id)

                    filtered_blocks.append(clean_block)

                if filtered_blocks:
                    result.append({"role": role, "content": filtered_blocks})

        # ç»Ÿè®¡ tool_use å’Œ tool_result æ•°é‡
        pre_tool_use_ids = set()
        pre_tool_result_ids = set()
        for msg in result:
            content = msg.get("content", [])
            if isinstance(content, list):
                for block in content:
                    if isinstance(block, dict):
                        if block.get("type") == "tool_use":
                            pre_tool_use_ids.add(block.get("id"))
                        elif block.get("type") == "tool_result":
                            pre_tool_result_ids.add(block.get("tool_use_id"))

        logger.info(
            f"ğŸ“Š äº¤é”™åˆ†ç¦»å: {len(result)} æ¡æ¶ˆæ¯, tool_use={len(pre_tool_use_ids)}, tool_result={len(pre_tool_result_ids)}"
        )

        if pre_tool_use_ids - pre_tool_result_ids:
            logger.warning(f"âš ï¸ æ£€æµ‹åˆ°æœªé…å¯¹çš„ tool_use: {pre_tool_use_ids - pre_tool_result_ids}")

        # ç¡®ä¿ tool_use/tool_result é…å¯¹
        result = ClaudeAdaptor.ensure_tool_pairs(result)

        logger.info(f"ğŸ“¤ prepare_messages_from_db: è¾“å‡º {len(result)} æ¡æ¶ˆæ¯")

        return result

    @staticmethod
    def ensure_tool_pairs(messages: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        ç¡®ä¿ tool_use å’Œ tool_result æˆå¯¹ä¸”é‚»æ¥å‡ºç°ï¼ˆåŒæ—¶å»é‡ï¼‰

        Claude API è¦æ±‚ï¼š
        - æ¯ä¸ª tool_use åé¢å¿…é¡»ç´§è·Ÿå¯¹åº”çš„ tool_resultï¼ˆåœ¨ä¸‹ä¸€ä¸ª user æ¶ˆæ¯ä¸­ï¼‰
        - å¦‚æœ tool_use æ²¡æœ‰å¯¹åº”çš„ tool_resultï¼Œéœ€è¦ç§»é™¤
        - å¦‚æœ tool_result æ²¡æœ‰å¯¹åº”çš„ tool_useï¼Œä¹Ÿéœ€è¦ç§»é™¤
        - æ¯ä¸ª tool_use_id åªèƒ½æœ‰ä¸€ä¸ª tool_resultï¼ˆå»é‡ï¼‰
        - tool_result å¿…é¡»åœ¨ tool_use æ‰€åœ¨ assistant æ¶ˆæ¯çš„**ç´§é‚»ä¸‹ä¸€æ¡** user æ¶ˆæ¯ä¸­

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨

        Returns:
            æ¸…ç†åçš„æ¶ˆæ¯åˆ—è¡¨ï¼ˆåªä¿ç•™é…å¯¹ã€é‚»æ¥ä¸”ä¸é‡å¤çš„ tool_use/tool_resultï¼‰
        """
        if not messages:
            return messages

        # Phase 1: å…¨å±€é…å¯¹æ£€æŸ¥ â€” æ”¶é›†æ‰€æœ‰ tool_use ID å’Œ tool_result ID
        tool_use_ids: set = set()
        tool_result_ids: set = set()

        for msg in messages:
            content = msg.get("content", [])
            if not isinstance(content, list):
                continue

            for block in content:
                if not isinstance(block, dict):
                    continue
                block_type = block.get("type")
                if block_type == "tool_use":
                    tool_use_ids.add(block.get("id"))
                elif block_type == "tool_result":
                    tool_result_ids.add(block.get("tool_use_id"))

        globally_paired = tool_use_ids & tool_result_ids

        if tool_use_ids - tool_result_ids:
            logger.warning(
                f"âš ï¸ å‘ç° {len(tool_use_ids - tool_result_ids)} ä¸ªå…¨å±€æœªé…å¯¹çš„ tool_useï¼Œå°†ç§»é™¤: "
                f"{tool_use_ids - tool_result_ids}"
            )
        if tool_result_ids - tool_use_ids:
            logger.warning(
                f"âš ï¸ å‘ç° {len(tool_result_ids - tool_use_ids)} ä¸ªå…¨å±€æœªé…å¯¹çš„ tool_resultï¼Œå°†ç§»é™¤: "
                f"{tool_result_ids - tool_use_ids}"
            )

        # Phase 2: é‚»æ¥æ€§æ£€æŸ¥ â€” tool_use æ‰€åœ¨ assistant æ¶ˆæ¯çš„ä¸‹ä¸€æ¡å¿…é¡»æ˜¯åŒ…å«
        # å¯¹åº” tool_result çš„ user æ¶ˆæ¯
        adjacent_paired: set = set()

        for i, msg in enumerate(messages):
            content = msg.get("content", [])
            if msg.get("role") != "assistant" or not isinstance(content, list):
                continue

            # æ”¶é›†è¯¥ assistant æ¶ˆæ¯ä¸­çš„ tool_use IDs
            tu_ids_in_msg = {
                b.get("id")
                for b in content
                if isinstance(b, dict) and b.get("type") == "tool_use" and b.get("id") in globally_paired
            }
            if not tu_ids_in_msg:
                continue

            # æ£€æŸ¥ç´§é‚»çš„ä¸‹ä¸€æ¡æ¶ˆæ¯æ˜¯å¦ä¸º user ä¸”åŒ…å«å¯¹åº” tool_result
            next_idx = i + 1
            if next_idx < len(messages):
                next_msg = messages[next_idx]
                next_content = next_msg.get("content", [])
                if next_msg.get("role") == "user" and isinstance(next_content, list):
                    tr_ids_in_next = {
                        b.get("tool_use_id")
                        for b in next_content
                        if isinstance(b, dict) and b.get("type") == "tool_result"
                    }
                    # åªæœ‰åœ¨ä¸‹ä¸€æ¡æ¶ˆæ¯ä¸­æœ‰å¯¹åº” tool_result çš„æ‰ç®—é‚»æ¥é…å¯¹
                    matched = tu_ids_in_msg & tr_ids_in_next
                    adjacent_paired.update(matched)

                    not_adjacent = tu_ids_in_msg - tr_ids_in_next
                    if not_adjacent:
                        logger.warning(
                            f"âš ï¸ æ¶ˆæ¯[{i}] ä¸­çš„ tool_use åœ¨ä¸‹ä¸€æ¡æ¶ˆæ¯ä¸­ç¼ºå°‘å¯¹åº” tool_resultï¼Œ"
                            f"å°†ç§»é™¤: {not_adjacent}"
                        )
                else:
                    # ä¸‹ä¸€æ¡ä¸æ˜¯ user æ¶ˆæ¯ï¼Œæ‰€æœ‰ tool_use éƒ½ä¸æ»¡è¶³é‚»æ¥æ€§
                    logger.warning(
                        f"âš ï¸ æ¶ˆæ¯[{i}] å« tool_use ä½†ä¸‹ä¸€æ¡æ¶ˆæ¯ä¸æ˜¯ userï¼Œå°†ç§»é™¤: {tu_ids_in_msg}"
                    )
            else:
                # assistant æ˜¯æœ€åä¸€æ¡æ¶ˆæ¯ï¼Œtool_use æ²¡æœ‰ tool_result
                logger.warning(
                    f"âš ï¸ æ¶ˆæ¯[{i}] å« tool_use ä½†å·²æ˜¯æœ€åä¸€æ¡æ¶ˆæ¯ï¼Œå°†ç§»é™¤: {tu_ids_in_msg}"
                )

        # Phase 3: åŸºäºé‚»æ¥é…å¯¹é›†åˆè¿‡æ»¤æ¶ˆæ¯ï¼ŒåŒæ—¶å»é‡
        added_tool_use_ids: set = set()
        added_tool_result_ids: set = set()
        cleaned_messages = []

        for msg in messages:
            content = msg.get("content", [])
            role = msg.get("role", "user")

            if isinstance(content, list):
                filtered_content = []
                for block in content:
                    if not isinstance(block, dict):
                        continue

                    block_type = block.get("type")

                    if block_type == "tool_use":
                        tool_id = block.get("id")
                        if tool_id in adjacent_paired:
                            if tool_id in added_tool_use_ids:
                                logger.warning(f"ğŸ§¹ ç§»é™¤é‡å¤çš„ tool_use: {tool_id}")
                                continue
                            added_tool_use_ids.add(tool_id)
                            filtered_content.append(block)
                        else:
                            logger.debug(f"ğŸ§¹ ç§»é™¤æœªé…å¯¹/éé‚»æ¥çš„ tool_use: {tool_id}")
                    elif block_type == "tool_result":
                        tool_use_id = block.get("tool_use_id")
                        if tool_use_id in adjacent_paired:
                            if tool_use_id in added_tool_result_ids:
                                logger.warning(f"ğŸ§¹ ç§»é™¤é‡å¤çš„ tool_result: {tool_use_id}")
                                continue
                            added_tool_result_ids.add(tool_use_id)
                            filtered_content.append(block)
                        else:
                            logger.debug(f"ğŸ§¹ ç§»é™¤æœªé…å¯¹/éé‚»æ¥çš„ tool_result: {tool_use_id}")
                    else:
                        filtered_content.append(block)

                # åªæ·»åŠ æœ‰å†…å®¹çš„æ¶ˆæ¯
                if filtered_content:
                    cleaned_messages.append({"role": role, "content": filtered_content})
            else:
                # çº¯æ–‡æœ¬æ¶ˆæ¯ï¼Œç›´æ¥ä¿ç•™
                if content:
                    cleaned_messages.append(msg)

        removed_count = len(messages) - len(cleaned_messages)
        if removed_count > 0:
            logger.info(
                f"âœ… ensure_tool_pairs: {len(messages)} â†’ {len(cleaned_messages)} æ¡æ¶ˆæ¯ "
                f"(adjacent_paired={len(adjacent_paired)})"
            )
        else:
            logger.debug(
                f"âœ… ensure_tool_pairs: {len(messages)} æ¡æ¶ˆæ¯æ— éœ€æ¸…ç† "
                f"(adjacent_paired={len(adjacent_paired)})"
            )

        return cleaned_messages

    @staticmethod
    def clean_content_blocks(blocks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        æ¸…ç† content blocks

        å¤„ç†ï¼š
        - ç§»é™¤ thinking, redacted_thinking å—
        - ç§»é™¤ index å­—æ®µ

        Args:
            blocks: content blocks åˆ—è¡¨

        Returns:
            æ¸…ç†åçš„ blocks
        """
        result = []
        for block in blocks:
            if not isinstance(block, dict):
                result.append(block)
                continue

            block_type = block.get("type", "")

            # è·³è¿‡ thinking å—
            if block_type in ("thinking", "redacted_thinking"):
                continue

            # ç§»é™¤ index å­—æ®µ
            clean_block = {k: v for k, v in block.items() if k != "index"}
            result.append(clean_block)

        return result

    # ==================== å‘é€ API å‰ ====================

    def convert_messages_to_provider(
        self, messages: List[Message], system: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Message â†’ Claude API æ ¼å¼

        å…œåº•æ£€æŸ¥ï¼š
        1. ç¡®ä¿ tool_result åœ¨ user æ¶ˆæ¯ä¸­
        2. è¿‡æ»¤æ— æ•ˆçš„ thinking å—ï¼ˆæ—  signature ä¼šå¯¼è‡´ API 400 é”™è¯¯ï¼‰
        """
        converted_messages = []

        for msg in messages:
            content = msg.content

            # å­—ç¬¦ä¸²å†…å®¹ç›´æ¥æ·»åŠ 
            if isinstance(content, str):
                converted_messages.append({"role": msg.role, "content": content})
                continue

            # åˆ—è¡¨å†…å®¹éœ€è¦æ£€æŸ¥ tool_result
            if isinstance(content, list) and msg.role == "assistant":
                assistant_blocks = []
                tool_result_blocks = []

                for block in content:
                    if not isinstance(block, dict):
                        assistant_blocks.append(block)
                        continue

                    block_type = block.get("type", "")

                    if block_type == "tool_result":
                        tool_result_blocks.append(block)
                    elif block_type in ("thinking", "redacted_thinking"):
                        # åªä¿ç•™æœ‰æœ‰æ•ˆ signature çš„ thinking å—
                        # æ—  signature çš„ thinking å—ä¼šå¯¼è‡´ Claude API 400 é”™è¯¯ï¼š
                        # "messages.X.content.Y.thinking.signature: Field required"
                        if block.get("signature"):
                            assistant_blocks.append(block)
                        else:
                            logger.debug(
                                f"ğŸ§¹ è¿‡æ»¤æ—  signature çš„ {block_type} å—"
                            )
                    else:
                        assistant_blocks.append(block)

                # æ·»åŠ  assistant æ¶ˆæ¯ï¼ˆä¸å« tool_resultï¼‰
                if assistant_blocks:
                    converted_messages.append({"role": "assistant", "content": assistant_blocks})

                # tool_result åˆ†ç¦»åˆ° user æ¶ˆæ¯
                if tool_result_blocks:
                    converted_messages.append({"role": "user", "content": tool_result_blocks})
            else:
                # å…¶ä»–æƒ…å†µç›´æ¥æ·»åŠ 
                converted_messages.append({"role": msg.role, "content": content})

        # ğŸ”§ å…³é”®ï¼šç¡®ä¿ tool_use/tool_result é…å¯¹ä¸”é‚»æ¥ï¼ˆç§»é™¤æœªé…å¯¹/éé‚»æ¥çš„ tool_useï¼‰
        converted_messages = ClaudeAdaptor.ensure_tool_pairs(converted_messages)

        # ğŸ”§ åˆå¹¶è¿ç»­åŒè§’è‰²æ¶ˆæ¯ï¼ˆensure_tool_pairs ç§»é™¤å†…å®¹åå¯èƒ½äº§ç”Ÿï¼‰
        converted_messages = ClaudeAdaptor._merge_consecutive_same_role(converted_messages)

        # ğŸ›¡ï¸ æœ€ç»ˆé˜²çº¿ï¼šåˆå¹¶åå†æ¬¡éªŒè¯ tool_use/tool_result é…å¯¹
        # _merge_consecutive_same_role å¯èƒ½æ”¹å˜æ¶ˆæ¯é‚»æ¥å…³ç³»ï¼Œéœ€è¦äºŒæ¬¡éªŒè¯
        converted_messages = ClaudeAdaptor.ensure_tool_pairs(converted_messages)

        result = {"messages": converted_messages}
        if system:
            result["system"] = system
        return result

    @staticmethod
    def _merge_consecutive_same_role(messages: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        åˆå¹¶è¿ç»­åŒè§’è‰²æ¶ˆæ¯ï¼ˆClaude API è¦æ±‚ user/assistant ä¸¥æ ¼äº¤æ›¿ï¼‰

        å½“ ensure_tool_pairs ç§»é™¤ tool_use/tool_result åï¼Œå¯èƒ½äº§ç”Ÿè¿ç»­åŒè§’è‰²æ¶ˆæ¯ï¼Œ
        éœ€è¦åˆå¹¶ä»¥æ»¡è¶³ Claude API çš„äº¤æ›¿è¦æ±‚ã€‚

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨

        Returns:
            åˆå¹¶åçš„æ¶ˆæ¯åˆ—è¡¨
        """
        if not messages:
            return messages

        merged = [messages[0]]

        for msg in messages[1:]:
            prev = merged[-1]
            if msg.get("role") == prev.get("role"):
                # åŒè§’è‰²ï¼Œåˆå¹¶ content
                prev_content = prev.get("content", [])
                curr_content = msg.get("content", [])

                if isinstance(prev_content, str) and isinstance(curr_content, str):
                    prev["content"] = prev_content + "\n" + curr_content
                elif isinstance(prev_content, list) and isinstance(curr_content, list):
                    prev["content"] = prev_content + curr_content
                elif isinstance(prev_content, str) and isinstance(curr_content, list):
                    prev["content"] = [{"type": "text", "text": prev_content}] + curr_content
                elif isinstance(prev_content, list) and isinstance(curr_content, str):
                    prev["content"] = prev_content + [{"type": "text", "text": curr_content}]

                logger.debug(
                    f"ğŸ”— åˆå¹¶è¿ç»­ {msg.get('role')} æ¶ˆæ¯"
                )
            else:
                merged.append(msg)

        if len(merged) != len(messages):
            logger.info(
                f"ğŸ”— åˆå¹¶è¿ç»­åŒè§’è‰²æ¶ˆæ¯: {len(messages)} â†’ {len(merged)} æ¡"
            )

        return merged

    def convert_response_to_claude(self, response: Any) -> LLMResponse:
        """Claude å“åº” â†’ LLMResponseï¼ˆåŸç”Ÿï¼‰"""
        # å·²ç»æ˜¯ Claude æ ¼å¼ï¼Œç›´æ¥è¿”å›
        if isinstance(response, LLMResponse):
            return response
        raise ValueError("Expected LLMResponse for Claude adaptor")

    def convert_tools_to_provider(self, tools: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Claude æ ¼å¼å·¥å…· â†’ Claude APIï¼ˆåŸç”Ÿï¼‰"""
        return tools


# ============================================================
# OpenAI é€‚é…å™¨
# ============================================================


class OpenAIAdaptor(BaseAdaptor):
    """
    OpenAI é€‚é…å™¨

    è½¬æ¢è§„åˆ™ï¼š
    - Claude content blocks â†’ OpenAI content + tool_calls
    - Claude tool_use â†’ OpenAI function calling
    - Claude thinking â†’ OpenAI ä¸æ”¯æŒï¼ˆå­˜ä¸º metadataï¼‰
    """

    def convert_messages_to_provider(
        self, messages: List[Message], system: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Claude æ ¼å¼ â†’ OpenAI æ ¼å¼

        è½¬æ¢è§„åˆ™ï¼š
        - system prompt â†’ messages[0] with role="system"
        - content blocks â†’ å±•å¼€ä¸º content å­—ç¬¦ä¸²
        - tool_result â†’ role="tool" æ¶ˆæ¯
        - ğŸ”§ ç¡®ä¿ tool_calls å’Œ tool æ¶ˆæ¯é…å¯¹
        """
        openai_messages = []

        # System prompt ä½œä¸ºç¬¬ä¸€æ¡æ¶ˆæ¯
        if system:
            openai_messages.append({"role": "system", "content": system})

        for msg in messages:
            converted = self._convert_message(msg)
            if isinstance(converted, list):
                openai_messages.extend(converted)
            else:
                openai_messages.append(converted)

        # ğŸ”§ å…³é”®ï¼šç¡®ä¿ tool_calls å’Œ tool æ¶ˆæ¯é…å¯¹
        openai_messages = self._ensure_tool_pairs(openai_messages)

        return {"messages": openai_messages}

    def _convert_message(self, msg: Message) -> Union[Dict, List[Dict]]:
        """è½¬æ¢å•æ¡æ¶ˆæ¯"""
        content = msg.content

        # ç®€å•å­—ç¬¦ä¸²
        if isinstance(content, str):
            return {"role": msg.role, "content": content}

        # Content blocks
        if isinstance(content, list):
            content_parts = []
            tool_calls = []
            tool_results = []

            for block in content:
                block_type = block.get("type", "")

                if block_type == "text":
                    text_val = block.get("text", "")
                    if text_val:
                        content_parts.append({"type": "text", "text": text_val})

                elif block_type == "image":
                    # å¤„ç†å›¾ç‰‡
                    source = block.get("source", {})
                    source_type = source.get("type")

                    if source_type == "url":
                        content_parts.append(
                            {"type": "image_url", "image_url": {"url": source.get("url", "")}}
                        )
                    elif source_type == "base64":
                        media_type = source.get("media_type", "image/jpeg")
                        data = source.get("data", "")
                        content_parts.append(
                            {
                                "type": "image_url",
                                "image_url": {"url": f"data:{media_type};base64,{data}"},
                            }
                        )

                elif block_type == "thinking":
                    # OpenAI ä¸æ”¯æŒ thinkingï¼Œè·³è¿‡
                    pass

                elif block_type == "tool_use":
                    tool_calls.append(
                        {
                            "id": block.get("id", ""),
                            "type": "function",
                            "function": {
                                "name": block.get("name", ""),
                                "arguments": self._serialize_json(block.get("input", {})),
                            },
                        }
                    )

                elif block_type == "tool_result":
                    tool_results.append(
                        {
                            "role": "tool",
                            "tool_call_id": block.get("tool_use_id", ""),
                            "content": self._get_tool_result_content(block),
                        }
                    )

            # æ„å»ºæ¶ˆæ¯
            result = []

            if msg.role == "assistant":
                assistant_msg = {"role": "assistant"}

                # å¤„ç† content
                if content_parts:
                    # å¦‚æœåªæœ‰çº¯æ–‡æœ¬ï¼Œå¯ä»¥ç®€åŒ–ä¸ºå­—ç¬¦ä¸²ï¼ˆå…¼å®¹æ€§æ›´å¥½ï¼‰
                    if all(p["type"] == "text" for p in content_parts):
                        assistant_msg["content"] = "\n".join(p["text"] for p in content_parts)
                    else:
                        # å¤šæ¨¡æ€ï¼ˆå«å›¾ç‰‡ï¼‰ï¼Œä½¿ç”¨åˆ—è¡¨
                        assistant_msg["content"] = content_parts

                if tool_calls:
                    assistant_msg["tool_calls"] = tool_calls

                # åªæœ‰å½“æ¶ˆæ¯æœ‰å†…å®¹æˆ–æœ‰ tool_calls æ—¶æ‰æ·»åŠ 
                if assistant_msg.get("content") or assistant_msg.get("tool_calls"):
                    result.append(assistant_msg)

            elif msg.role == "user":
                if content_parts:
                    # å¦‚æœåªæœ‰çº¯æ–‡æœ¬ï¼Œå¯ä»¥ç®€åŒ–ä¸ºå­—ç¬¦ä¸²
                    if all(p["type"] == "text" for p in content_parts):
                        result.append(
                            {"role": "user", "content": "\n".join(p["text"] for p in content_parts)}
                        )
                    else:
                        # å¤šæ¨¡æ€ï¼ˆå«å›¾ç‰‡ï¼‰ï¼Œä½¿ç”¨åˆ—è¡¨
                        result.append({"role": "user", "content": content_parts})

            # Tool results ä½œä¸ºç‹¬ç«‹æ¶ˆæ¯
            result.extend(tool_results)

            # å¦‚æœ result ä¸ºç©ºä½†åŸå§‹æ¶ˆæ¯æœ‰å†…å®¹ï¼ˆä¾‹å¦‚åªæœ‰ thinking è¢«è¿‡æ»¤äº†ï¼‰ï¼Œè¿”å›ç©ºå†…å®¹çš„æ¶ˆæ¯ä»¥é˜²æŠ¥é”™
            # ä½†é€šå¸¸ thinking ä¼´éšç€ text æˆ– tool_use

            return (
                result
                if len(result) > 1
                else result[0] if result else {"role": msg.role, "content": ""}
            )

        return {"role": msg.role, "content": str(content)}

    def _ensure_tool_pairs(self, messages: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        ç¡®ä¿ tool_calls å’Œ tool æ¶ˆæ¯é…å¯¹

        OpenAI API è¦æ±‚ï¼š
        - assistant æ¶ˆæ¯ä¸­çš„æ¯ä¸ª tool_call_id éƒ½å¿…é¡»æœ‰å¯¹åº”çš„ tool æ¶ˆæ¯å“åº”
        - å¦‚æœæ²¡æœ‰é…å¯¹ï¼Œç§»é™¤è¯¥ tool_callï¼ˆé¿å… API æŠ¥é”™ï¼‰

        Args:
            messages: OpenAI æ ¼å¼çš„æ¶ˆæ¯åˆ—è¡¨

        Returns:
            æ¸…ç†åçš„æ¶ˆæ¯åˆ—è¡¨ï¼ˆåªä¿ç•™é…å¯¹çš„ tool_callsï¼‰
        """
        if not messages:
            return messages

        # 1. æ”¶é›†æ‰€æœ‰ tool_call_id å’Œ tool å“åº”çš„ tool_call_id
        tool_call_ids: set = set()
        tool_response_ids: set = set()

        for msg in messages:
            role = msg.get("role", "")

            if role == "assistant" and msg.get("tool_calls"):
                for tc in msg["tool_calls"]:
                    tool_call_ids.add(tc.get("id"))

            elif role == "tool":
                tool_response_ids.add(msg.get("tool_call_id"))

        # 2. æ‰¾å‡ºé…å¯¹çš„ tool_call_id
        paired_ids = tool_call_ids & tool_response_ids
        unpaired_tool_calls = tool_call_ids - tool_response_ids
        unpaired_tool_responses = tool_response_ids - tool_call_ids

        if unpaired_tool_calls:
            logger.warning(
                f"âš ï¸ [OpenAI] å‘ç° {len(unpaired_tool_calls)} ä¸ªæœªé…å¯¹çš„ tool_callsï¼Œå°†ç§»é™¤: {unpaired_tool_calls}"
            )
        if unpaired_tool_responses:
            logger.warning(
                f"âš ï¸ [OpenAI] å‘ç° {len(unpaired_tool_responses)} ä¸ªæœªé…å¯¹çš„ tool å“åº”ï¼Œå°†ç§»é™¤: {unpaired_tool_responses}"
            )

        # 3. è¿‡æ»¤æ¶ˆæ¯ï¼Œç§»é™¤æœªé…å¯¹çš„ tool_calls å’Œ tool å“åº”
        cleaned_messages = []

        for msg in messages:
            role = msg.get("role", "")

            if role == "assistant" and msg.get("tool_calls"):
                # è¿‡æ»¤æ‰æœªé…å¯¹çš„ tool_calls
                filtered_tool_calls = [tc for tc in msg["tool_calls"] if tc.get("id") in paired_ids]

                # æ„å»ºæ–°çš„ assistant æ¶ˆæ¯
                new_msg = {k: v for k, v in msg.items() if k != "tool_calls"}
                if filtered_tool_calls:
                    new_msg["tool_calls"] = filtered_tool_calls

                # åªæœ‰å½“æ¶ˆæ¯æœ‰å†…å®¹æˆ–æœ‰ tool_calls æ—¶æ‰æ·»åŠ 
                if new_msg.get("content") or new_msg.get("tool_calls"):
                    cleaned_messages.append(new_msg)
                elif not new_msg.get("content") and not filtered_tool_calls:
                    # åŸæ¶ˆæ¯åªæœ‰ tool_calls ä¸”å…¨è¢«ç§»é™¤ï¼Œè·³è¿‡
                    logger.debug(f"ğŸ§¹ [OpenAI] ç§»é™¤ç©ºçš„ assistant æ¶ˆæ¯ï¼ˆtool_calls å…¨è¢«ç§»é™¤ï¼‰")

            elif role == "tool":
                # åªä¿ç•™é…å¯¹çš„ tool å“åº”
                if msg.get("tool_call_id") in paired_ids:
                    cleaned_messages.append(msg)
                else:
                    logger.debug(f"ğŸ§¹ [OpenAI] ç§»é™¤æœªé…å¯¹çš„ tool å“åº”: {msg.get('tool_call_id')}")

            else:
                # å…¶ä»–æ¶ˆæ¯ç›´æ¥ä¿ç•™
                cleaned_messages.append(msg)

        if len(messages) != len(cleaned_messages):
            logger.info(
                f"âœ… [OpenAI] ensure_tool_pairs: {len(messages)} â†’ {len(cleaned_messages)} æ¡æ¶ˆæ¯"
            )

        return cleaned_messages

    def _serialize_json(self, obj: Any) -> str:
        """åºåˆ—åŒ–ä¸º JSON å­—ç¬¦ä¸²"""
        return json.dumps(obj, ensure_ascii=False)

    def _get_tool_result_content(self, block: Dict) -> Any:
        """Get tool_result content. Returns str or list of content blocks (multimodal)."""
        content = block.get("content", "")
        if isinstance(content, str):
            return content
        if isinstance(content, list):
            # Multimodal content blocks (e.g. text + image), pass through
            return content
        return str(content)

    def convert_response_to_claude(self, response: Any) -> LLMResponse:
        """
        OpenAI å“åº” â†’ Claude æ ¼å¼

        è½¬æ¢è§„åˆ™ï¼š
        - choices[0].message.content â†’ content
        - choices[0].message.tool_calls â†’ tool_calls
        - finish_reason â†’ stop_reason
        """
        # å‡è®¾ response æ˜¯ OpenAI çš„å“åº”å¯¹è±¡æˆ–å­—å…¸
        if isinstance(response, dict):
            return self._convert_dict_response(response)

        # OpenAI SDK å“åº”å¯¹è±¡
        choice = response.choices[0] if response.choices else None
        if not choice:
            return LLMResponse(content="", stop_reason="end_turn")

        message = choice.message
        content = message.content or ""
        tool_calls = None
        raw_content = []

        # æ·»åŠ æ–‡æœ¬å†…å®¹
        if content:
            raw_content.append({"type": "text", "text": content})

        # è½¬æ¢ tool_calls
        if hasattr(message, "tool_calls") and message.tool_calls:
            tool_calls = []
            for tc in message.tool_calls:
                tool_call = {
                    "id": tc.id,
                    "name": tc.function.name,
                    "input": json.loads(tc.function.arguments) if tc.function.arguments else {},
                }
                tool_calls.append(tool_call)
                raw_content.append(
                    {
                        "type": "tool_use",
                        "id": tc.id,
                        "name": tc.function.name,
                        "input": tool_call["input"],
                    }
                )

        # è½¬æ¢ stop_reason
        stop_reason_map = {
            "stop": "end_turn",
            "tool_calls": "tool_use",
            "length": "max_tokens",
            "content_filter": "end_turn",
        }
        stop_reason = stop_reason_map.get(choice.finish_reason, "end_turn")

        # Usage
        usage = {}
        if hasattr(response, "usage") and response.usage:
            usage = {
                "input_tokens": response.usage.prompt_tokens,
                "output_tokens": response.usage.completion_tokens,
            }

        return LLMResponse(
            content=content,
            thinking=None,  # OpenAI ä¸æ”¯æŒ thinking
            tool_calls=tool_calls,
            stop_reason=stop_reason,
            usage=usage,
            raw_content=raw_content,
        )

    def _convert_dict_response(self, response: Dict) -> LLMResponse:
        """è½¬æ¢å­—å…¸æ ¼å¼çš„å“åº”"""
        choices = response.get("choices", [])
        if not choices:
            return LLMResponse(content="", stop_reason="end_turn")

        choice = choices[0]
        message = choice.get("message", {})
        content = message.get("content", "") or ""
        tool_calls = None
        raw_content = []

        if content:
            raw_content.append({"type": "text", "text": content})

        if message.get("tool_calls"):
            tool_calls = []
            for tc in message["tool_calls"]:
                func = tc.get("function", {})
                tool_call = {
                    "id": tc.get("id", ""),
                    "name": func.get("name", ""),
                    "input": json.loads(func.get("arguments", "{}")),
                }
                tool_calls.append(tool_call)
                raw_content.append(
                    {
                        "type": "tool_use",
                        "id": tool_call["id"],
                        "name": tool_call["name"],
                        "input": tool_call["input"],
                    }
                )

        stop_reason_map = {"stop": "end_turn", "tool_calls": "tool_use", "length": "max_tokens"}
        stop_reason = stop_reason_map.get(choice.get("finish_reason", ""), "end_turn")

        usage = {}
        if response.get("usage"):
            usage = {
                "input_tokens": response["usage"].get("prompt_tokens", 0),
                "output_tokens": response["usage"].get("completion_tokens", 0),
            }

        return LLMResponse(
            content=content,
            tool_calls=tool_calls,
            stop_reason=stop_reason,
            usage=usage,
            raw_content=raw_content,
        )

    def convert_tools_to_provider(self, tools: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Claude æ ¼å¼å·¥å…· â†’ OpenAI æ ¼å¼

        è½¬æ¢è§„åˆ™ï¼š
        - name â†’ function.name
        - description â†’ function.description
        - input_schema â†’ function.parameters
        """
        openai_tools = []

        for tool in tools:
            # è·³è¿‡ Claude åŸç”Ÿå·¥å…·ï¼ˆå¦‚ web_search_20250305ï¼‰
            if "type" in tool and tool["type"] != "function":
                continue

            openai_tool = {
                "type": "function",
                "function": {
                    "name": tool.get("name", ""),
                    "description": tool.get("description", ""),
                    "parameters": tool.get(
                        "input_schema", {"type": "object", "properties": {}, "required": []}
                    ),
                },
            }
            openai_tools.append(openai_tool)

        return openai_tools


# ============================================================
# Gemini é€‚é…å™¨
# ============================================================


class GeminiAdaptor(BaseAdaptor):
    """
    Gemini é€‚é…å™¨

    è½¬æ¢è§„åˆ™ï¼š
    - Claude content â†’ Gemini parts
    - Claude tool_use â†’ Gemini function_call
    """

    def convert_messages_to_provider(
        self, messages: List[Message], system: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Claude æ ¼å¼ â†’ Gemini æ ¼å¼

        Gemini æ ¼å¼ï¼š
        {
            "contents": [
                {"role": "user", "parts": [{"text": "..."}]},
                {"role": "model", "parts": [{"text": "..."}]}
            ],
            "system_instruction": {"parts": [{"text": "..."}]}
        }
        """
        gemini_contents = []

        for msg in messages:
            # Gemini ä½¿ç”¨ "model" è€Œä¸æ˜¯ "assistant"
            role = "model" if msg.role == "assistant" else msg.role
            parts = self._convert_content_to_parts(msg.content)

            gemini_contents.append({"role": role, "parts": parts})

        result = {"contents": gemini_contents}

        if system:
            result["system_instruction"] = {"parts": [{"text": system}]}

        return result

    def _convert_content_to_parts(self, content: Union[str, List[Dict]]) -> List[Dict[str, Any]]:
        """å°† Claude content è½¬æ¢ä¸º Gemini parts"""
        if isinstance(content, str):
            return [{"text": content}]

        parts = []
        for block in content:
            block_type = block.get("type", "")

            if block_type == "text":
                parts.append({"text": block.get("text", "")})

            elif block_type == "thinking":
                # Gemini ä¸æ”¯æŒ thinkingï¼Œè·³è¿‡
                pass

            elif block_type == "tool_use":
                parts.append(
                    {
                        "function_call": {
                            "name": block.get("name", ""),
                            "args": block.get("input", {}),
                        }
                    }
                )

            elif block_type == "tool_result":
                parts.append(
                    {
                        "function_response": {
                            "name": block.get("name", ""),
                            "response": {"result": block.get("content", "")},
                        }
                    }
                )

        return parts if parts else [{"text": ""}]

    def convert_response_to_claude(self, response: Any) -> LLMResponse:
        """
        Gemini å“åº” â†’ Claude æ ¼å¼

        Gemini å“åº”æ ¼å¼ï¼š
        {
            "candidates": [{
                "content": {"parts": [{"text": "..."}]},
                "finishReason": "STOP"
            }]
        }
        """
        if isinstance(response, dict):
            return self._convert_dict_response(response)

        # Gemini SDK å“åº”å¯¹è±¡
        candidate = response.candidates[0] if response.candidates else None
        if not candidate:
            return LLMResponse(content="", stop_reason="end_turn")

        content_parts = candidate.content.parts if candidate.content else []

        text_content = ""
        tool_calls = []
        raw_content = []

        for part in content_parts:
            if hasattr(part, "text") and part.text:
                text_content += part.text
                raw_content.append({"type": "text", "text": part.text})

            elif hasattr(part, "function_call") and part.function_call:
                fc = part.function_call
                tool_call = {
                    "id": f"gemini_{fc.name}",  # Gemini æ²¡æœ‰ idï¼Œç”Ÿæˆä¸€ä¸ª
                    "name": fc.name,
                    "input": dict(fc.args) if fc.args else {},
                }
                tool_calls.append(tool_call)
                raw_content.append(
                    {
                        "type": "tool_use",
                        "id": tool_call["id"],
                        "name": tool_call["name"],
                        "input": tool_call["input"],
                    }
                )

        # è½¬æ¢ finish_reason
        stop_reason_map = {
            "STOP": "end_turn",
            "MAX_TOKENS": "max_tokens",
            "SAFETY": "end_turn",
            "RECITATION": "end_turn",
            "OTHER": "end_turn",
        }
        finish_reason = getattr(candidate, "finish_reason", None)
        stop_reason = stop_reason_map.get(str(finish_reason), "end_turn")

        # Usage
        usage = {}
        if hasattr(response, "usage_metadata") and response.usage_metadata:
            usage = {
                "input_tokens": response.usage_metadata.prompt_token_count,
                "output_tokens": response.usage_metadata.candidates_token_count,
            }

        return LLMResponse(
            content=text_content,
            thinking=None,
            tool_calls=tool_calls if tool_calls else None,
            stop_reason=stop_reason,
            usage=usage,
            raw_content=raw_content,
        )

    def _convert_dict_response(self, response: Dict) -> LLMResponse:
        """è½¬æ¢å­—å…¸æ ¼å¼çš„å“åº”"""
        candidates = response.get("candidates", [])
        if not candidates:
            return LLMResponse(content="", stop_reason="end_turn")

        candidate = candidates[0]
        content = candidate.get("content", {})
        parts = content.get("parts", [])

        text_content = ""
        tool_calls = []
        raw_content = []

        for part in parts:
            if "text" in part:
                text_content += part["text"]
                raw_content.append({"type": "text", "text": part["text"]})

            elif "functionCall" in part:
                fc = part["functionCall"]
                tool_call = {
                    "id": f"gemini_{fc.get('name', '')}",
                    "name": fc.get("name", ""),
                    "input": fc.get("args", {}),
                }
                tool_calls.append(tool_call)
                raw_content.append(
                    {
                        "type": "tool_use",
                        "id": tool_call["id"],
                        "name": tool_call["name"],
                        "input": tool_call["input"],
                    }
                )

        stop_reason_map = {"STOP": "end_turn", "MAX_TOKENS": "max_tokens"}
        stop_reason = stop_reason_map.get(candidate.get("finishReason", ""), "end_turn")

        usage = {}
        if response.get("usageMetadata"):
            usage = {
                "input_tokens": response["usageMetadata"].get("promptTokenCount", 0),
                "output_tokens": response["usageMetadata"].get("candidatesTokenCount", 0),
            }

        return LLMResponse(
            content=text_content,
            tool_calls=tool_calls if tool_calls else None,
            stop_reason=stop_reason,
            usage=usage,
            raw_content=raw_content,
        )

    def convert_tools_to_provider(self, tools: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Claude æ ¼å¼å·¥å…· â†’ Gemini æ ¼å¼

        Gemini å·¥å…·æ ¼å¼ï¼š
        {
            "function_declarations": [{
                "name": "...",
                "description": "...",
                "parameters": {...}
            }]
        }
        """
        function_declarations = []

        for tool in tools:
            # è·³è¿‡ Claude åŸç”Ÿå·¥å…·
            if "type" in tool and tool["type"] != "function":
                continue

            declaration = {
                "name": tool.get("name", ""),
                "description": tool.get("description", ""),
                "parameters": tool.get(
                    "input_schema", {"type": "object", "properties": {}, "required": []}
                ),
            }
            function_declarations.append(declaration)

        return [{"function_declarations": function_declarations}] if function_declarations else []


# ============================================================
# å·¥å‚å‡½æ•°
# ============================================================


def get_adaptor(provider: str) -> BaseAdaptor:
    """
    è·å–å¯¹åº” Provider çš„é€‚é…å™¨

    Args:
        provider: æä¾›å•†åç§° (claude, openai, gemini, qwen)

    Returns:
        å¯¹åº”çš„é€‚é…å™¨å®ä¾‹
    """
    adaptors = {
        "claude": ClaudeAdaptor,
        "openai": OpenAIAdaptor,
        "gemini": GeminiAdaptor,
        "qwen": OpenAIAdaptor,  # ğŸ†• åƒé—®ä½¿ç”¨ OpenAI å…¼å®¹æ¥å£
    }

    adaptor_class = adaptors.get(provider.lower())
    if not adaptor_class:
        raise ValueError(f"Unknown provider: {provider}")

    return adaptor_class()
