"""
æ¨¡å‹è·¯ç”±å™¨

ç”¨äºåœ¨å¤šä¸ª LLM æœåŠ¡ä¹‹é—´è¿›è¡Œä¸»å¤‡åˆ‡æ¢ï¼Œé™ä½å•ç‚¹æ•…éšœé£é™©ã€‚
"""

import os
import time
from dataclasses import dataclass
from typing import Any, AsyncIterator, Callable, Dict, List, Optional, Union

from logger import get_logger

from .base import BaseLLMService, LLMProvider, LLMResponse, Message, ToolType
from .health_monitor import LLMHealthMonitor, get_llm_health_monitor

logger = get_logger("llm.router")


@dataclass
class RouterPolicy:
    """
    è·¯ç”±ç­–ç•¥

    Attributes:
        max_failures: æœ€å¤§å¤±è´¥æ¬¡æ•°ï¼ˆè¶…è¿‡å³è¿›å…¥å†·å´ï¼‰
        cooldown_seconds: å†·å´æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œå¯é€šè¿‡ LLM_ROUTER_COOLDOWN_SECONDS ç¯å¢ƒå˜é‡è¦†ç›–
    """

    max_failures: int = 2
    cooldown_seconds: int = 600  # é»˜è®¤ 10 åˆ†é’Ÿï¼ˆV7.11ï¼šä» 1 å°æ—¶æ”¹ä¸º 10 åˆ†é’Ÿï¼‰


def _resolve_policy(policy: Optional[Dict[str, Any]]) -> RouterPolicy:
    """
    è§£æè·¯ç”±ç­–ç•¥ï¼ˆæ”¯æŒç¯å¢ƒå˜é‡å…œåº•ï¼‰
    """
    resolved = dict(policy or {})

    if "max_failures" not in resolved:
        env_max_failures = os.getenv("LLM_ROUTER_MAX_FAILURES")
        if env_max_failures:
            resolved["max_failures"] = int(env_max_failures)

    if "cooldown_seconds" not in resolved:
        env_cooldown = os.getenv("LLM_ROUTER_COOLDOWN_SECONDS")
        if env_cooldown:
            resolved["cooldown_seconds"] = int(env_cooldown)

    return RouterPolicy(**resolved)


@dataclass
class RouteTarget:
    """
    è·¯ç”±ç›®æ ‡

    Attributes:
        service: LLM æœåŠ¡å®ä¾‹
        provider: æä¾›å•†
        model: æ¨¡å‹åç§°
        name: ç›®æ ‡åç§°ï¼ˆç”¨äºæ—¥å¿—ä¸çŠ¶æ€è·Ÿè¸ªï¼‰
    """

    service: BaseLLMService
    provider: LLMProvider
    model: str
    name: str


class ModelRouter(BaseLLMService):
    """
    æ¨¡å‹è·¯ç”±å™¨ï¼ˆæ”¯æŒä¸»å¤‡åˆ‡æ¢ï¼‰
    """

    def __init__(
        self,
        primary: RouteTarget,
        fallbacks: Optional[List[RouteTarget]] = None,
        policy: Optional[Dict[str, Any]] = None,
        health_monitor: Optional[LLMHealthMonitor] = None,
    ):
        """
        åˆå§‹åŒ–è·¯ç”±å™¨

        Args:
            primary: ä¸»æ¨¡å‹
            fallbacks: å¤‡é€‰æ¨¡å‹åˆ—è¡¨
            policy: è·¯ç”±ç­–ç•¥é…ç½®
            health_monitor: å¥åº·ç›‘æ§å™¨
        """
        self.primary = primary
        self.fallbacks = fallbacks or []
        self.targets = [self.primary] + self.fallbacks
        self.policy = _resolve_policy(policy)
        self.health_monitor = health_monitor or get_llm_health_monitor()

        # ğŸ†• V7.10: æš´éœ² Primary çš„ configï¼Œä¾›ä¸Šå±‚å…¼å®¹æ€§æ£€æŸ¥ï¼ˆå¦‚ prompt cachingï¼‰
        self.config = getattr(self.primary.service, "config", None)

        # å¤±è´¥ç»Ÿè®¡
        self._failure_counts: Dict[str, int] = {t.name: 0 for t in self.targets}
        self._last_failure_ts: Dict[str, float] = {t.name: 0.0 for t in self.targets}
        self._last_selected: str = self.primary.name

    def _target_available(self, target: RouteTarget) -> bool:
        """
        åˆ¤æ–­ç›®æ ‡æ˜¯å¦å¯ç”¨

        Args:
            target: ç›®æ ‡

        Returns:
            æ˜¯å¦å¯ç”¨
        """
        if self.health_monitor and not self.health_monitor.is_healthy(target.name):
            return False

        failures = self._failure_counts.get(target.name, 0)
        if failures < self.policy.max_failures:
            return True

        # å·²è¾¾åˆ°ç†”æ–­é˜ˆå€¼ï¼Œæ£€æŸ¥å†·å´æ—¶é—´
        last_ts = self._last_failure_ts.get(target.name, 0.0)
        elapsed = time.time() - last_ts
        cooldown_passed = elapsed >= self.policy.cooldown_seconds

        if cooldown_passed:
            # ğŸ†• å†·å´æ—¶é—´å·²è¿‡ï¼Œå°è¯•æ¢å¤
            logger.info(
                f"ğŸ”„ å°è¯•æ¢å¤ç†”æ–­ç›®æ ‡: target={target.name}, " f"å†·å´æ—¶é—´å·²è¿‡={int(elapsed)}ç§’"
            )
            return True

        return False

    def _record_failure(
        self,
        target: RouteTarget,
        error: Exception,
        force_down: bool = False,
        is_probe: bool = False,
    ) -> None:
        """
        è®°å½•å¤±è´¥

        Args:
            target: ç›®æ ‡
            error: å¼‚å¸¸
            force_down: æ˜¯å¦å¼ºåˆ¶æ ‡è®°ä¸ºä¸å¯ç”¨
            is_probe: æ˜¯å¦ä¸ºæ¢æµ‹è¯·æ±‚ï¼ˆæ¢æµ‹å¤±è´¥ä¸è®°å½• WARNINGï¼‰
        """
        previous_failures = self._failure_counts.get(target.name, 0)

        if force_down:
            self._failure_counts[target.name] = max(previous_failures, self.policy.max_failures)
        else:
            self._failure_counts[target.name] = previous_failures + 1

        current_failures = self._failure_counts[target.name]
        self._last_failure_ts[target.name] = time.time()

        # æ¢æµ‹è¯·æ±‚çš„å¤±è´¥ä¸è®°å½• WARNINGï¼ˆå·²åœ¨ probe æ–¹æ³•ä¸­è®°å½• INFOï¼‰
        if not is_probe:
            # ğŸ” DEBUG: æ‰“å° API Key ä¿¡æ¯ï¼ˆè„±æ•ï¼‰
            api_key = getattr(target.service, "config", None)
            api_key = getattr(api_key, "api_key", None) if api_key else None
            if api_key:
                masked_key = f"{api_key[:8]}...{api_key[-4:]}" if len(api_key) > 12 else "***"
            else:
                masked_key = "æœªé…ç½®"

            logger.warning(
                f"âš ï¸ æ¨¡å‹è°ƒç”¨å¤±è´¥: target={target.name}, "
                f"failures={current_failures}, api_key={masked_key}, error={error}"
            )

        # ğŸ†• æ£€æµ‹æ˜¯å¦åˆšè¾¾åˆ°ç†”æ–­é˜ˆå€¼
        if previous_failures < self.policy.max_failures <= current_failures:
            logger.warning(
                f"ğŸ”’ æ¨¡å‹å·²ç†”æ–­: target={target.name}, "
                f"failures={current_failures}/{self.policy.max_failures}, "
                f"å†·å´æ—¶é—´={self.policy.cooldown_seconds}ç§’"
            )

    def _record_success(self, target: RouteTarget) -> None:
        """
        è®°å½•æˆåŠŸï¼ˆé‡ç½®å¤±è´¥è®¡æ•°ï¼‰

        Args:
            target: ç›®æ ‡
        """
        if self._failure_counts.get(target.name, 0) > 0:
            self._failure_counts[target.name] = 0
            self._last_failure_ts[target.name] = 0.0
            logger.info(f"âœ… æ¨¡å‹æ¢å¤: target={target.name}")

    def _format_target(self, target: RouteTarget) -> Dict[str, str]:
        """
        æ ¼å¼åŒ–ç›®æ ‡ä¿¡æ¯ï¼ˆç”¨äºäº‹ä»¶ä¸æ—¥å¿—ï¼‰
        """
        base_url = ""
        if hasattr(target.service, "config"):
            base_url = getattr(target.service.config, "base_url", "") or ""
        return {
            "name": target.name,
            "provider": target.provider.value,
            "model": target.model,
            "base_url": base_url,
        }

    def get_current_model(self) -> str:
        """
        è·å–å½“å‰å®é™…ä½¿ç”¨çš„æ¨¡å‹åç§°

        Returns:
            æ¨¡å‹åç§°ï¼ˆå¦‚ "qwen3-max"ï¼‰
        """
        for target in self.targets:
            if target.name == self._last_selected:
                return target.model
        # å¦‚æœæ‰¾ä¸åˆ°ï¼Œè¿”å› primary çš„æ¨¡å‹
        return self.primary.model

    def _select_targets(self) -> List[RouteTarget]:
        """
        é€‰æ‹©å¯ç”¨ç›®æ ‡

        Returns:
            ç›®æ ‡åˆ—è¡¨ï¼ˆä¼˜å…ˆçº§æ’åºï¼‰
        """
        available = [t for t in self.targets if self._target_available(t)]
        return available if available else [self.primary]

    def _filter_tools_for_provider(
        self, tools: Optional[List[Union[ToolType, str, Dict]]], provider: LLMProvider
    ) -> Optional[List[Union[ToolType, str, Dict]]]:
        """
        é’ˆå¯¹ä¸åŒæä¾›å•†è¿‡æ»¤å·¥å…·

        Args:
            tools: å·¥å…·åˆ—è¡¨
            provider: ç›®æ ‡æä¾›å•†

        Returns:
            è¿‡æ»¤åçš„å·¥å…·åˆ—è¡¨
        """
        if not tools:
            return tools
        if provider == LLMProvider.CLAUDE:
            return tools
        # é Claudeï¼šä»…ä¿ç•™ dict ç±»å‹å·¥å…·ï¼ˆé¿å… native tool å­—ç¬¦ä¸²ï¼‰
        return [tool for tool in tools if isinstance(tool, dict)]

    async def probe(
        self, max_retries: int = 3, message: str = "ping", include_unhealthy: bool = False
    ) -> Dict[str, Any]:
        """
        æœåŠ¡å­˜æ´»æ¢é’ˆï¼ˆä¸»å¤‡åˆ‡æ¢ï¼‰

        Args:
            max_retries: æ¯ä¸ªç›®æ ‡çš„æœ€å¤§é‡è¯•æ¬¡æ•°
            message: æ¢é’ˆæ¶ˆæ¯å†…å®¹
            include_unhealthy: æ˜¯å¦æ¢æµ‹ä¸å¯ç”¨ç›®æ ‡ï¼ˆç”¨äºé«˜ä¼˜å…ˆçº§æ¢å¤æ¢æµ‹ï¼‰

        Returns:
            æ¢é’ˆç»“æœï¼ˆåŒ…å«æ˜¯å¦å‘ç”Ÿåˆ‡æ¢ï¼‰
        """
        from infra.resilience.retry import retry_async

        last_error: Optional[Exception] = None
        errors: List[Dict[str, str]] = []

        targets = self.targets if include_unhealthy else self._select_targets()
        previous_selected = self._last_selected

        for target in targets:
            start_time = time.time()

            async def _call():
                return await target.service.create_message_async(
                    messages=[Message(role="user", content=message)],
                    system=None,
                    tools=None,
                    max_tokens=100,  # è½»é‡çº§æ¢é’ˆ
                    temperature=0.0,
                    override_thinking=False,  # ç¦ç”¨ thinkingï¼ˆé¿å… budget_tokens å†²çªï¼‰
                    enable_caching=False,
                    is_probe=True,  # æ ‡è®°ä¸ºæ¢æµ‹è¯·æ±‚ï¼Œé¿å… ERROR æ—¥å¿—
                )

            try:
                if target.provider == LLMProvider.CLAUDE:
                    await _call()
                else:
                    await retry_async(_call, max_retries=max_retries)

                latency_ms = (time.time() - start_time) * 1000
                if self.health_monitor:
                    self.health_monitor.record_success(target.name, latency_ms)
                self._record_success(target)
                self._last_selected = target.name

                # æ¢æµ‹æˆåŠŸæ—¶è®°å½• INFO æ—¥å¿—
                logger.info(f"âœ… æ¢æµ‹æˆåŠŸ: {target.name} ({latency_ms:.0f}ms)")

                return {
                    "primary": self._format_target(self.primary),
                    "selected": self._format_target(target),
                    "switched": target.name != previous_selected,
                    "errors": errors,
                }
            except Exception as e:
                latency_ms = (time.time() - start_time) * 1000
                if self.health_monitor:
                    self.health_monitor.record_failure(target.name, latency_ms, e)

                # æå– API key ç¯å¢ƒå˜é‡åï¼ˆç”¨äºæ—¥å¿—å±•ç¤ºï¼‰
                api_key_env = "æœªçŸ¥"
                if hasattr(target.service, "config") and hasattr(
                    target.service.config, "api_key_env"
                ):
                    api_key_env = target.service.config.api_key_env

                errors.append(
                    {
                        "target": target.name,
                        "provider": target.provider.value,
                        "model": target.model,
                        "api_key_env": api_key_env,
                        "error": str(e),
                    }
                )

                # æ¢æµ‹å¤±è´¥æ—¶è®°å½• INFO æ—¥å¿—ï¼ˆé ERRORï¼‰
                logger.info(f"âŒ æ¢æµ‹å¤±è´¥: {target.name} (å¯†é’¥: {api_key_env}) - {str(e)[:100]}")

                self._record_failure(target, e, force_down=True, is_probe=True)
                last_error = e
                continue

        raise last_error if last_error else RuntimeError("æ¨¡å‹æ¢é’ˆå¤±è´¥ï¼šæ— å¯ç”¨ç›®æ ‡")

    async def create_message_async(
        self,
        messages: List[Message],
        system: Optional[str] = None,
        tools: Optional[List[Union[ToolType, str, Dict]]] = None,
        **kwargs,
    ) -> LLMResponse:
        """
        åˆ›å»ºæ¶ˆæ¯ï¼ˆå¼‚æ­¥ï¼‰
        """
        last_error: Optional[Exception] = None

        for target in self._select_targets():
            start_time = time.time()
            try:
                filtered_tools = self._filter_tools_for_provider(tools, target.provider)
                response = await target.service.create_message_async(
                    messages=messages, system=system, tools=filtered_tools, **kwargs
                )
                latency_ms = (time.time() - start_time) * 1000
                if self.health_monitor:
                    self.health_monitor.record_success(target.name, latency_ms)
                self._record_success(target)
                self._last_selected = target.name

                # ğŸ†• è¦†ç›– response.model ä¸ºå®é™…ä½¿ç”¨çš„æ¨¡å‹ï¼ˆç”¨äºå‡†ç¡®è®¡è´¹ï¼‰
                response.model = target.service.config.model

                return response
            except Exception as e:
                latency_ms = (time.time() - start_time) * 1000
                if self.health_monitor:
                    self.health_monitor.record_failure(target.name, latency_ms, e)
                self._record_failure(target, e)
                last_error = e
                continue

        raise last_error if last_error else RuntimeError("æ¨¡å‹è°ƒç”¨å¤±è´¥ï¼šæ— å¯ç”¨ç›®æ ‡")

    async def create_message_stream(
        self,
        messages: List[Message],
        system: Optional[str] = None,
        tools: Optional[List[Union[ToolType, str, Dict]]] = None,
        on_thinking: Optional[Callable[[str], None]] = None,
        on_content: Optional[Callable[[str], None]] = None,
        on_tool_call: Optional[Callable[[Dict], None]] = None,
        **kwargs,
    ) -> AsyncIterator[LLMResponse]:
        """
        åˆ›å»ºæ¶ˆæ¯ï¼ˆæµå¼ï¼‰
        """
        last_error: Optional[Exception] = None

        for target in self._select_targets():
            yielded = False
            start_time = time.time()
            try:
                filtered_tools = self._filter_tools_for_provider(tools, target.provider)
                async for chunk in target.service.create_message_stream(
                    messages=messages,
                    system=system,
                    tools=filtered_tools,
                    on_thinking=on_thinking,
                    on_content=on_content,
                    on_tool_call=on_tool_call,
                    **kwargs,
                ):
                    yielded = True
                    # ğŸ†• è¦†ç›– chunk.model ä¸ºå®é™…ä½¿ç”¨çš„æ¨¡å‹ï¼ˆç”¨äºå‡†ç¡®è®¡è´¹ï¼‰
                    chunk.model = target.service.config.model
                    yield chunk
                latency_ms = (time.time() - start_time) * 1000
                if self.health_monitor:
                    self.health_monitor.record_success(target.name, latency_ms)
                self._record_success(target)
                self._last_selected = target.name
                return
            except Exception as e:
                latency_ms = (time.time() - start_time) * 1000
                if self.health_monitor:
                    self.health_monitor.record_failure(target.name, latency_ms, e)
                self._record_failure(target, e)
                last_error = e
                # å·²ç»å¼€å§‹è¾“å‡ºæ—¶ä¸åˆ‡æ¢ï¼Œé¿å…é‡å¤è¾“å‡º
                if yielded:
                    raise
                continue

        raise last_error if last_error else RuntimeError("æ¨¡å‹æµå¼è°ƒç”¨å¤±è´¥ï¼šæ— å¯ç”¨ç›®æ ‡")

    def count_tokens(self, text: str) -> int:
        """
        è®¡ç®— token æ•°é‡ï¼ˆä½¿ç”¨ä¸»æ¨¡å‹ä¼°ç®—ï¼‰

        Args:
            text: æ–‡æœ¬å†…å®¹

        Returns:
            token æ•°é‡
        """
        return self.primary.service.count_tokens(text)

    def supports_native_tools(self) -> bool:
        """
        è·¯ç”±å™¨æ˜¯å¦æ”¯æŒåŸç”Ÿå·¥å…·ï¼ˆä»¥ä¸»æ¨¡å‹ä¸ºå‡†ï¼‰
        """
        if hasattr(self.primary.service, "supports_native_tools"):
            return self.primary.service.supports_native_tools()
        return False

    def supports_skills(self) -> bool:
        """
        è·¯ç”±å™¨æ˜¯å¦æ”¯æŒ Skillsï¼ˆä»¥ä¸»æ¨¡å‹ä¸ºå‡†ï¼‰
        """
        if hasattr(self.primary.service, "supports_skills"):
            return self.primary.service.supports_skills()
        return False

    def add_custom_tool(self, name: str, description: str, input_schema: Dict[str, Any]) -> None:
        """
        æ³¨å†Œè‡ªå®šä¹‰å·¥å…·
        """
        for target in self.targets:
            if hasattr(target.service, "add_custom_tool"):
                target.service.add_custom_tool(
                    name=name, description=description, input_schema=input_schema
                )

    def convert_to_claude_tool(self, capability: Dict[str, Any]) -> Dict[str, Any]:
        """
        å…¼å®¹å·¥å…·è½¬æ¢ï¼ˆä¼˜å…ˆä½¿ç”¨ä¸»æ¨¡å‹çš„è½¬æ¢é€»è¾‘ï¼‰

        Args:
            capability: å·¥å…·å®šä¹‰

        Returns:
            Claude æ ¼å¼å·¥å…·å®šä¹‰
        """
        if hasattr(self.primary.service, "convert_to_claude_tool"):
            return self.primary.service.convert_to_claude_tool(capability)
        return capability
