"""
ä¸Šä¸‹æ–‡å‹ç¼©æ¨¡å—

æ¶æ„å†³ç­–ï¼šåŸºäºå½“å‰ RVR æ¶æ„ï¼ˆé tool_runnerï¼‰ï¼Œé‡‡ç”¨ä»¥ä¸‹ç­–ç•¥ï¼š

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ç­–ç•¥å±‚çº§ï¼ˆä»ç”¨æˆ·ä½“éªŒå’Œæ•ˆæœä¼˜å…ˆï¼‰                            â”‚
â”‚                                                              â”‚
â”‚  L1. Memory Tool çŠ¶æ€ä¿å­˜ï¼ˆClaude è‡ªä¸»ï¼‰                     â”‚
â”‚      â†’ å‘Šè¯‰ Claude ä½¿ç”¨ memory å·¥å…·ä¿å­˜é‡è¦å‘ç°              â”‚
â”‚      â†’ è·¨ context window ä¿æŒçŠ¶æ€è¿ç»­æ€§                      â”‚
â”‚                                                              â”‚
â”‚  L2. å†å²æ¶ˆæ¯æ™ºèƒ½è£å‰ªï¼ˆæœåŠ¡å±‚è‡ªåŠ¨ï¼‰                          â”‚
â”‚      â†’ ä¿ç•™å…³é”®æ¶ˆæ¯ï¼šé¦–è½® + æœ€è¿‘ N è½® + tool_result          â”‚
â”‚      â†’ ä¸­é—´è½®æ¬¡ä¸¢å¼ƒç»†èŠ‚ï¼Œä¿ç•™æ‘˜è¦                            â”‚
â”‚                                                              â”‚
â”‚  L3. QoS æˆæœ¬æ§åˆ¶ï¼ˆåç«¯é™é»˜ï¼‰                                â”‚
â”‚      â†’ æ ¹æ®ç”¨æˆ·ç­‰çº§è®¾ç½® token é¢„ç®—                           â”‚
â”‚      â†’ ä»…ç”¨äºæˆæœ¬ç»Ÿè®¡ï¼Œä¸å½±å“ç”¨æˆ·ä½“éªŒ                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æ ¸å¿ƒåŸåˆ™ï¼š
1. é™é»˜å¤„ç†ï¼Œç”¨æˆ·æ— æ„ŸçŸ¥
2. ä¸è­¦å‘Šç”¨æˆ·ï¼Œä¸å»ºè®®å¼€å¯æ–°ä¼šè¯
3. ä¼˜å…ˆä¿è¯é—®ç­”æ•ˆæœï¼Œå…¶æ¬¡æ§åˆ¶æˆæœ¬

å‚è€ƒæ–‡æ¡£ï¼š
- https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/claude-4-best-practices
"""

from dataclasses import dataclass, field
from enum import Enum
from typing import Any, Dict, List, Optional, Tuple

from core.llm.base import (
    count_message_tokens,
    count_messages_tokens,
    count_request_tokens,
    count_tokens,
    count_tools_tokens,
)
from logger import get_logger

logger = get_logger("context.compaction")


class QoSLevel(str, Enum):
    """
    æœåŠ¡è´¨é‡ç­‰çº§

    ä»…ç”¨äºåç«¯æˆæœ¬æ§åˆ¶å’Œè®¡è´¹ï¼Œä¸å½±å“ç”¨æˆ·ä½“éªŒ
    """

    FREE = "free"  # å…è´¹ç”¨æˆ·ï¼š50K tokens
    BASIC = "basic"  # åŸºç¡€ä»˜è´¹ï¼š150K tokens
    PRO = "pro"  # ä¸“ä¸šç‰ˆï¼š200K tokensï¼ˆé»˜è®¤ï¼‰
    ENTERPRISE = "enterprise"  # ä¼ä¸šç‰ˆï¼š1M tokens


# QoS ç­‰çº§å¯¹åº”çš„ token é¢„ç®—
QOS_TOKEN_BUDGETS: Dict[QoSLevel, int] = {
    QoSLevel.FREE: 50_000,
    QoSLevel.BASIC: 150_000,
    QoSLevel.PRO: 200_000,
    QoSLevel.ENTERPRISE: 1_000_000,
}


@dataclass
class ContextStrategy:
    """
    ä¸Šä¸‹æ–‡ç®¡ç†ç­–ç•¥é…ç½®

    L1: Memory Tool æŒ‡å¯¼ï¼ˆé€šè¿‡ System Promptï¼‰
    L2: å†å²æ¶ˆæ¯è£å‰ªï¼ˆçº¯ token é©±åŠ¨ï¼ŒæœåŠ¡å±‚è‡ªåŠ¨æ‰§è¡Œï¼‰
    L3: QoS æˆæœ¬æ§åˆ¶ï¼ˆåç«¯é™é»˜ï¼‰

    é…ç½®æ¥æºä¼˜å…ˆçº§ï¼š
    1. å®ä¾‹é…ç½® config.yaml ä¸­çš„ context_management å­—æ®µ
    2. æ¡†æ¶é»˜è®¤å€¼
    """

    # L1: Memory Tool æŒ‡å¯¼
    # å¯åœ¨å®ä¾‹ config.yaml ä¸­é…ç½®ï¼šcontext_management.enable_memory_guidance
    enable_memory_guidance: bool = True  # æ˜¯å¦åœ¨ Prompt ä¸­æ·»åŠ  Memory ä½¿ç”¨æŒ‡å¯¼

    # L2: å†å²æ¶ˆæ¯å‹ç¼©ï¼ˆåŒé˜ˆå€¼æœºåˆ¶ï¼‰
    # å¯åœ¨å®ä¾‹ config.yaml ä¸­é…ç½®ï¼šcontext_management.enable_history_trimming
    enable_history_trimming: bool = True  # æ˜¯å¦å¯ç”¨å†å²æ¶ˆæ¯å‹ç¼©
    preserve_first_messages: int = 4  # å§‹ç»ˆä¿ç•™å¼€å¤´ N æ¡æ¶ˆæ¯ï¼ˆä»»åŠ¡ä¸Šä¸‹æ–‡ï¼‰
    preserve_last_messages: int = 10  # å°½é‡ä¿ç•™æœ€è¿‘ N æ¡æ¶ˆæ¯ï¼ˆå½“å‰ä¸Šä¸‹æ–‡ï¼‰
    preserve_tool_results: bool = True  # ä¿ç•™ä¸­é—´çš„ tool_resultï¼ˆå«é‡è¦æ•°æ®ï¼‰

    # ğŸ†• åŒé˜ˆå€¼å‹ç¼©æœºåˆ¶
    pre_run_threshold: float = 0.80  # 80% é˜ˆå€¼ - è¿è¡Œå‰é¢„æ£€æŸ¥ï¼ˆAgent å¯åŠ¨å‰ï¼‰
    runtime_threshold: float = 0.92  # 92% é˜ˆå€¼ - è¿è¡Œä¸­å®æ—¶æ£€æŸ¥ï¼ˆAgent æ‰§è¡Œä¸­ï¼‰

    # L3: QoS æˆæœ¬æ§åˆ¶
    qos_level: QoSLevel = QoSLevel.PRO
    token_budget: int = 200_000
    warning_threshold: float = 0.8  # 80% æ—¶åç«¯æ—¥å¿—è­¦å‘Šï¼ˆç”¨æˆ·æ— æ„ŸçŸ¥ï¼‰


@dataclass
class TrimStats:
    """
    å†å²æ¶ˆæ¯è£å‰ªç»Ÿè®¡ä¿¡æ¯

    ç”¨äºå•æ¬¡éå†åŒæ—¶å®Œæˆè£å‰ªå’Œ token ä¼°ç®—ï¼Œé¿å…é‡å¤éå†ã€‚
    """

    original_count: int = 0  # åŸå§‹æ¶ˆæ¯æ•°é‡
    trimmed_count: int = 0  # è£å‰ªåæ¶ˆæ¯æ•°é‡
    estimated_tokens: int = 0  # ä¼°ç®—çš„ token æ•°
    exceeded_budget: bool = False  # æ˜¯å¦è¶…è¿‡é¢„ç®—é˜ˆå€¼
    should_warn: bool = False  # æ˜¯å¦åº”è¯¥åç«¯è­¦å‘Š

    # ğŸ†• æ‘˜è¦ç›¸å…³
    has_summary: bool = False  # æ˜¯å¦åŒ…å«æ‘˜è¦
    summary_tokens: int = 0  # æ‘˜è¦ä½¿ç”¨çš„ token æ•°
    compressed_message_count: int = 0  # è¢«å‹ç¼©ä¸ºæ‘˜è¦çš„æ¶ˆæ¯æ•°é‡


def get_context_strategy(qos_level: QoSLevel = QoSLevel.PRO) -> ContextStrategy:
    """
    è·å–ä¸Šä¸‹æ–‡ç®¡ç†ç­–ç•¥

    é…ç½®æ¥æºï¼š
    1. ç¯å¢ƒå˜é‡ QOS_LEVELï¼ˆæ§åˆ¶ QoS ç­‰çº§ï¼‰
    2. æ¡†æ¶é…ç½® config/context_compaction.yaml

    æ³¨æ„ï¼šä¸ä»å®ä¾‹é…ç½®è¯»å–ï¼Œè¿è¥äººå‘˜æ— éœ€é…ç½®æ­¤é¡¹

    Args:
        qos_level: QoS ç­‰çº§ï¼ˆé»˜è®¤ PROï¼‰

    Returns:
        ContextStrategy å®ä¾‹
    """
    return ContextStrategy(
        qos_level=qos_level, token_budget=QOS_TOKEN_BUDGETS.get(qos_level, 200_000)
    )


def get_memory_guidance_prompt() -> str:
    """
    è·å– Memory Tool ä½¿ç”¨æŒ‡å¯¼ï¼ˆL1 ç­–ç•¥ï¼‰

    æ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼šMemory Tool ä¸ Context Awareness è‡ªç„¶é…å¯¹
    ç”¨äºè·¨ context window ä¿æŒçŠ¶æ€è¿ç»­æ€§

    æ³¨æ„ï¼šè¿™é‡Œä¸å†è¯´"ä¸Šä¸‹æ–‡ä¼šè‡ªåŠ¨å‹ç¼©"ï¼ˆå› ä¸ºæˆ‘ä»¬æ²¡ç”¨ tool_runnerï¼‰
    è€Œæ˜¯æŒ‡å¯¼ Claude ä¸»åŠ¨ä½¿ç”¨ Memory Tool ä¿å­˜é‡è¦çŠ¶æ€

    Returns:
        Memory ä½¿ç”¨æŒ‡å¯¼ Prompt
    """
    return """## ğŸ§  Long-Running Task Guidelines

For complex or multi-step tasks:

1. **Save Important Discoveries**
   - Use the `memory` tool to store key findings, decisions, and progress
   - Save any data that would be costly to re-compute or re-discover

2. **State Management**
   - Periodically save your current state and next steps
   - This ensures continuity if the conversation is long

3. **Work Autonomously**
   - Complete tasks fully without stopping early
   - Break complex tasks into manageable steps
   - Make steady progress on a few things at a time

4. **Preserve Critical Context**
   - File paths, configurations, and user preferences
   - Error patterns and solutions found
   - Progress markers for multi-file operations"""


def _has_tool_result(msg: Dict[str, Any]) -> bool:
    """
    æ£€æŸ¥æ¶ˆæ¯æ˜¯å¦åŒ…å« tool_result

    Args:
        msg: æ¶ˆæ¯å­—å…¸

    Returns:
        æ˜¯å¦åŒ…å« tool_result
    """
    content = msg.get("content", "")
    if isinstance(content, list):
        return any(
            isinstance(block, dict) and block.get("type") == "tool_result" for block in content
        )
    return False


# ============================================================
# å¿«é€Ÿå­—ç¬¦çº§é¢„è¿‡æ»¤ï¼ˆé˜²æ­¢å¤§ä¸Šä¸‹æ–‡å¯¼è‡´åç»­ token è®¡ç®—å»¶è¿Ÿï¼‰
# ============================================================

# å•æ¡æ¶ˆæ¯å†…å®¹çš„ç¡¬ä¸Šé™ï¼ˆå­—ç¬¦æ•°ï¼‰â€”â€” ä»»ä½•å•æ¡ tool_result ä¸å…è®¸è¶…è¿‡æ­¤å€¼è¿›å…¥å†å²
# è¿™æ˜¯åœ¨æ˜‚è´µçš„ token è®¡ç®—ä¹‹å‰çš„ O(n) å¿«é€Ÿé¢„è¿‡æ»¤ï¼Œé˜²æ­¢ä¸Šä¸‹æ–‡è†¨èƒ€
_MAX_SINGLE_CONTENT_CHARS = 3000

# æ€»æ¶ˆæ¯å­—ç¬¦æ•°çš„å¿«é€Ÿé¢„æ£€é˜ˆå€¼ï¼ˆè¶…è¿‡æ­¤å€¼æ—¶è§¦å‘æ¿€è¿›è£å‰ªï¼Œé¿å… token è®¡ç®—å»¶è¿Ÿï¼‰
# çº¦ç­‰äº token_budget * 4ï¼ˆ1 token â‰ˆ 4 chars ç²—ç•¥ä¼°ç®—ï¼‰
_FAST_PREFILTER_TOTAL_CHARS = 600_000


def _fast_cap_message_content(content: Any, cap: int = _MAX_SINGLE_CONTENT_CHARS) -> Any:
    """
    å¿«é€Ÿæˆªæ–­å•æ¡æ¶ˆæ¯å†…å®¹åˆ°ç¡¬ä¸Šé™ï¼ˆ<0.01ms per messageï¼‰

    ä¸åš token è®¡ç®—ï¼Œçº¯å­—ç¬¦æˆªæ–­ã€‚ç”¨äºé˜²æ­¢è¶…å¤§ tool_result
    åœ¨è¿›å…¥ token è®¡ç®—æµç¨‹å‰å°±è¢«æ§åˆ¶ä½ã€‚
    """
    if isinstance(content, str):
        if len(content) <= cap:
            return content
        head = cap * 2 // 3  # 2/3 ç»™å¤´éƒ¨
        tail = cap // 3      # 1/3 ç»™å°¾éƒ¨
        return (
            content[:head]
            + f"\n\n... (å·²æˆªæ–­: åŸæ–‡ {len(content)} å­—ç¬¦, ä¿ç•™å¤´ {head} + å°¾ {tail}) ...\n\n"
            + content[-tail:]
        )

    if isinstance(content, list):
        capped = []
        for block in content:
            if isinstance(block, dict):
                if block.get("type") == "text":
                    text = block.get("text", "")
                    if len(text) > cap:
                        head = cap * 2 // 3
                        tail = cap // 3
                        capped.append({
                            **block,
                            "text": (
                                text[:head]
                                + f"\n... (å·²æˆªæ–­: åŸæ–‡ {len(text)} å­—ç¬¦) ...\n"
                                + text[-tail:]
                            ),
                        })
                    else:
                        capped.append(block)
                elif block.get("type") == "tool_result":
                    # é€’å½’å¤„ç†åµŒå¥—çš„ tool_result content
                    inner = block.get("content", "")
                    capped_inner = _fast_cap_message_content(inner, cap)
                    if capped_inner is not inner:
                        capped.append({**block, "content": capped_inner})
                    else:
                        capped.append(block)
                else:
                    capped.append(block)
            else:
                capped.append(block)
        return capped

    return content


def fast_prefilter_messages(
    messages: List[Dict[str, Any]],
    per_message_cap: int = _MAX_SINGLE_CONTENT_CHARS,
) -> List[Dict[str, Any]]:
    """
    å¿«é€Ÿå­—ç¬¦çº§é¢„è¿‡æ»¤ï¼šåœ¨æ˜‚è´µçš„ token è®¡ç®—ä¹‹å‰æˆªæ–­è¶…å¤§æ¶ˆæ¯ï¼ˆO(n), <1msï¼‰

    ç›®çš„ï¼šé˜²æ­¢ä¸Šä¸‹æ–‡è†¨èƒ€å¯¼è‡´ count_message_tokens ç­‰æ“ä½œæœ¬èº«å˜æ…¢ã€‚
    åœ¨ token è®¡ç®—ä¹‹å‰å…ˆåšä¸€éç²—ç²’åº¦æˆªæ–­ï¼Œç¡®ä¿æ¯æ¡æ¶ˆæ¯å†…å®¹éƒ½åœ¨åˆç†èŒƒå›´å†…ã€‚

    Args:
        messages: æ¶ˆæ¯åˆ—è¡¨
        per_message_cap: å•æ¡æ¶ˆæ¯å†…å®¹çš„å­—ç¬¦ç¡¬ä¸Šé™

    Returns:
        é¢„è¿‡æ»¤åçš„æ¶ˆæ¯åˆ—è¡¨
    """
    if not messages:
        return messages

    # å¿«é€Ÿä¼°ç®—æ€»å­—ç¬¦æ•°ï¼ˆO(n), <0.1msï¼‰
    total_chars = sum(len(str(m.get("content", ""))) for m in messages)
    if total_chars <= _FAST_PREFILTER_TOTAL_CHARS:
        return messages  # æ€»é‡åœ¨å®‰å…¨èŒƒå›´å†…ï¼Œè·³è¿‡é¢„è¿‡æ»¤

    # è¶…è¿‡é˜ˆå€¼ï¼Œé€æ¡æˆªæ–­
    capped_count = 0
    result = []
    for msg in messages:
        content = msg.get("content")
        if content is None:
            result.append(msg)
            continue
        capped = _fast_cap_message_content(content, per_message_cap)
        if capped is not content:
            result.append({**msg, "content": capped})
            capped_count += 1
        else:
            result.append(msg)

    if capped_count > 0:
        new_total = sum(len(str(m.get("content", ""))) for m in result)
        logger.warning(
            f"âš¡ å¿«é€Ÿé¢„è¿‡æ»¤: æˆªæ–­ {capped_count} æ¡è¶…å¤§æ¶ˆæ¯ "
            f"(æ€»å­—ç¬¦ {total_chars:,} â†’ {new_total:,})"
        )

    return result


# ============================================================
# tool_result å†…å®¹çº§å‹ç¼©ï¼ˆå³æ—¶ï¼ŒO(n)ï¼Œé›¶ LLM è°ƒç”¨ï¼‰
# ============================================================

# tool_result å†…å®¹è¶…è¿‡æ­¤å­—ç¬¦æ•°æ—¶è§¦å‘æˆªæ–­ï¼ˆå†å²æ¶ˆæ¯ä¸­çš„ tool_resultï¼‰
_TOOL_RESULT_TRUNCATE_THRESHOLD = 300
# æˆªæ–­åä¿ç•™çš„å¤´å°¾å­—ç¬¦æ•°
_TOOL_RESULT_KEEP_HEAD = 150
_TOOL_RESULT_KEEP_TAIL = 80

# Immediate compression threshold for fresh tool results (before appending to messages)
# This prevents recent large tool_results from bloating context
_IMMEDIATE_COMPRESS_THRESHOLD = 1500
_IMMEDIATE_KEEP_HEAD = 500
_IMMEDIATE_KEEP_TAIL = 200


def _compress_tool_result_content(content: Any) -> Any:
    """
    å‹ç¼©å•ä¸ª tool_result çš„ content å­—æ®µ

    ç­–ç•¥ï¼š
    - å·²è¢« ToolResultCompressor å³æ—¶å‹ç¼©çš„å†…å®¹ï¼ˆå¸¦ COMPRESSED æ ‡è®°ï¼‰â†’ è·³è¿‡ï¼Œé˜²æ­¢äºŒæ¬¡æˆªæ–­
    - å­—ç¬¦ä¸²è¶…é•¿ â†’ ä¿ç•™å¤´ 200 + å°¾ 100 å­—ç¬¦ + æˆªæ–­æ ‡è®°
    - list of blocks â†’ é€’å½’å‹ç¼©æ¯ä¸ª text block
    - å…¶ä»– â†’ ä¸å˜
    """
    if isinstance(content, str):
        if len(content) <= _TOOL_RESULT_TRUNCATE_THRESHOLD:
            return content
        # é˜²æ­¢äºŒæ¬¡å‹ç¼©ï¼šå·²è¢« ToolResultCompressor å‹ç¼©çš„ç»“æœåŒ…å«æ–‡ä»¶è·¯å¾„å¼•ç”¨ï¼Œ
        # æˆªæ–­ä¼šä¸¢å¤±è·¯å¾„ï¼Œå¯¼è‡´ Agent æ— æ³•é€šè¿‡ cat æŸ¥çœ‹å®Œæ•´å†…å®¹
        if content.startswith("[COMPRESSED:"):
            return content
        return (
            content[:_TOOL_RESULT_KEEP_HEAD]
            + f"\n\n... (å·²çœç•¥ {len(content) - _TOOL_RESULT_KEEP_HEAD - _TOOL_RESULT_KEEP_TAIL} å­—ç¬¦) ...\n\n"
            + content[-_TOOL_RESULT_KEEP_TAIL:]
        )

    if isinstance(content, list):
        compressed = []
        for block in content:
            if isinstance(block, dict):
                block_type = block.get("type", "")
                if block_type == "text":
                    text = block.get("text", "")
                    # é˜²æ­¢äºŒæ¬¡å‹ç¼©
                    if text.startswith("[COMPRESSED:"):
                        compressed.append(block)
                    elif len(text) > _TOOL_RESULT_TRUNCATE_THRESHOLD:
                        compressed.append({
                            **block,
                            "text": (
                                text[:_TOOL_RESULT_KEEP_HEAD]
                                + f"\n... (å·²çœç•¥ {len(text) - _TOOL_RESULT_KEEP_HEAD - _TOOL_RESULT_KEEP_TAIL} å­—ç¬¦) ...\n"
                                + text[-_TOOL_RESULT_KEEP_TAIL:]
                            ),
                        })
                    else:
                        compressed.append(block)
                elif block_type == "image":
                    compressed.append({"type": "text", "text": "[å›¾ç‰‡å·²çœç•¥]"})
                elif block_type == "input_audio":
                    compressed.append({"type": "text", "text": "[éŸ³é¢‘å·²çœç•¥]"})
                else:
                    compressed.append(block)
            else:
                compressed.append(block)
        return compressed

    return content


def _try_fold_plan_tool_result(content: Any) -> Optional[str]:
    """Fold old plan tool_result into a one-line summary (zero LLM, <0.1ms).

    Detects plan tool results by checking for "success" + "plan" keys in JSON,
    then extracts plan name + todo statuses into a compact string.

    Returns:
        Folded string if content is a plan result, None otherwise.
    """
    import json as _json

    text = content if isinstance(content, str) else str(content) if content else ""
    if len(text) < 10 or '"plan"' not in text:
        return None

    try:
        data = _json.loads(text) if isinstance(text, str) else None
        if not isinstance(data, dict):
            return None
        if "success" not in data or "plan" not in data:
            return None
        plan = data["plan"]
        if not isinstance(plan, dict):
            return None

        name = plan.get("name", "")
        todos = plan.get("todos", [])
        if not todos:
            return f"[plan] {name} (æ— æ­¥éª¤)"

        status_icons = {"completed": "âœ“", "in_progress": "â†’", "failed": "âœ—"}
        total = len(todos)
        completed = sum(1 for t in todos if t.get("status") == "completed")
        parts = []
        for t in todos:
            icon = status_icons.get(t.get("status", "pending"), "â—‹")
            # ä¼˜å…ˆä½¿ç”¨ contentï¼ˆå®Œæ•´æ­¥éª¤æè¿°ï¼‰ï¼Œfallback åˆ° title
            title = (t.get("content") or t.get("title", ""))[:30]
            parts.append(f"{icon}{title}")

        return f"[plan] {name}ï¼ˆ{completed}/{total}ï¼‰: {', '.join(parts)}"

    except (ValueError, TypeError, KeyError):
        return None


def compress_fresh_tool_result(content: str) -> str:
    """Compress a fresh tool result BEFORE appending to messages.

    Unlike _compress_old_tool_results (which only handles old messages),
    this compresses immediately â€” preventing large tool outputs from
    bloating context from the start.

    Threshold: 1500 chars (vs 300 for old messages).
    Keeps more context (head=500 + tail=200) since this is recent/relevant.

    Args:
        content: Raw tool result string.

    Returns:
        Compressed string if over threshold, original otherwise.
    """
    if not isinstance(content, str):
        return content
    if len(content) <= _IMMEDIATE_COMPRESS_THRESHOLD:
        return content

    omitted = len(content) - _IMMEDIATE_KEEP_HEAD - _IMMEDIATE_KEEP_TAIL
    return (
        content[:_IMMEDIATE_KEEP_HEAD]
        + f"\n\n... (å·²çœç•¥ {omitted:,} å­—ç¬¦ï¼Œå®Œæ•´ç»“æœå·²ä¿å­˜) ...\n\n"
        + content[-_IMMEDIATE_KEEP_TAIL:]
    )


def _build_tool_name_map(messages: List[Dict[str, Any]]) -> Dict[str, str]:
    """
    Build a mapping from tool_use_id to tool name.

    Scans all assistant messages for tool_use blocks and records id -> name.
    Used by _compress_old_tool_results to check skip_tools whitelist.

    Args:
        messages: full message list

    Returns:
        Dict mapping tool_use_id to tool name
    """
    mapping: Dict[str, str] = {}
    for msg in messages:
        if msg.get("role") != "assistant":
            continue
        content = msg.get("content")
        if not isinstance(content, list):
            continue
        for block in content:
            if isinstance(block, dict) and block.get("type") == "tool_use":
                tool_id = block.get("id")
                tool_name = block.get("name", "")
                if tool_id and tool_name:
                    mapping[tool_id] = tool_name
    return mapping


def _load_skip_tools() -> set:
    """
    Load skip_tools whitelist from context_compaction.yaml.

    Returns:
        Set of tool names that should not be compressed.
    """
    try:
        import yaml
        from pathlib import Path

        config_paths = [
            Path("config/context_compaction.yaml"),
            Path(__file__).resolve().parents[3] / "config" / "context_compaction.yaml",
        ]
        for path in config_paths:
            if path.exists():
                with open(path, "r", encoding="utf-8") as f:
                    config = yaml.safe_load(f) or {}
                tools = config.get("tool_result_compressor", {}).get("skip_tools", [])
                if tools:
                    return set(tools)
    except Exception as e:
        logger.debug(f"åŠ è½½ skip_tools é…ç½®å¤±è´¥: {e}")
    return set()


# Module-level cache (loaded once)
_SKIP_TOOLS: Optional[set] = None


def _get_skip_tools() -> set:
    """Get skip_tools whitelist (cached after first load)."""
    global _SKIP_TOOLS
    if _SKIP_TOOLS is None:
        _SKIP_TOOLS = _load_skip_tools()
        if _SKIP_TOOLS:
            logger.info(f"ğŸ“‹ skip_tools ç™½åå•å·²åŠ è½½: {sorted(_SKIP_TOOLS)}")
    return _SKIP_TOOLS


def _compress_old_tool_results(
    messages: List[Dict[str, Any]],
    preserve_recent_n: int = 4,
) -> List[Dict[str, Any]]:
    """
    å‹ç¼©éæœ€è¿‘æ¶ˆæ¯ä¸­çš„ tool_result å†…å®¹ï¼ˆå³æ—¶ï¼ŒO(n)ï¼Œé›¶ LLM è°ƒç”¨ï¼‰

    ä¿ç•™æœ€è¿‘ N æ¡æ¶ˆæ¯çš„ tool_result åŸæ–‡ä¸åŠ¨ï¼Œ
    æ›´æ—©çš„æ¶ˆæ¯ä¸­è¶…é•¿çš„ tool_result å†…å®¹æˆªæ–­ä¸ºå¤´+å°¾ã€‚

    ç™½åå•å·¥å…·ï¼ˆconfig/context_compaction.yaml skip_toolsï¼‰çš„ç»“æœä¸è¢«å‹ç¼©ï¼Œ
    å› ä¸º planã€memoryã€hitl ç­‰å·¥å…·çš„ç»“æœå½±å“æµç¨‹æ§åˆ¶ã€‚

    Args:
        messages: æ¶ˆæ¯åˆ—è¡¨
        preserve_recent_n: ä¿ç•™æœ€è¿‘ N æ¡æ¶ˆæ¯ä¸å‹ç¼©

    Returns:
        å‹ç¼©åçš„æ¶ˆæ¯åˆ—è¡¨
    """
    if not messages:
        return messages

    boundary = len(messages) - preserve_recent_n
    if boundary <= 0:
        return messages

    # æ„å»º tool_use_id â†’ tool_name æ˜ å°„ + åŠ è½½ç™½åå•
    tool_name_map = _build_tool_name_map(messages)
    skip_tools = _get_skip_tools()

    compressed_count = 0
    skipped_count = 0
    result = []

    for i, msg in enumerate(messages):
        if i >= boundary:
            result.append(msg)
            continue

        content = msg.get("content")
        if not isinstance(content, list):
            result.append(msg)
            continue

        # æ£€æŸ¥æ˜¯å¦åŒ…å« tool_result
        has_tr = any(
            isinstance(b, dict) and b.get("type") == "tool_result"
            for b in content
        )
        if not has_tr:
            result.append(msg)
            continue

        # å‹ç¼© tool_result å†…å®¹
        new_content = []
        changed = False
        for block in content:
            if isinstance(block, dict) and block.get("type") == "tool_result":
                # ç™½åå•æ£€æŸ¥ï¼šé€šè¿‡ tool_use_id åæŸ¥å·¥å…·å
                tool_use_id = block.get("tool_use_id", "")
                tool_name = tool_name_map.get(tool_use_id, "")
                if tool_name in skip_tools:
                    new_content.append(block)
                    skipped_count += 1
                    continue

                original = block.get("content", "")
                # P1: Plan update ç‰¹æ®ŠæŠ˜å  â€” æ—§ plan tool_result æŠ˜å ä¸ºä¸€è¡Œæ‘˜è¦
                folded = _try_fold_plan_tool_result(original)
                if folded is not None:
                    new_content.append({**block, "content": folded})
                    changed = True
                    continue
                compressed = _compress_tool_result_content(original)
                if compressed is not original:
                    new_content.append({**block, "content": compressed})
                    changed = True
                else:
                    new_content.append(block)
            else:
                new_content.append(block)

        if changed:
            compressed_count += 1
            result.append({**msg, "content": new_content})
        else:
            result.append(msg)

    if compressed_count > 0 or skipped_count > 0:
        logger.info(
            f"ğŸ“¦ tool_result å‹ç¼©: {compressed_count} æ¡å·²å‹ç¼©, "
            f"{skipped_count} æ¡å› ç™½åå•è·³è¿‡"
        )

    return result


def trim_by_token_budget(
    messages: List[Dict[str, Any]],
    token_budget: int,
    preserve_first_messages: int = 4,
    preserve_last_messages: int = 10,
    preserve_tool_results: bool = True,
    system_prompt: str = "",
) -> Tuple[List[Dict[str, Any]], TrimStats]:
    """
    åŸºäº token é¢„ç®—è£å‰ªæ¶ˆæ¯ï¼ˆçº¯ token é©±åŠ¨ï¼ŒL2 ç­–ç•¥æ ¸å¿ƒå®ç°ï¼‰

    è£å‰ªé€»è¾‘ï¼š
    0. å…ˆå‹ç¼©æ—§æ¶ˆæ¯ä¸­çš„ tool_result å†…å®¹ï¼ˆå³æ—¶ï¼Œé›¶ LLM è°ƒç”¨ï¼‰
    1. ä¼°ç®—æ€» token æ•°ï¼Œå¦‚æœæœªè¶…é¢„ç®—åˆ™ç›´æ¥è¿”å›
    2. å§‹ç»ˆä¿ç•™å¼€å¤´ N æ¡æ¶ˆæ¯ï¼ˆä»»åŠ¡ä¸Šä¸‹æ–‡ï¼‰
    3. ä»æœ€è¿‘æ¶ˆæ¯å‘å‰ç´¯è®¡ tokenï¼Œæ‰¾åˆ°é¢„ç®—åˆ†å‰²ç‚¹
    4. ä¸­é—´éƒ¨åˆ†å¯é€‰ä¿ç•™ tool_result æ¶ˆæ¯ï¼ˆå«é‡è¦æ•°æ®ï¼‰

    Args:
        messages: æ¶ˆæ¯åˆ—è¡¨
        token_budget: token é¢„ç®—ä¸Šé™
        preserve_first_messages: å§‹ç»ˆä¿ç•™å¼€å¤´ N æ¡æ¶ˆæ¯
        preserve_last_messages: å°½é‡ä¿ç•™æœ€è¿‘ N æ¡æ¶ˆæ¯
        preserve_tool_results: æ˜¯å¦ä¿ç•™ä¸­é—´çš„ tool_result æ¶ˆæ¯
        system_prompt: ç³»ç»Ÿæç¤ºè¯ï¼ˆè®¡å…¥ tokenï¼‰

    Returns:
        (è£å‰ªåçš„æ¶ˆæ¯, ç»Ÿè®¡ä¿¡æ¯)
    """
    # Step -1: å¿«é€Ÿå­—ç¬¦çº§é¢„è¿‡æ»¤ï¼ˆ<1msï¼‰ï¼Œé˜²æ­¢è¶…å¤§æ¶ˆæ¯å¯¼è‡´åç»­ token è®¡ç®—å»¶è¿Ÿ
    messages = fast_prefilter_messages(messages)

    # Step 0: åˆ†çº§å‹ç¼©æ—§æ¶ˆæ¯ä¸­è¶…é•¿çš„ tool_result å†…å®¹ï¼ˆå³æ—¶ï¼ŒO(n)ï¼Œé›¶ LLM è°ƒç”¨ï¼‰
    # ä¿ç•™æœ€è¿‘ 4 æ¡æ¶ˆæ¯ï¼ˆçº¦ 2 è½®å¯¹è¯ï¼‰çš„ tool_result åŸæ–‡
    # ç¬¬ 5 æ¡ä»¥å‰çš„ tool_result æˆªæ–­ä¸ºå¤´+å°¾
    messages = _compress_old_tool_results(messages, preserve_recent_n=min(4, preserve_last_messages))

    original_count = len(messages)

    # ---------- P0: ç»å¯¹ä¸Šé™å‘Šè­¦ ----------
    # åœ¨æ˜‚è´µçš„ token è®¡ç®—å‰åšç²—ç•¥ä¼°ç®—ï¼ˆ1 char â‰ˆ 0.33 tokenï¼‰
    _ABSOLUTE_WARN_TOKENS = 50_000
    _ABSOLUTE_ERROR_TOKENS = 100_000
    _rough_chars = sum(len(str(m.get("content", ""))) for m in messages)
    _rough_tokens = _rough_chars // 3
    if _rough_tokens > _ABSOLUTE_ERROR_TOKENS:
        logger.error(
            f"ğŸš¨ ä¸Šä¸‹æ–‡ç»å¯¹ä¸Šé™å‘Šè­¦: ç²—ä¼° {_rough_tokens:,} tokens > {_ABSOLUTE_ERROR_TOKENS:,}ï¼Œ"
            f"å°†å¼ºåˆ¶è£å‰ªï¼ˆæ¶ˆæ¯æ•°={original_count}ï¼‰"
        )
    elif _rough_tokens > _ABSOLUTE_WARN_TOKENS:
        logger.warning(
            f"âš ï¸ ä¸Šä¸‹æ–‡ç»å¯¹ä¸Šé™é¢„è­¦: ç²—ä¼° {_rough_tokens:,} tokens > {_ABSOLUTE_WARN_TOKENS:,}ï¼ˆæ¶ˆæ¯æ•°={original_count}ï¼‰"
        )

    # è¾¹ç•Œæƒ…å†µï¼šæ¶ˆæ¯æ•°å¾ˆå°‘ï¼Œæ— éœ€è£å‰ª
    min_preserve = preserve_first_messages + preserve_last_messages
    if original_count <= min_preserve:
        estimated_tokens = count_messages_tokens(messages, system_prompt)
        return messages, TrimStats(
            original_count=original_count,
            trimmed_count=original_count,
            estimated_tokens=estimated_tokens,
            exceeded_budget=estimated_tokens >= token_budget,
            should_warn=estimated_tokens >= token_budget * 0.8,
        )

    # 1. è®¡ç®— system_prompt çš„ token æ•°ï¼ˆåŸºç¡€å¼€é”€ï¼‰
    # æ³¨æ„ï¼šä¸å« tools å®šä¹‰çš„ tokenï¼ˆçº¦ 3000ï¼‰ã€‚è°ƒç”¨æ–¹ï¼ˆrvr.pyï¼‰åœ¨åˆ¤æ–­
    # æ˜¯å¦éœ€è¦è£å‰ªæ—¶å·²ç”¨ count_request_tokens() å®Œæ•´ä¼°ç®—ï¼ˆå« toolsï¼‰ï¼Œ
    # ä¸” safe_threshold æœ‰ 8-20% bufferï¼Œtools çš„ 1.5% å¼€é”€åœ¨å®‰å…¨èŒƒå›´å†…ã€‚
    base_tokens = count_tokens(system_prompt) if system_prompt else 0

    # 2. è®¡ç®—æ¯æ¡æ¶ˆæ¯çš„ token æ•°
    message_tokens = [count_message_tokens(msg) for msg in messages]
    total_tokens = base_tokens + sum(message_tokens)

    # 3. å¦‚æœæœªè¶…é¢„ç®—ï¼Œç›´æ¥è¿”å›
    if total_tokens <= token_budget:
        return messages, TrimStats(
            original_count=original_count,
            trimmed_count=original_count,
            estimated_tokens=total_tokens,
            exceeded_budget=False,
            should_warn=total_tokens >= token_budget * 0.8,
        )

    logger.info(f"âš ï¸ Token è¶…é¢„ç®—: {total_tokens:,} > {token_budget:,}ï¼Œå¼€å§‹è£å‰ª...")

    # 4. ä¿ç•™å¼€å¤´ N æ¡æ¶ˆæ¯ï¼ˆä»»åŠ¡ä¸Šä¸‹æ–‡ï¼‰
    first_part = messages[:preserve_first_messages]
    first_tokens = sum(message_tokens[:preserve_first_messages])

    # 5. ä»æœ€è¿‘æ¶ˆæ¯å‘å‰ç´¯è®¡ï¼Œæ‰¾åˆ°èƒ½æ”¾è¿›é¢„ç®—çš„æœ€å¤§èŒƒå›´
    # å‰©ä½™é¢„ç®— = token_budget - base_tokens - first_tokens - ç¼“å†²åŒº
    buffer_tokens = 5000  # ç•™å‡ºç¼“å†²åŒºç»™åç»­å·¥å…·è°ƒç”¨
    remaining_budget = token_budget - base_tokens - first_tokens - buffer_tokens

    # ä»åå‘å‰ç´¯è®¡ token
    last_part = []
    last_tokens = 0
    last_start_idx = original_count  # ä»åå‘å‰çš„èµ·å§‹ç´¢å¼•

    for i in range(original_count - 1, preserve_first_messages - 1, -1):
        msg_token = message_tokens[i]
        if last_tokens + msg_token <= remaining_budget:
            last_tokens += msg_token
            last_start_idx = i
        else:
            break

    # ç¡®ä¿è‡³å°‘ä¿ç•™ preserve_last_messages æ¡æœ€è¿‘æ¶ˆæ¯ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
    min_last_idx = max(preserve_first_messages, original_count - preserve_last_messages)
    if last_start_idx > min_last_idx:
        # å¼ºåˆ¶ä¿ç•™æœ€è¿‘ N æ¡ï¼Œå³ä½¿è¶…é¢„ç®—
        last_start_idx = min_last_idx
        last_tokens = sum(message_tokens[last_start_idx:])

    last_part = messages[last_start_idx:]

    # 6. ä¸­é—´éƒ¨åˆ†ï¼šå¯é€‰ä¿ç•™ tool_result æ¶ˆæ¯
    middle_part = []
    middle_tokens = 0

    if preserve_tool_results and last_start_idx > preserve_first_messages:
        middle_budget = remaining_budget - last_tokens

        for i in range(preserve_first_messages, last_start_idx):
            msg = messages[i]
            if _has_tool_result(msg):
                msg_token = message_tokens[i]
                if middle_tokens + msg_token <= middle_budget:
                    middle_part.append(msg)
                    middle_tokens += msg_token

    # 7. ç»„åˆç»“æœ
    result = first_part + middle_part + last_part

    # 8. ğŸ›¡ï¸ è£å‰ªåç¡®ä¿ tool_use/tool_result é…å¯¹ï¼ˆè£å‰ªå¯èƒ½ç ´åè¾¹ç•Œå¤„çš„é…å¯¹ï¼‰
    from core.llm.adaptor import ClaudeAdaptor

    result = ClaudeAdaptor.ensure_tool_pairs(result)

    trimmed_count = len(result)
    estimated_tokens = base_tokens + first_tokens + middle_tokens + last_tokens

    logger.info(
        f"âœ‚ï¸ è£å‰ªå®Œæˆ: {original_count} â†’ {trimmed_count} æ¡æ¶ˆæ¯, "
        f"token: {total_tokens:,} â†’ {estimated_tokens:,} "
        f"(first={len(first_part)}, middle={len(middle_part)}, last={len(last_part)})"
    )

    return result, TrimStats(
        original_count=original_count,
        trimmed_count=trimmed_count,
        estimated_tokens=estimated_tokens,
        exceeded_budget=estimated_tokens >= token_budget,
        should_warn=estimated_tokens >= token_budget * 0.8,
    )


def should_warn_backend(estimated_tokens: int, strategy: ContextStrategy) -> bool:
    """
    æ£€æŸ¥æ˜¯å¦åº”è¯¥åœ¨åç«¯æ—¥å¿—ä¸­è­¦å‘Šï¼ˆç”¨æˆ·æ— æ„ŸçŸ¥ï¼‰

    Args:
        estimated_tokens: ä¼°ç®—çš„ token æ•°
        strategy: ä¸Šä¸‹æ–‡ç­–ç•¥

    Returns:
        æ˜¯å¦åº”è¯¥è­¦å‘Šï¼ˆä»…åç«¯æ—¥å¿—ï¼‰
    """
    return estimated_tokens >= strategy.token_budget * strategy.warning_threshold


# ============================================================
# ğŸ†• å¸¦æ‘˜è¦çš„æ™ºèƒ½å‹ç¼©ï¼ˆæ•´åˆ conversation.py åŠŸèƒ½ï¼‰
# ============================================================


class CompressionPhase:
    """å‹ç¼©é˜¶æ®µï¼ˆåŒé˜ˆå€¼æœºåˆ¶ï¼‰"""

    PRE_RUN = "pre_run"  # è¿è¡Œå‰é¢„æ£€æŸ¥ï¼ˆ80% é˜ˆå€¼ï¼‰
    RUNTIME = "runtime"  # è¿è¡Œä¸­å®æ—¶æ£€æŸ¥ï¼ˆ92% é˜ˆå€¼ï¼‰


async def compress_with_summary(
    messages: List[Dict[str, Any]],
    token_budget: int,
    llm_client: Optional[Any] = None,
    conversation_id: Optional[str] = None,
    conversation_service: Optional[Any] = None,
    preserve_first_messages: int = 4,
    preserve_last_messages: int = 10,
    preserve_tool_results: bool = True,
    system_prompt: str = "",
    compression_phase: str = "pre_run",
) -> Tuple[List[Dict[str, Any]], TrimStats]:
    """
    å¸¦æ‘˜è¦çš„æ™ºèƒ½æ¶ˆæ¯å‹ç¼©ï¼ˆæ”¯æŒåŒé˜ˆå€¼æœºåˆ¶ï¼‰

    åŒé˜ˆå€¼æœºåˆ¶ï¼š
    - pre_run (80%): è¿è¡Œå‰é¢„æ£€æŸ¥ï¼ŒAgent å¯åŠ¨å‰æ‰§è¡Œ
    - runtime (92%): è¿è¡Œä¸­å®æ—¶æ£€æŸ¥ï¼ŒAgent æ‰§è¡Œè¿‡ç¨‹ä¸­è§¦å‘

    æµç¨‹ï¼š
    1. æ£€æŸ¥æ˜¯å¦è¶…é˜ˆå€¼ï¼ˆæ ¹æ® compression_phase é€‰æ‹©é˜ˆå€¼ï¼‰
    2. å¦‚è¶…é˜ˆå€¼ï¼Œå¯¹æ—©æœŸæ¶ˆæ¯ç”Ÿæˆ LLM æ‘˜è¦
    3. å¯é€‰ï¼šä¿å­˜æ‘˜è¦åˆ° conversation.metadata
    4. è¿”å› [æ‘˜è¦æ¶ˆæ¯] + ä¸­é—´ tool_result + æœ€è¿‘ N æ¡æ¶ˆæ¯

    ç›¸æ¯” trim_by_token_budgetï¼š
    - ä¸æ˜¯ç®€å•ä¸¢å¼ƒä¸­é—´æ¶ˆæ¯ï¼Œè€Œæ˜¯ç”Ÿæˆæ‘˜è¦ä¿ç•™å…³é”®ä¿¡æ¯
    - æ”¯æŒæŒä¹…åŒ–æ‘˜è¦åˆ°æ•°æ®åº“
    - ä¸‹æ¬¡åŠ è½½æ—¶å¯è‡ªåŠ¨åº”ç”¨å·²æœ‰æ‘˜è¦

    Args:
        messages: æ¶ˆæ¯åˆ—è¡¨
        token_budget: token é¢„ç®—ä¸Šé™
        llm_client: LLM å®¢æˆ·ç«¯ï¼ˆç”¨äºç”Ÿæˆæ‘˜è¦ï¼Œæ¨è Haikuï¼‰
        conversation_id: å¯¹è¯ IDï¼ˆç”¨äºä¿å­˜æ‘˜è¦åˆ°æ•°æ®åº“ï¼‰
        conversation_service: å¯¹è¯æœåŠ¡ï¼ˆç”¨äºä¿å­˜æ‘˜è¦åˆ°æ•°æ®åº“ï¼‰
        preserve_first_messages: å§‹ç»ˆä¿ç•™å¼€å¤´ N æ¡æ¶ˆæ¯
        preserve_last_messages: å°½é‡ä¿ç•™æœ€è¿‘ N æ¡æ¶ˆæ¯
        preserve_tool_results: æ˜¯å¦ä¿ç•™ä¸­é—´çš„ tool_result æ¶ˆæ¯
        system_prompt: ç³»ç»Ÿæç¤ºè¯ï¼ˆè®¡å…¥ tokenï¼‰
        compression_phase: å‹ç¼©é˜¶æ®µ ("pre_run" æˆ– "runtime")

    Returns:
        (å‹ç¼©åçš„æ¶ˆæ¯, ç»Ÿè®¡ä¿¡æ¯)
    """
    from datetime import datetime

    from .summarizer import ConversationSummarizer

    original_count = len(messages)
    phase_label = "è¿è¡Œå‰" if compression_phase == CompressionPhase.PRE_RUN else "è¿è¡Œä¸­"

    # 1. è¾¹ç•Œæƒ…å†µï¼šæ¶ˆæ¯æ•°å¾ˆå°‘ï¼Œæ— éœ€å‹ç¼©
    min_preserve = preserve_first_messages + preserve_last_messages
    if original_count <= min_preserve:
        estimated_tokens = count_messages_tokens(messages, system_prompt)
        return messages, TrimStats(
            original_count=original_count,
            trimmed_count=original_count,
            estimated_tokens=estimated_tokens,
            exceeded_budget=estimated_tokens >= token_budget,
            should_warn=estimated_tokens >= token_budget * 0.8,
        )

    # 2. è®¡ç®— token ä½¿ç”¨æƒ…å†µ
    base_tokens = count_tokens(system_prompt) if system_prompt else 0

    message_tokens = [count_message_tokens(msg) for msg in messages]
    total_tokens = base_tokens + sum(message_tokens)

    # 3. å¦‚æœæœªè¶…é¢„ç®—ï¼Œç›´æ¥è¿”å›
    if total_tokens <= token_budget:
        return messages, TrimStats(
            original_count=original_count,
            trimmed_count=original_count,
            estimated_tokens=total_tokens,
            exceeded_budget=False,
            should_warn=total_tokens >= token_budget * 0.8,
        )

    logger.info(
        f"âš ï¸ [{phase_label}æ£€æŸ¥] Token è¶…é¢„ç®—: {total_tokens:,} > {token_budget:,}ï¼Œå¼€å§‹å¸¦æ‘˜è¦å‹ç¼©..."
    )

    # 4. ç¡®å®šä¿ç•™èŒƒå›´
    # ä¿ç•™å¼€å¤´ N æ¡
    first_part = messages[:preserve_first_messages]
    first_tokens = sum(message_tokens[:preserve_first_messages])

    # ä¿ç•™æœ€è¿‘ N æ¡
    last_start_idx = max(preserve_first_messages, original_count - preserve_last_messages)
    last_part = messages[last_start_idx:]
    last_tokens = sum(message_tokens[last_start_idx:])

    # ä¸­é—´éœ€è¦å‹ç¼©çš„æ¶ˆæ¯
    middle_start = preserve_first_messages
    middle_end = last_start_idx
    early_messages = messages[middle_start:middle_end]

    # 5. ç”Ÿæˆæ‘˜è¦
    summarizer = ConversationSummarizer()

    if llm_client:
        summary = await summarizer.generate_summary(early_messages, llm_client)
    else:
        summary = summarizer.generate_simple_summary(early_messages)

    # è®¡ç®—æ‘˜è¦ token
    summary_tokens = count_tokens(summary)

    # 6. æ„å»ºæ‘˜è¦æ¶ˆæ¯
    summary_message = {
        "role": "user",  # ä½œä¸º user æ¶ˆæ¯æ³¨å…¥
        "content": f"[å†å²å¯¹è¯æ‘˜è¦ - å…± {len(early_messages)} æ¡æ¶ˆæ¯]\n\n{summary}",
    }

    # 7. ä¸­é—´éƒ¨åˆ†ï¼šå¯é€‰ä¿ç•™ tool_result æ¶ˆæ¯
    middle_tool_results = []
    middle_tool_tokens = 0

    if preserve_tool_results:
        # è®¡ç®—å¯ç”¨é¢„ç®—
        buffer_tokens = 5000
        used_tokens = base_tokens + first_tokens + summary_tokens + last_tokens + buffer_tokens
        available_for_tools = max(0, token_budget - used_tokens)

        for i in range(middle_start, middle_end):
            msg = messages[i]
            if _has_tool_result(msg):
                msg_token = message_tokens[i]
                if middle_tool_tokens + msg_token <= available_for_tools:
                    middle_tool_results.append(msg)
                    middle_tool_tokens += msg_token

    # 8. ç»„åˆç»“æœ
    result = first_part + [summary_message] + middle_tool_results + last_part

    # 9. ğŸ›¡ï¸ å‹ç¼©åç¡®ä¿ tool_use/tool_result é…å¯¹ï¼ˆå‹ç¼©å¯èƒ½ç ´åè¾¹ç•Œå¤„çš„é…å¯¹ï¼‰
    from core.llm.adaptor import ClaudeAdaptor

    result = ClaudeAdaptor.ensure_tool_pairs(result)

    trimmed_count = len(result)
    estimated_tokens = (
        base_tokens + first_tokens + summary_tokens + middle_tool_tokens + last_tokens
    )

    logger.info(
        f"âœ… å¸¦æ‘˜è¦å‹ç¼©å®Œæˆ: {original_count} â†’ {trimmed_count} æ¡æ¶ˆæ¯, "
        f"token: {total_tokens:,} â†’ {estimated_tokens:,} "
        f"(first={len(first_part)}, summary=1[{len(early_messages)}æ¡], "
        f"middle_tools={len(middle_tool_results)}, last={len(last_part)})"
    )

    # 9. å¯é€‰ï¼šä¿å­˜æ‘˜è¦åˆ°æ•°æ®åº“
    if conversation_id and conversation_service:
        try:
            await _save_compression_metadata(
                conversation_id=conversation_id,
                conversation_service=conversation_service,
                summary=summary,
                original_count=original_count,
                summary_tokens=summary_tokens,
                middle_start=middle_start,
                middle_end=middle_end,
                summarized_count=len(early_messages),
                preserve_first_messages=preserve_first_messages,
                preserve_last_messages=preserve_last_messages,
                preserve_tool_results=preserve_tool_results,
                compression_phase=compression_phase,
            )
        except Exception as e:
            logger.warning(f"âš ï¸ ä¿å­˜å‹ç¼©å…ƒæ•°æ®å¤±è´¥: {e}")

    return result, TrimStats(
        original_count=original_count,
        trimmed_count=trimmed_count,
        estimated_tokens=estimated_tokens,
        exceeded_budget=estimated_tokens >= token_budget,
        should_warn=estimated_tokens >= token_budget * 0.8,
        has_summary=True,
        summary_tokens=summary_tokens,
        compressed_message_count=len(early_messages),
    )


async def _save_compression_metadata(
    conversation_id: str,
    conversation_service: Any,
    summary: str,
    original_count: int,
    summary_tokens: int,
    middle_start: int,
    middle_end: int,
    summarized_count: int,
    preserve_first_messages: int,
    preserve_last_messages: int,
    preserve_tool_results: bool,
    compression_phase: str,
) -> None:
    """
    ä¿å­˜å‹ç¼©å…ƒæ•°æ®åˆ°æ•°æ®åº“

    Args:
        conversation_id: å¯¹è¯ ID
        conversation_service: å¯¹è¯æœåŠ¡
        summary: æ‘˜è¦æ–‡æœ¬
        original_count: åŸå§‹æ¶ˆæ¯æ•°é‡
        summary_tokens: æ‘˜è¦ token æ•°
        middle_start: è¢«æ‘˜è¦æ›¿æ¢çš„èµ·å§‹ä¸‹æ ‡ï¼ˆåŒ…å«ï¼‰
        middle_end: è¢«æ‘˜è¦æ›¿æ¢çš„ç»“æŸä¸‹æ ‡ï¼ˆä¸åŒ…å«ï¼‰
        summarized_count: è¢«æ‘˜è¦è¦†ç›–çš„æ¶ˆæ¯æ•°é‡
        preserve_first_messages: å›ºå®šä¿ç•™çš„å¼€å¤´æ¶ˆæ¯æ•°
        preserve_last_messages: å°½é‡ä¿ç•™çš„ç»“å°¾æ¶ˆæ¯æ•°
        preserve_tool_results: æ˜¯å¦ä¿ç•™ä¸­é—´ tool_resultï¼ˆä»…ç”¨äºè®°å½•é…ç½®ï¼‰
        compression_phase: å‹ç¼©é˜¶æ®µï¼ˆpre_run/runtimeï¼‰
    """
    from datetime import datetime

    compression_info = {
        "type": "context_summary",
        "compressed_at": datetime.now().isoformat(),
        "summary": summary,
        "original_count": original_count,
        "summary_tokens": summary_tokens,
        # ä½¿ç”¨èŒƒå›´è€Œä¸æ˜¯ countï¼Œé¿å…â€œä¿å­˜/åŠ è½½è¯­ä¹‰ä¸ä¸€è‡´â€
        "middle_start": middle_start,
        "middle_end": middle_end,
        "summarized_count": summarized_count,
        # è®°å½•å½“æ—¶çš„ç­–ç•¥å‚æ•°ï¼Œä¾¿äºè°ƒè¯•ä¸å›æ”¾
        "preserve_first_messages": preserve_first_messages,
        "preserve_last_messages": preserve_last_messages,
        "preserve_tool_results": preserve_tool_results,
        "compression_phase": compression_phase,
    }

    # è·å–ç°æœ‰ metadata å¹¶åˆå¹¶
    conversation = await conversation_service.get_conversation(conversation_id)
    existing_metadata = {}
    if conversation and hasattr(conversation, "metadata"):
        existing_metadata = conversation.metadata if isinstance(conversation.metadata, dict) else {}

    existing_metadata["compression"] = compression_info

    await conversation_service.update_conversation(
        conversation_id=conversation_id, metadata=existing_metadata
    )

    logger.info(f"ğŸ’¾ å‹ç¼©å…ƒæ•°æ®å·²ä¿å­˜: conversation_id={conversation_id}")


async def load_with_existing_summary(
    messages: List[Dict[str, Any]], conversation_id: str, conversation_service: Any
) -> Tuple[List[Dict[str, Any]], bool]:
    """
    åŠ è½½æ¶ˆæ¯æ—¶åº”ç”¨å·²æœ‰çš„å‹ç¼©æ‘˜è¦

    å¦‚æœå¯¹è¯å·²æœ‰å‹ç¼©æ‘˜è¦ï¼Œåˆ™è‡ªåŠ¨åº”ç”¨ï¼š
    - ç”¨æ‘˜è¦æ›¿æ¢æ—©æœŸæ¶ˆæ¯
    - ä¿ç•™æœ€è¿‘çš„æ¶ˆæ¯

    Args:
        messages: åŸå§‹æ¶ˆæ¯åˆ—è¡¨
        conversation_id: å¯¹è¯ ID
        conversation_service: å¯¹è¯æœåŠ¡

    Returns:
        (å¤„ç†åçš„æ¶ˆæ¯åˆ—è¡¨, æ˜¯å¦åº”ç”¨äº†æ‘˜è¦)
    """
    try:
        conversation = await conversation_service.get_conversation(conversation_id)
        if not conversation or not hasattr(conversation, "metadata"):
            return messages, False

        metadata = conversation.metadata if isinstance(conversation.metadata, dict) else {}
        compression = metadata.get("compression")

        if not compression or not compression.get("summary"):
            return messages, False

        # åªåº”ç”¨â€œä¸Šä¸‹æ–‡å‹ç¼©æ‘˜è¦â€ï¼Œé¿å…è¯¯ç”¨ failure_summary ç­‰å…¶ä»–å¤ç”¨å­—æ®µ
        compression_type = compression.get("type")
        if compression_type and compression_type != "context_summary":
            return messages, False
        if not compression_type:
            # å…¼å®¹ï¼šå¦‚æœæ²¡æœ‰ typeï¼Œä½†åŒ…å« failure_summary å¸¸ç”¨å­—æ®µï¼Œç›´æ¥è·³è¿‡
            if compression.get("from_message_id"):
                return messages, False

        summary = compression["summary"]
        middle_start = compression.get("middle_start")
        middle_end = compression.get("middle_end")

        # æ—§ schemaï¼ˆåªæœ‰ compressed_countï¼‰æ— æ³•å¯é å›æ”¾ï¼Œä¼šå¯¼è‡´æ¶ˆæ¯é”™åˆ ï¼›ä¿å®ˆè·³è¿‡ï¼Œç­‰ä¸‹æ¬¡é‡æ–°ç”Ÿæˆ
        if middle_start is None or middle_end is None:
            logger.warning("âš ï¸ å‹ç¼©æ‘˜è¦ schema è¿‡æ—§ï¼Œè·³è¿‡åº”ç”¨ï¼ˆç­‰å¾…é‡æ–°ç”Ÿæˆï¼‰")
            return messages, False

        if not isinstance(middle_start, int) or not isinstance(middle_end, int):
            logger.warning("âš ï¸ å‹ç¼©æ‘˜è¦ schema å¼‚å¸¸ï¼ˆmiddle_start/middle_end éæ•´æ•°ï¼‰ï¼Œè·³è¿‡åº”ç”¨")
            return messages, False

        if middle_end <= middle_start:
            return messages, False

        # æ£€æŸ¥æ¶ˆæ¯æ•°é‡æ˜¯å¦è¶³å¤Ÿåº”ç”¨æ‘˜è¦
        if len(messages) <= middle_end:
            return messages, False

        covered = middle_end - middle_start

        # æ„å»ºæ‘˜è¦æ¶ˆæ¯
        summary_message = {
            "role": "user",
            "content": f"[å†å²å¯¹è¯æ‘˜è¦ - è¦†ç›– {covered} æ¡æ¶ˆæ¯]\n\n{summary}",
        }

        # ç”¨æ‘˜è¦æ›¿æ¢æŒ‡å®šèŒƒå›´
        result = messages[:middle_start] + [summary_message] + messages[middle_end:]

        # ğŸ›¡ï¸ æ‘˜è¦æ›¿æ¢åç¡®ä¿ tool_use/tool_result é…å¯¹
        from core.llm.adaptor import ClaudeAdaptor

        result = ClaudeAdaptor.ensure_tool_pairs(result)

        logger.info(
            f"ğŸ“¦ åº”ç”¨å·²æœ‰æ‘˜è¦: {len(messages)} â†’ {len(result)} æ¡æ¶ˆæ¯ "
            f"(æ‘˜è¦è¦†ç›– {covered} æ¡, range=[{middle_start},{middle_end}))"
        )

        return result, True

    except Exception as e:
        logger.warning(f"âš ï¸ åŠ è½½å‹ç¼©æ‘˜è¦å¤±è´¥: {e}")
        return messages, False


# å¯¼å‡º
__all__ = [
    "QoSLevel",
    "QOS_TOKEN_BUDGETS",
    "ContextStrategy",
    "TrimStats",
    "get_context_strategy",
    "get_memory_guidance_prompt",
    "should_warn_backend",
    # ğŸ†• å¸¦æ‘˜è¦çš„æ™ºèƒ½å‹ç¼©ï¼ˆåŒé˜ˆå€¼æœºåˆ¶ï¼‰
    "CompressionPhase",
    "fast_prefilter_messages",  # å¿«é€Ÿå­—ç¬¦çº§é¢„è¿‡æ»¤
    "trim_by_token_budget",  # çº¯ token é©±åŠ¨è£å‰ª
    "compress_with_summary",
    "load_with_existing_summary",
    # ğŸ†• æ‘˜è¦ç”Ÿæˆå™¨
    "ConversationSummarizer",
    "generate_conversation_summary",
    # ğŸ†• å·¥å…·ç»“æœå‹ç¼©å™¨ï¼ˆç»Ÿä¸€æ–¹æ¡ˆï¼‰
    "ToolResultCompressor",
    "compress_tool_result",
    "is_compressed",
    "extract_ref_id",
    "COMPRESSED_MARKER",
]

# å»¶è¿Ÿå¯¼å…¥æ‘˜è¦ç”Ÿæˆå™¨ï¼ˆé¿å…å¾ªç¯ä¾èµ–ï¼‰
from .summarizer import ConversationSummarizer, generate_conversation_summary

# å·¥å…·ç»“æœå‹ç¼©å™¨
from .tool_result import (
    COMPRESSED_MARKER,
    ToolResultCompressor,
    compress_tool_result,
    extract_ref_id,
    is_compressed,
)
