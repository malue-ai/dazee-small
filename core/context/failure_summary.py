"""
å¤±è´¥ç»éªŒæ€»ç»“æ¨¡å—ï¼ˆMVPï¼‰

åœ¨ Agent è§¦å‘å¤±è´¥/ä¸­æ–­æ—¶ç”Ÿæˆç»“æ„åŒ–æ€»ç»“ï¼Œç”¨äºä¸Šä¸‹æ–‡å‹ç¼©å’Œç»­èŠæ¢å¤ã€‚
"""

from __future__ import annotations

import json
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

import aiofiles
import yaml
from pydantic import BaseModel, Field, ValidationError

from core.llm import Message
from logger import get_logger
from utils.json_utils import extract_json

logger = get_logger(__name__)

_CONFIG_CACHE: Optional["FailureSummaryConfig"] = None


class FailureSummaryConfig(BaseModel):
    """å¤±è´¥ç»éªŒæ€»ç»“é…ç½®ï¼ˆæ¡†æ¶çº§ï¼‰"""

    enabled: bool = True
    trigger_on_stop_reasons: List[str] = Field(default_factory=lambda: ["max_turns_reached"])
    keep_recent_messages: Optional[int] = Field(
        default=None, description="ä¿ç•™æœ€è¿‘æ¶ˆæ¯æ¡æ•°ï¼ˆNone åˆ™ç”± ContextStrategy å†³å®šï¼‰"
    )
    max_input_chars: int = 12000
    max_summary_chars: int = 1200
    max_block_chars: int = 1000


class FailureSummary(BaseModel):
    """ç»“æ„åŒ–å¤±è´¥æ€»ç»“"""

    goal: str = ""
    progress: List[str] = Field(default_factory=list)
    failures: List[str] = Field(default_factory=list)
    constraints: List[str] = Field(default_factory=list)
    next_steps: List[str] = Field(default_factory=list)
    avoid: List[str] = Field(default_factory=list)
    key_files: List[str] = Field(default_factory=list)
    open_questions: List[str] = Field(default_factory=list)
    final_status: str = ""


@dataclass
class FailureSummaryResult:
    """å¤±è´¥æ€»ç»“ç»“æœ"""

    summary_text: str
    summary: Optional[FailureSummary] = None
    raw_text: str = ""
    created_at: str = ""


async def get_failure_summary_config(config_path: Optional[Path] = None) -> FailureSummaryConfig:
    """
    åŠ è½½å¤±è´¥ç»éªŒæ€»ç»“é…ç½®ï¼ˆå¸¦ç¼“å­˜ï¼‰

    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ config/context_compaction.yaml

    Returns:
        FailureSummaryConfig
    """
    global _CONFIG_CACHE
    if _CONFIG_CACHE is not None:
        return _CONFIG_CACHE

    if config_path is None:
        from utils.app_paths import get_bundle_dir
        config_path = get_bundle_dir() / "config" / "context_compaction.yaml"

    config_data: Dict[str, Any] = {}
    if config_path.exists():
        try:
            async with aiofiles.open(config_path, "r", encoding="utf-8") as f:
                content = await f.read()
                config_data = yaml.safe_load(content) or {}
            logger.info(f"âœ… å¤±è´¥æ€»ç»“é…ç½®å·²åŠ è½½: {config_path}")
        except Exception as e:
            logger.warning(f"âš ï¸ åŠ è½½å¤±è´¥æ€»ç»“é…ç½®å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼")
    else:
        logger.warning(f"âš ï¸ æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶: {config_path}ï¼Œä½¿ç”¨é»˜è®¤å€¼")

    raw_cfg = config_data.get("failure_summary", {}) if isinstance(config_data, dict) else {}
    try:
        _CONFIG_CACHE = FailureSummaryConfig.model_validate(raw_cfg or {})
    except ValidationError as e:
        logger.warning(f"âš ï¸ å¤±è´¥æ€»ç»“é…ç½®æ ¡éªŒå¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼")
        _CONFIG_CACHE = FailureSummaryConfig()

    return _CONFIG_CACHE


def build_failure_summary_prompt() -> str:
    """æ„å»ºå¤±è´¥æ€»ç»“ System Prompt"""
    return (
        "ä½ æ˜¯å¤±è´¥ç»éªŒæ€»ç»“å™¨ã€‚è¯·åŸºäºå¯¹è¯è®°å½•ç”Ÿæˆç»“æ„åŒ–å¤±è´¥æ€»ç»“ï¼Œç”¨äºç»­èŠæ¢å¤ã€‚\n"
        "è¦æ±‚ï¼š\n"
        "1) è¾“å‡ºå¿…é¡»æ˜¯ä¸¥æ ¼ JSONï¼Œä¸è¦åŒ…å«å¤šä½™æ–‡æœ¬ã€Markdown æˆ–ä»£ç å—ã€‚\n"
        "2) å†…å®¹è¦çŸ­ã€å¯æ‰§è¡Œï¼Œé¿å…å¤è¿°ç»†èŠ‚ã€‚\n"
        "3) æ€»ç»“ç›®æ ‡ã€å·²å®Œæˆã€å¤±è´¥åŸå› ã€çº¦æŸã€å…³é”®æ–‡ä»¶ã€ä¸‹ä¸€æ­¥ã€é¿å…äº‹é¡¹ã€æœªè§£å†³é—®é¢˜ã€‚\n"
        "4) è‹¥ä¿¡æ¯ä¸è¶³ï¼Œè¯·ç•™ç©ºå­—æ®µæˆ–ç»™å‡ºç©ºåˆ—è¡¨ã€‚\n"
        "\n"
        "JSON å­—æ®µï¼š\n"
        "{\n"
        '  "goal": "...",\n'
        '  "progress": ["..."],\n'
        '  "failures": ["..."],\n'
        '  "constraints": ["..."],\n'
        '  "next_steps": ["..."],\n'
        '  "avoid": ["..."],\n'
        '  "key_files": ["..."],\n'
        '  "open_questions": ["..."],\n'
        '  "final_status": "..."\n'
        "}"
    )


def format_failure_summary(summary: FailureSummary, max_chars: int) -> str:
    """
    å°†ç»“æ„åŒ–å¤±è´¥æ€»ç»“æ ¼å¼åŒ–ä¸ºæ–‡æœ¬

    Args:
        summary: ç»“æ„åŒ–æ€»ç»“
        max_chars: æœ€å¤§å­—ç¬¦æ•°

    Returns:
        æ–‡æœ¬æ€»ç»“
    """
    lines: List[str] = []
    if summary.goal:
        lines.append(f"ç›®æ ‡: {summary.goal}")
    if summary.progress:
        lines.append(f"å·²å®Œæˆ: {'ï¼›'.join(summary.progress)}")
    if summary.failures:
        lines.append(f"å¤±è´¥åŸå› : {'ï¼›'.join(summary.failures)}")
    if summary.constraints:
        lines.append(f"çº¦æŸ/é™åˆ¶: {'ï¼›'.join(summary.constraints)}")
    if summary.next_steps:
        lines.append(f"ä¸‹ä¸€æ­¥: {'ï¼›'.join(summary.next_steps)}")
    if summary.avoid:
        lines.append(f"é¿å…/ä¸è¦: {'ï¼›'.join(summary.avoid)}")
    if summary.key_files:
        lines.append(f"å…³é”®æ–‡ä»¶: {'ï¼›'.join(summary.key_files)}")
    if summary.open_questions:
        lines.append(f"å¾…ç¡®è®¤: {'ï¼›'.join(summary.open_questions)}")
    if summary.final_status:
        lines.append(f"ç»ˆæ­¢åŸå› : {summary.final_status}")

    text = "\n".join(lines).strip()
    if not text:
        text = "æœªç”Ÿæˆæœ‰æ•ˆå¤±è´¥æ€»ç»“"
    return _truncate_text(text, max_chars)


def serialize_messages_for_summary(
    messages: List[Dict[str, Any]], max_chars: int, max_block_chars: int
) -> str:
    """
    å°†æ¶ˆæ¯åˆ—è¡¨åºåˆ—åŒ–ä¸ºæ€»ç»“è¾“å…¥æ–‡æœ¬

    Args:
        messages: æ¶ˆæ¯åˆ—è¡¨ï¼ˆdict æ ¼å¼ï¼‰
        max_chars: æœ€å¤§å­—ç¬¦æ•°
        max_block_chars: å•ä¸ª block æœ€å¤§å­—ç¬¦æ•°

    Returns:
        æ€»ç»“è¾“å…¥æ–‡æœ¬
    """
    lines: List[str] = []
    total_chars = 0

    for msg in messages:
        role = msg.get("role", "unknown")
        content = msg.get("content", "")
        content_text = _extract_content_text(content, max_block_chars)
        if not content_text:
            continue

        line = f"{role}: {content_text}"
        if total_chars + len(line) > max_chars:
            lines.append("...(å¯¹è¯å·²æˆªæ–­)")
            break

        lines.append(line)
        total_chars += len(line)

    return "\n".join(lines)


class FailureSummaryGenerator:
    """å¤±è´¥æ€»ç»“ç”Ÿæˆå™¨"""

    def __init__(self, llm_service, config: FailureSummaryConfig):
        self.llm_service = llm_service
        self.config = config

    async def generate(
        self, messages: List[Dict[str, Any]], stop_reason: str
    ) -> FailureSummaryResult:
        """
        ç”Ÿæˆå¤±è´¥æ€»ç»“

        Args:
            messages: éœ€è¦æ€»ç»“çš„æ¶ˆæ¯åˆ—è¡¨
            stop_reason: åœæ­¢åŸå› 

        Returns:
            FailureSummaryResult
        """
        created_at = datetime.now().isoformat()
        if not messages:
            return FailureSummaryResult(
                summary_text="æœªç”Ÿæˆæœ‰æ•ˆå¤±è´¥æ€»ç»“", summary=None, raw_text="", created_at=created_at
            )

        conversation_text = serialize_messages_for_summary(
            messages,
            max_chars=self.config.max_input_chars,
            max_block_chars=self.config.max_block_chars,
        )
        user_prompt = (
            f"åœæ­¢åŸå› : {stop_reason}\n" "ä»¥ä¸‹ä¸ºå¯¹è¯è®°å½•ï¼ˆå°†è¢«å‹ç¼©ï¼‰ï¼š\n" f"{conversation_text}"
        )

        try:
            response = await self.llm_service.create_message_async(
                messages=[Message(role="user", content=user_prompt)],
                system=build_failure_summary_prompt(),
                tools=[],
                max_tokens=1024,
            )
        except Exception as e:
            logger.warning(f"âš ï¸ å¤±è´¥æ€»ç»“ç”Ÿæˆå¤±è´¥: {e}")
            return FailureSummaryResult(
                summary_text=_fallback_summary(
                    stop_reason, messages, self.config.max_summary_chars
                ),
                summary=None,
                raw_text="",
                created_at=created_at,
            )

        raw_text = _extract_text_from_llm_response(response)
        parsed = extract_json(raw_text)

        summary: Optional[FailureSummary] = None
        if isinstance(parsed, dict):
            try:
                summary = FailureSummary.model_validate(parsed)
            except ValidationError as e:
                logger.debug(f"JSON è§£æå¤±è´¥ï¼Œå›é€€ä¸ºæ–‡æœ¬æ€»ç»“: {e}")

        if summary:
            summary_text = format_failure_summary(summary, self.config.max_summary_chars)
        else:
            summary_text = _truncate_text(
                raw_text.strip(), self.config.max_summary_chars
            ) or _fallback_summary(stop_reason, messages, self.config.max_summary_chars)

        return FailureSummaryResult(
            summary_text=summary_text, summary=summary, raw_text=raw_text, created_at=created_at
        )


def _extract_content_text(content: Any, max_block_chars: int) -> str:
    """æå–æ¶ˆæ¯å†…å®¹ä¸ºæ–‡æœ¬ï¼ˆå« tool_use/tool_resultï¼‰"""
    if isinstance(content, str):
        return _truncate_text(content, max_block_chars)

    if not isinstance(content, list):
        return _truncate_text(str(content), max_block_chars)

    parts: List[str] = []
    for block in content:
        if not isinstance(block, dict):
            continue
        block_type = block.get("type")
        if block_type == "text":
            text = block.get("text", "")
            if text:
                parts.append(text)
        elif block_type == "tool_use":
            name = block.get("name", "unknown")
            input_data = block.get("input", {})
            input_text = _safe_json_dump(input_data)
            parts.append(f"[å·¥å…·è°ƒç”¨:{name}] {input_text}")
        elif block_type == "tool_result":
            result = block.get("content", "")
            parts.append(f"[å·¥å…·ç»“æœ] {_normalize_tool_result(result)}")
        else:
            text = block.get("text", "")
            if text:
                parts.append(text)

    merged = "\n".join(parts).strip()
    return _truncate_text(merged, max_block_chars)


def _normalize_tool_result(result: Any) -> str:
    if isinstance(result, str):
        return result
    if isinstance(result, (dict, list)):
        return _safe_json_dump(result)
    return str(result)


def _safe_json_dump(data: Any) -> str:
    try:
        return json.dumps(data, ensure_ascii=False)
    except Exception:
        return str(data)


def _extract_text_from_llm_response(response: Any) -> str:
    """ä» LLMResponse ä¸­æå–æ–‡æœ¬"""
    if not response or not getattr(response, "content", None):
        return ""

    parts: List[str] = []
    for block in response.content:
        if isinstance(block, dict):
            if block.get("type") == "text":
                parts.append(block.get("text", ""))
            elif "text" in block:
                parts.append(str(block.get("text", "")))
        elif hasattr(block, "text"):
            parts.append(block.text)

    return "\n".join([p for p in parts if p]).strip()


def _truncate_text(text: str, max_chars: int) -> str:
    if not text:
        return ""
    if max_chars <= 0 or len(text) <= max_chars:
        return text
    return text[: max_chars - 3] + "..."


def _fallback_summary(stop_reason: str, messages: List[Dict[str, Any]], max_chars: int) -> str:
    """ç”Ÿæˆç®€æ˜“å¤±è´¥æ€»ç»“ï¼ˆæ— éœ€ LLMï¼‰"""
    first_user = ""
    last_assistant = ""

    for msg in messages:
        if msg.get("role") == "user" and not first_user:
            first_user = _extract_content_text(msg.get("content", ""), max_chars)
    for msg in reversed(messages):
        if msg.get("role") == "assistant":
            last_assistant = _extract_content_text(msg.get("content", ""), max_chars)
            break

    lines = []
    if first_user:
        lines.append(f"ç›®æ ‡: {first_user}")
    if last_assistant:
        lines.append(f"æœ€æ–°è¿›å±•: {last_assistant}")
    lines.append(f"ç»ˆæ­¢åŸå› : {stop_reason}")

    return _truncate_text("\n".join(lines), max_chars)


class FailureSummaryManager:
    """
    ğŸ†• V10.0: å¤±è´¥æ€»ç»“ç®¡ç†å™¨

    ä» Agent._maybe_generate_failure_summary æå–ï¼Œ
    ä½¿ Agent ä¿æŒçº¯ RVR ç¼–æ’å±‚ã€‚

    èŒè´£ï¼š
    1. æ ¹æ®é…ç½®å’Œæ¡ä»¶åˆ¤æ–­æ˜¯å¦éœ€è¦ç”Ÿæˆæ€»ç»“
    2. è·å–å¯¹è¯æ¶ˆæ¯
    3. è°ƒç”¨ FailureSummaryGenerator ç”Ÿæˆæ€»ç»“
    4. å†™å…¥ conversation metadata
    """

    def __init__(
        self,
        conversation_service,
        llm_service,
        config: Optional[FailureSummaryConfig] = None,
        context_strategy=None,
    ):
        """
        Args:
            conversation_service: å¯¹è¯æœåŠ¡ï¼ˆç”¨äºè·å–å’Œæ›´æ–°å¯¹è¯ï¼‰
            llm_service: LLM æœåŠ¡ï¼ˆç”¨äºç”Ÿæˆæ€»ç»“ï¼‰
            config: å¤±è´¥æ€»ç»“é…ç½®ï¼ˆå¯é€‰ï¼‰
            context_strategy: ä¸Šä¸‹æ–‡ç­–ç•¥ï¼ˆå¯é€‰ï¼Œç”¨äºç¡®å®šä¿ç•™æ¶ˆæ¯æ•°ï¼‰
        """
        self.conversation_service = conversation_service
        self.llm_service = llm_service
        # get_failure_summary_config() is async; callers must pass config explicitly.
        # Use sync default if config is not provided.
        self.config = config or FailureSummaryConfig()
        self.context_strategy = context_strategy
        self._generator: Optional[FailureSummaryGenerator] = None

    @property
    def generator(self) -> FailureSummaryGenerator:
        """æ‡’åŠ è½½ç”Ÿæˆå™¨"""
        if self._generator is None:
            self._generator = FailureSummaryGenerator(self.llm_service, self.config)
        return self._generator

    async def maybe_generate(
        self,
        conversation_id: str,
        stop_reason: Optional[str],
        session_id: str,
        user_id: Optional[str],
        message_id: Optional[str] = None,
    ) -> Optional[FailureSummaryResult]:
        """
        åœ¨å¤±è´¥/ä¸­æ–­æ—¶ç”Ÿæˆå¤±è´¥ç»éªŒæ€»ç»“ï¼Œå¹¶å†™å…¥å¯¹è¯ metadata

        Args:
            conversation_id: å¯¹è¯ ID
            stop_reason: åœæ­¢åŸå› 
            session_id: ä¼šè¯ ID
            user_id: ç”¨æˆ· ID
            message_id: æ¶ˆæ¯ IDï¼ˆå¯é€‰ï¼‰

        Returns:
            FailureSummaryResult æˆ– None
        """
        if not self.config.enabled:
            return None
        if not stop_reason or stop_reason not in self.config.trigger_on_stop_reasons:
            return None
        if not self.conversation_service:
            logger.warning("âš ï¸ æœªæä¾› conversation_serviceï¼Œè·³è¿‡å¤±è´¥æ€»ç»“")
            return None
        if not conversation_id:
            logger.warning("âš ï¸ æœªæä¾› conversation_idï¼Œè·³è¿‡å¤±è´¥æ€»ç»“")
            return None

        # è·å–å¯¹è¯æ¶ˆæ¯
        try:
            result = await self.conversation_service.get_conversation_messages(
                conversation_id=conversation_id, limit=1000, order="asc"
            )
            db_messages = result.get("messages", [])
        except Exception as e:
            logger.warning(f"âš ï¸ è·å–å¯¹è¯æ¶ˆæ¯å¤±è´¥ï¼Œè·³è¿‡å¤±è´¥æ€»ç»“: {e}")
            return None

        if not db_messages:
            return None

        # ç¡®å®šä¿ç•™æ¶ˆæ¯æ•°
        preserve_last_n = 2
        if self.context_strategy and hasattr(self.context_strategy, "preserve_last_n"):
            preserve_last_n = self.context_strategy.preserve_last_n
        keep_recent = self.config.keep_recent_messages or max(preserve_last_n * 2, 2)

        if len(db_messages) <= keep_recent:
            logger.info("ğŸ“¦ æ¶ˆæ¯æ•°é‡ä¸è¶³ï¼Œè·³è¿‡å¤±è´¥æ€»ç»“")
            return None

        early_messages = db_messages[:-keep_recent]
        compress_from_message = db_messages[-(keep_recent + 1)]
        from_message_id = (
            compress_from_message.get("id") if isinstance(compress_from_message, dict) else None
        )
        if not from_message_id:
            logger.warning("âš ï¸ æœªæ‰¾åˆ°å‹ç¼©èµ·ç‚¹ message_idï¼Œè·³è¿‡å¤±è´¥æ€»ç»“")
            return None

        # ç”Ÿæˆæ€»ç»“
        summary_result = await self.generator.generate(
            messages=early_messages, stop_reason=stop_reason
        )
        if not summary_result.summary_text:
            logger.info("ğŸ“¦ å¤±è´¥æ€»ç»“ä¸ºç©ºï¼Œè·³è¿‡å†™å…¥")
            return None

        # å†™å…¥ metadata
        try:
            conversation = await self.conversation_service.get_conversation(conversation_id)
            existing_metadata = (
                conversation.metadata if isinstance(conversation.metadata, dict) else {}
            )

            compression_info = {
                "compressed_at": summary_result.created_at or datetime.now().isoformat(),
                "from_message_id": from_message_id,
                "summary": summary_result.summary_text,
                "type": "failure_summary",
                "stop_reason": stop_reason,
                "session_id": session_id,
                "message_id": message_id,
                "user_id": user_id,
            }

            existing_metadata["compression"] = compression_info
            existing_metadata["failure_summary"] = {
                "created_at": summary_result.created_at or datetime.now().isoformat(),
                "stop_reason": stop_reason,
                "summary": summary_result.summary_text,
                "raw": summary_result.raw_text,
                "session_id": session_id,
                "message_id": message_id,
                "user_id": user_id,
            }

            await self.conversation_service.update_conversation(
                conversation_id=conversation_id, metadata=existing_metadata
            )
            logger.info(
                f"âœ… å¤±è´¥æ€»ç»“å·²å†™å…¥ metadata: conversation_id={conversation_id}, "
                f"stop_reason={stop_reason}"
            )
        except Exception as e:
            logger.warning(f"âš ï¸ å†™å…¥å¤±è´¥æ€»ç»“å¤±è´¥: {e}")

        return summary_result


    # V11.0: ç§»é™¤ generate_failure_summary_for_multiagentï¼ˆå°æ­å­ä¸ä½¿ç”¨å¤šæ™ºèƒ½ä½“ï¼‰
