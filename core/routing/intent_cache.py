"""
æ„å›¾è¯†åˆ«è¯­ä¹‰ç¼“å­˜ - IntentSemanticCache

ğŸ†• V9.3: é€šè¿‡å‘é‡ç›¸ä¼¼åº¦åŒ¹é…å‡å°‘ LLM è°ƒç”¨ï¼Œé™ä½å»¶è¿Ÿå’Œæˆæœ¬

è®¾è®¡åŸåˆ™ï¼š
1. æ€§èƒ½çº¦æŸï¼šç¼“å­˜æŸ¥è¯¢ < 100msï¼ˆåŒ…å« Embedding + ç›¸ä¼¼åº¦è®¡ç®—ï¼‰
2. è¿”å› Top-1 + Score
3. é¢„ç•™å‘é‡åº“æ‰©å±•æ¥å£

æ¶æ„ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ IntentSemanticCache                                      â”‚
â”‚ â”œâ”€â”€ L1: ç²¾ç¡®åŒ¹é…ï¼ˆhashï¼‰         < 0.1ms               â”‚
â”‚ â””â”€â”€ L2: è¯­ä¹‰åŒ¹é…ï¼ˆembeddingï¼‰    < 60ms                 â”‚
â”‚     â”œâ”€â”€ Embedding æœåŠ¡           ~50ms (OpenAI API)    â”‚
â”‚     â””â”€â”€ ç›¸ä¼¼åº¦è®¡ç®—               ~5ms  (numpy/å†…å­˜)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ä½¿ç”¨æ–¹å¼ï¼š
    cache = IntentSemanticCache.get_instance()

    # æŸ¥è¯¢
    result, score = await cache.lookup(query)
    if result and score >= 0.95:
        return result  # ç¼“å­˜å‘½ä¸­

    # æœªå‘½ä¸­ï¼Œè°ƒç”¨ LLM
    result = await intent_analyzer.analyze(messages)

    # å¼‚æ­¥å­˜å‚¨
    await cache.store(query, result)
"""

import asyncio
import hashlib
import os
import time
from abc import ABC, abstractmethod
from collections import OrderedDict
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from threading import Lock
from typing import Any, Dict, List, Optional, Tuple

import numpy as np

from core.routing.types import Complexity, IntentResult
from logger import get_logger

logger = get_logger("intent_cache")


# ============================================================
# é…ç½®
# ============================================================


@dataclass
class IntentCacheConfig:
    """
    æ„å›¾ç¼“å­˜é…ç½®

    é»˜è®¤ hash-only æ¨¡å¼ï¼ˆç²¾å‡† 100%ï¼Œä»…åŒ¹é…å®Œå…¨ç›¸åŒçš„æŸ¥è¯¢ï¼‰ã€‚
    è¯­ä¹‰åŒ¹é…éœ€æ˜¾å¼å¼€å¯ï¼ˆINTENT_CACHE_SEMANTIC_ENABLED=trueï¼‰ï¼Œ
    å¯ç”¨åé˜ˆå€¼æé«˜ï¼ˆ0.95ï¼‰ä»¥ä¿è¯ä¸è¯¯åŒ¹é…ã€‚

    ç©ºé—´ä¼°ç®—ï¼ˆmax_size=10000 æ—¶ï¼‰:
    - hash_only: ~1KB/æ¡ç›®ï¼Œçº¦ 10MB
    - fullï¼ˆå«è¯­ä¹‰ï¼‰: ~5KB/æ¡ç›®ï¼ˆå« 1024-dim float32ï¼‰ï¼Œçº¦ 50MB
    """

    enabled: bool = True  # æ˜¯å¦å¯ç”¨ç¼“å­˜
    semantic_enabled: bool = False  # L2 è¯­ä¹‰åŒ¹é…ï¼ˆé»˜è®¤å…³é—­ï¼Œhash-onlyï¼‰
    threshold: float = 0.95  # L2 è¯­ä¹‰é˜ˆå€¼ï¼ˆæé«˜ä¿è¯ç²¾å‡†ï¼Œä»… semantic_enabled æ—¶ç”Ÿæ•ˆï¼‰
    max_size: int = 10000  # æœ€å¤§ç¼“å­˜æ¡ç›®æ•°ï¼ˆLRUï¼‰
    ttl_hours: int = 24  # ç¼“å­˜ TTLï¼ˆå°æ—¶ï¼‰
    backend: str = "memory"  # å­˜å‚¨åç«¯ï¼šmemory | vectordb
    embedding_model: str = "bge-m3-Q4_K_M"  # Embedding æ¨¡å‹ï¼ˆæœ¬åœ° GGUFï¼‰
    embedding_dim: int = 1024  # å‘é‡ç»´åº¦ï¼ˆBGE-M3ï¼‰

    @classmethod
    def from_env(cls) -> "IntentCacheConfig":
        """ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®"""
        return cls(
            enabled=os.getenv("INTENT_CACHE_ENABLED", "true").lower() == "true",
            semantic_enabled=os.getenv("INTENT_CACHE_SEMANTIC_ENABLED", "false").lower()
            == "true",
            threshold=float(os.getenv("INTENT_CACHE_THRESHOLD", "0.95")),
            max_size=int(os.getenv("INTENT_CACHE_MAX_SIZE", "10000")),
            ttl_hours=int(os.getenv("INTENT_CACHE_TTL_HOURS", "24")),
            backend=os.getenv("INTENT_CACHE_BACKEND", "memory"),
            embedding_model=os.getenv("EMBEDDING_MODEL", "bge-m3-Q4_K_M"),
        )


# ============================================================
# ç¼“å­˜æ•°æ®ç»“æ„
# ============================================================


@dataclass
class CachedIntentResult:
    """ç¼“å­˜çš„æ„å›¾ç»“æœ"""

    query_text: str  # åŸå§‹æŸ¥è¯¢æ–‡æœ¬
    query_hash: str  # æŸ¥è¯¢æ–‡æœ¬çš„ hashï¼ˆç”¨äºç²¾ç¡®åŒ¹é…ï¼‰
    embedding: Optional[np.ndarray]  # å‘é‡ï¼ˆæ¨¡å‹ä¸å¯ç”¨æ—¶ä¸º Noneï¼Œä»… hash ç²¾ç¡®åŒ¹é…ï¼‰
    intent_result: IntentResult  # æ„å›¾åˆ†æç»“æœ
    created_at: datetime = field(default_factory=datetime.now)
    hit_count: int = 0  # å‘½ä¸­æ¬¡æ•°

    def is_expired(self, ttl_hours: int) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¿‡æœŸ"""
        return datetime.now() - self.created_at > timedelta(hours=ttl_hours)


# ============================================================
# ç¼“å­˜åç«¯æŠ½è±¡æ¥å£
# ============================================================


class IntentCacheBackend(ABC):
    """
    ç¼“å­˜åç«¯æŠ½è±¡æ¥å£

    é¢„ç•™å‘é‡åº“æ‰©å±•ï¼šå®ç° VectorDBBackend ç»§æ‰¿æ­¤æ¥å£
    """

    @abstractmethod
    async def search(self, embedding: np.ndarray) -> Tuple[Optional[CachedIntentResult], float]:
        """
        å‘é‡ç›¸ä¼¼åº¦æœç´¢

        Args:
            embedding: æŸ¥è¯¢å‘é‡

        Returns:
            (Top-1 ç»“æœ, ç›¸ä¼¼åº¦åˆ†æ•°)ï¼Œæœªå‘½ä¸­è¿”å› (None, 0.0)
        """
        pass

    @abstractmethod
    async def insert(self, item: CachedIntentResult) -> None:
        """æ’å…¥ç¼“å­˜é¡¹"""
        pass

    @abstractmethod
    async def get_by_hash(self, query_hash: str) -> Optional[CachedIntentResult]:
        """ç²¾ç¡®åŒ¹é…ï¼ˆL1 ç¼“å­˜ï¼‰"""
        pass

    @abstractmethod
    def size(self) -> int:
        """å½“å‰ç¼“å­˜å¤§å°"""
        pass

    @abstractmethod
    def clear(self) -> None:
        """æ¸…ç©ºç¼“å­˜"""
        pass


# ============================================================
# å†…å­˜åç«¯å®ç°ï¼ˆé»˜è®¤ï¼‰
# ============================================================


class InMemoryBackend(IntentCacheBackend):
    """
    å†…å­˜åç«¯å®ç°

    ä½¿ç”¨ numpy ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—ï¼ŒO(n) éå†
    10000 æ¡ç¼“å­˜çº¦ 2-3ms
    """

    def __init__(self, max_size: int = 10000, ttl_hours: int = 24):
        self.max_size = max_size
        self.ttl_hours = ttl_hours
        self._cache: OrderedDict[str, CachedIntentResult] = OrderedDict()
        self._lock = Lock()

        # é¢„åˆ†é…å‘é‡çŸ©é˜µï¼ˆä¼˜åŒ–ç›¸ä¼¼åº¦è®¡ç®—ï¼‰
        self._embeddings: Optional[np.ndarray] = None
        self._hash_to_idx: Dict[str, int] = {}
        self._idx_to_hash: Dict[int, str] = {}
        self._next_idx: int = 0

    async def search(self, embedding: np.ndarray) -> Tuple[Optional[CachedIntentResult], float]:
        """
        å‘é‡ç›¸ä¼¼åº¦æœç´¢ï¼ˆè¿”å› Top-1ï¼‰

        ä½¿ç”¨ numpy æ‰¹é‡è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œçº¦ 2-3ms
        """
        if not self._cache:
            return None, 0.0

        start_time = time.time()

        with self._lock:
            # æ¸…ç†è¿‡æœŸæ¡ç›®
            self._cleanup_expired()

            if not self._cache:
                return None, 0.0

            # æ„å»ºå‘é‡çŸ©é˜µï¼ˆå¦‚æœéœ€è¦ï¼Œhash-only æ¡ç›®ä¸å‚ä¸ï¼‰
            if self._embeddings is None:
                self._rebuild_matrix()

            # å…¨éƒ¨ä¸º hash-only æ¡ç›®ï¼Œæ— å¯ç”¨å‘é‡
            if self._embeddings is None or self._embeddings.shape[0] == 0:
                return None, 0.0

            # å½’ä¸€åŒ–æŸ¥è¯¢å‘é‡
            query_norm = embedding / (np.linalg.norm(embedding) + 1e-10)

            # æ‰¹é‡è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
            similarities = np.dot(self._embeddings, query_norm)

            # æ‰¾åˆ°æœ€å¤§å€¼
            max_idx = np.argmax(similarities)
            max_score = float(similarities[max_idx])

            # è·å–å¯¹åº”çš„ç¼“å­˜é¡¹
            if max_idx in self._idx_to_hash:
                query_hash = self._idx_to_hash[max_idx]
                if query_hash in self._cache:
                    result = self._cache[query_hash]
                    result.hit_count += 1

                    elapsed_ms = (time.time() - start_time) * 1000
                    logger.debug(
                        f"ğŸ” è¯­ä¹‰æœç´¢å®Œæˆ: score={max_score:.4f}, "
                        f"elapsed={elapsed_ms:.1f}ms, size={len(self._cache)}"
                    )

                    return result, max_score

        return None, 0.0

    async def insert(self, item: CachedIntentResult) -> None:
        """æ’å…¥ç¼“å­˜é¡¹"""
        with self._lock:
            # LRU æ·˜æ±°
            while len(self._cache) >= self.max_size:
                oldest_hash, _ = self._cache.popitem(last=False)
                if oldest_hash in self._hash_to_idx:
                    idx = self._hash_to_idx.pop(oldest_hash)
                    self._idx_to_hash.pop(idx, None)

            # æ’å…¥æ–°é¡¹
            self._cache[item.query_hash] = item

            # æ›´æ–°å‘é‡ç´¢å¼•ï¼ˆä»…æœ‰ embedding çš„æ¡ç›®å‚ä¸è¯­ä¹‰æœç´¢ï¼‰
            if item.embedding is not None:
                idx = self._next_idx
                self._next_idx += 1
                self._hash_to_idx[item.query_hash] = idx
                self._idx_to_hash[idx] = item.query_hash
                # æœ‰æ–°å‘é‡ï¼Œæ ‡è®°çŸ©é˜µéœ€è¦é‡å»º
                self._embeddings = None

    async def get_by_hash(self, query_hash: str) -> Optional[CachedIntentResult]:
        """ç²¾ç¡®åŒ¹é…ï¼ˆL1 ç¼“å­˜ï¼‰"""
        with self._lock:
            if query_hash in self._cache:
                result = self._cache[query_hash]
                if not result.is_expired(self.ttl_hours):
                    result.hit_count += 1
                    # ç§»åŠ¨åˆ°æœ«å°¾ï¼ˆLRUï¼‰
                    self._cache.move_to_end(query_hash)
                    return result
                else:
                    # è¿‡æœŸï¼Œåˆ é™¤
                    self._remove_item(query_hash)
        return None

    def size(self) -> int:
        """å½“å‰ç¼“å­˜å¤§å°"""
        return len(self._cache)

    def clear(self) -> None:
        """æ¸…ç©ºç¼“å­˜"""
        with self._lock:
            self._cache.clear()
            self._embeddings = None
            self._hash_to_idx.clear()
            self._idx_to_hash.clear()
            self._next_idx = 0

    def _cleanup_expired(self) -> None:
        """æ¸…ç†è¿‡æœŸæ¡ç›®"""
        expired = [h for h, item in self._cache.items() if item.is_expired(self.ttl_hours)]
        for h in expired:
            self._remove_item(h)

    def _remove_item(self, query_hash: str) -> None:
        """åˆ é™¤ç¼“å­˜é¡¹"""
        if query_hash in self._cache:
            del self._cache[query_hash]
            if query_hash in self._hash_to_idx:
                idx = self._hash_to_idx.pop(query_hash)
                self._idx_to_hash.pop(idx, None)
            self._embeddings = None

    def _rebuild_matrix(self) -> None:
        """é‡å»ºå‘é‡çŸ©é˜µï¼ˆè·³è¿‡ hash-only æ¡ç›®ï¼Œä¸å‚ä¸è¯­ä¹‰æœç´¢ï¼‰"""
        if not self._cache:
            self._embeddings = None
            return

        # é‡å»ºç´¢å¼•æ˜ å°„
        self._hash_to_idx.clear()
        self._idx_to_hash.clear()

        embeddings = []
        for query_hash, item in self._cache.items():
            if item.embedding is None:
                continue  # hash-only æ¡ç›®ï¼Œä»…æ”¯æŒ L1 ç²¾ç¡®åŒ¹é…
            # å½’ä¸€åŒ–å‘é‡
            norm = np.linalg.norm(item.embedding) + 1e-10
            embeddings.append(item.embedding / norm)
            idx = len(embeddings) - 1
            self._hash_to_idx[query_hash] = idx
            self._idx_to_hash[idx] = query_hash

        if embeddings:
            self._embeddings = np.array(embeddings)
        else:
            self._embeddings = None  # å…¨éƒ¨ä¸º hash-only æ¡ç›®
        self._next_idx = len(embeddings)


# ============================================================
# å‘é‡åº“åç«¯ï¼ˆé¢„ç•™æ¥å£ï¼‰
# ============================================================


class VectorDBBackend(IntentCacheBackend):
    """
    å‘é‡åº“åç«¯ï¼ˆé¢„ç•™å®ç°ï¼‰

    å¤ç”¨ infra/vector/ åŸºç¡€è®¾æ–½
    """

    def __init__(self, collection_name: str = "intent_cache"):
        self.collection_name = collection_name
        self._vector_store = None
        logger.info(f"ğŸ“¦ VectorDBBackend åˆå§‹åŒ–ï¼ˆé¢„ç•™ï¼‰: collection={collection_name}")

    async def _get_vector_store(self):
        """å»¶è¿Ÿåˆå§‹åŒ–å‘é‡åº“"""
        if self._vector_store is None:
            try:
                from infra.vector.factory import get_vector_store

                self._vector_store = await get_vector_store()
            except ImportError:
                # TODO: è¿ç§»åˆ° local_store
                logger.warning("âš ï¸ å‘é‡åº“æ¨¡å—ä¸å¯ç”¨ï¼ŒVectorDBBackend åŠŸèƒ½å·²ç¦ç”¨")
                raise NotImplementedError("å‘é‡åº“æ¨¡å—å·²åˆ é™¤ï¼Œè¯·ä½¿ç”¨ InMemoryBackend")
        return self._vector_store

    async def search(self, embedding: np.ndarray) -> Tuple[Optional[CachedIntentResult], float]:
        """å‘é‡åº“æœç´¢ï¼ˆé¢„ç•™å®ç°ï¼‰"""
        # TODO: å®ç°å‘é‡åº“æœç´¢
        raise NotImplementedError("VectorDBBackend.search() å°šæœªå®ç°")

    async def insert(self, item: CachedIntentResult) -> None:
        """æ’å…¥å‘é‡åº“ï¼ˆé¢„ç•™å®ç°ï¼‰"""
        # TODO: å®ç°å‘é‡åº“æ’å…¥
        raise NotImplementedError("VectorDBBackend.insert() å°šæœªå®ç°")

    async def get_by_hash(self, query_hash: str) -> Optional[CachedIntentResult]:
        """ç²¾ç¡®åŒ¹é…ï¼ˆé¢„ç•™å®ç°ï¼‰"""
        # TODO: å®ç°ç²¾ç¡®åŒ¹é…
        return None

    def size(self) -> int:
        """å½“å‰ç¼“å­˜å¤§å°"""
        return 0

    def clear(self) -> None:
        """æ¸…ç©ºç¼“å­˜"""
        pass


# ============================================================
# Embedding æœåŠ¡
# ============================================================


class EmbeddingService:
    """
    Embedding æœåŠ¡ï¼ˆä¼˜é›…é™çº§ï¼‰

    ä½¿ç”¨æœ¬åœ° GGUF æ¨¡å‹ï¼ˆBGE-M3ï¼‰ï¼Œå¤ç”¨ core/knowledge/embeddings çš„ providerã€‚
    æ¨¡å‹æœªä¸‹è½½æ—¶è¿”å› Noneï¼Œè°ƒç”¨æ–¹è‡ªè¡Œé™çº§ä¸ºå…³é”®è¯/hash åŒ¹é…ã€‚
    """

    def __init__(self, model: str = "bge-m3-Q4_K_M"):
        self.model = model
        self._provider = None
        self._unavailable = False  # True = model not downloaded, skip silently

    async def _get_provider(self):
        """Lazy-init embedding provider. Returns None if model not available."""
        if self._unavailable:
            return None

        if self._provider is None:
            try:
                from core.knowledge.embeddings import create_embedding_provider

                self._provider = await create_embedding_provider("auto")
                logger.info(
                    f"IntentCache embedding provider: {self._provider.provider_id} "
                    f"(dim={self._provider.dimensions})"
                )
            except Exception:
                # Model not downloaded or no provider available â†’ silent degradation
                self._unavailable = True
                logger.debug(
                    "Embedding model not available, "
                    "intent cache will use hash-only matching"
                )
                return None

        return self._provider

    async def embed(self, text: str) -> Optional[np.ndarray]:
        """
        Get embedding vector for text.

        Returns None if model not available (graceful degradation).

        Args:
            text: input text

        Returns:
            1024-dim vector or None
        """
        provider = await self._get_provider()
        if provider is None:
            return None

        start_time = time.time()
        embedding = await provider.embed(text[:8000])
        elapsed_ms = (time.time() - start_time) * 1000
        logger.debug(f"Embedding done: dim={len(embedding)}, elapsed={elapsed_ms:.1f}ms")

        return embedding


# ============================================================
# ä¸»ç±»ï¼šIntentSemanticCache
# ============================================================


class IntentSemanticCache:
    """
    æ„å›¾è¯†åˆ«è¯­ä¹‰ç¼“å­˜ï¼ˆå•ä¾‹ï¼‰

    ä¸¤å±‚ç¼“å­˜ç­–ç•¥ï¼š
    - L1: ç²¾ç¡®åŒ¹é…ï¼ˆhashï¼‰< 0.1ms
    - L2: è¯­ä¹‰åŒ¹é…ï¼ˆembeddingï¼‰< 60ms

    ä½¿ç”¨æ–¹å¼ï¼š
        cache = IntentSemanticCache.get_instance()

        # æŸ¥è¯¢
        result, score = await cache.lookup(query)
        if result and score >= cache.config.threshold:
            return result

        # æœªå‘½ä¸­ï¼Œè°ƒç”¨ LLM åå­˜å‚¨
        await cache.store(query, intent_result)
    """

    _instance: Optional["IntentSemanticCache"] = None
    _lock = Lock()

    def __init__(self, config: Optional[IntentCacheConfig] = None):
        self.config = config or IntentCacheConfig.from_env()

        # åˆå§‹åŒ–åç«¯
        if self.config.backend == "vectordb":
            self._backend: IntentCacheBackend = VectorDBBackend()
        else:
            self._backend = InMemoryBackend(
                max_size=self.config.max_size, ttl_hours=self.config.ttl_hours
            )

        # Embedding æœåŠ¡ï¼ˆä»… semantic_enabled æ—¶åˆå§‹åŒ–ï¼Œhash-only æ¨¡å¼ä¸åŠ è½½æ¨¡å‹ï¼‰
        self._embedding_service: Optional[EmbeddingService] = None
        if self.config.semantic_enabled:
            self._embedding_service = EmbeddingService(model=self.config.embedding_model)

        # ç»Ÿè®¡æŒ‡æ ‡
        self._stats = {
            "l1_hits": 0,
            "l2_hits": 0,
            "misses": 0,
            "stores": 0,
            "hash_only_stores": 0,  # æ—  embedding çš„å­˜å‚¨æ¬¡æ•°
        }

        # é™çº§æ—¥å¿—æ ‡è®°ï¼ˆä»…è®°å½•ä¸€æ¬¡ï¼Œé¿å…åˆ·å±ï¼‰
        self._hash_only_logged = False

        mode = (
            "hash_only"
            if not self.config.semantic_enabled
            else f"full (threshold={self.config.threshold})"
        )
        logger.info(
            f"IntentSemanticCache åˆå§‹åŒ–: "
            f"enabled={self.config.enabled}, "
            f"mode={mode}, "
            f"max_size={self.config.max_size}"
        )

    @classmethod
    def get_instance(cls, config: Optional[IntentCacheConfig] = None) -> "IntentSemanticCache":
        """è·å–å•ä¾‹å®ä¾‹"""
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = cls(config)
        return cls._instance

    @classmethod
    def reset_instance(cls) -> None:
        """é‡ç½®å•ä¾‹ï¼ˆæµ‹è¯•ç”¨ï¼‰"""
        with cls._lock:
            if cls._instance:
                cls._instance._backend.clear()
            cls._instance = None

    async def lookup(self, query: str) -> Tuple[Optional[IntentResult], float]:
        """
        æŸ¥è¯¢è¯­ä¹‰ç¼“å­˜

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢æ–‡æœ¬

        Returns:
            (IntentResult, ç›¸ä¼¼åº¦åˆ†æ•°)ï¼Œæœªå‘½ä¸­è¿”å› (None, 0.0)

        è€—æ—¶é¢„ç®—:
        - L1 ç²¾ç¡®åŒ¹é…: < 0.1ms
        - L2 è¯­ä¹‰åŒ¹é…: < 60ms (Embedding 50ms + ç›¸ä¼¼åº¦ 5ms)
        """
        if not self.config.enabled:
            return None, 0.0

        start_time = time.time()

        # L1: ç²¾ç¡®åŒ¹é…ï¼ˆhashï¼‰
        query_hash = self._compute_hash(query)
        cached = await self._backend.get_by_hash(query_hash)
        if cached:
            self._stats["l1_hits"] += 1
            elapsed_ms = (time.time() - start_time) * 1000
            logger.info(f"âœ… L1 ç²¾ç¡®å‘½ä¸­: hash={query_hash[:8]}..., " f"elapsed={elapsed_ms:.2f}ms")
            return cached.intent_result, 1.0

        # L2: è¯­ä¹‰åŒ¹é…ï¼ˆä»… semantic_enabled æ—¶æ‰§è¡Œï¼Œé»˜è®¤è·³è¿‡ï¼‰
        if not self.config.semantic_enabled or self._embedding_service is None:
            self._stats["misses"] += 1
            return None, 0.0

        try:
            embedding = await self._embedding_service.embed(query)
            if embedding is None:
                # æ¨¡å‹ä¸å¯ç”¨ â†’ é™é»˜é™çº§ï¼Œä»… L1 hash ç²¾ç¡®åŒ¹é…
                # ç²¾å‡†ä¼˜å…ˆï¼šæœªå‘½ä¸­èµ°æ­£å¸¸ LLM æ„å›¾è¯†åˆ«ï¼Œä¸åšæ¨¡ç³ŠçŒœæµ‹
                if not self._hash_only_logged:
                    logger.info(
                        "IntentCache è¯­ä¹‰åŒ¹é…é™çº§ä¸º hash-only"
                        "ï¼ˆembedding æ¨¡å‹ä¸å¯ç”¨ï¼Œä»…ç²¾ç¡®åŒ¹é…ï¼Œæœªå‘½ä¸­èµ° LLMï¼‰"
                    )
                    self._hash_only_logged = True
                self._stats["misses"] += 1
                return None, 0.0

            cached, score = await self._backend.search(embedding)

            elapsed_ms = (time.time() - start_time) * 1000

            if cached and score >= self.config.threshold:
                self._stats["l2_hits"] += 1
                logger.info(
                    f"L2 semantic hit: score={score:.4f}, "
                    f"threshold={self.config.threshold}, "
                    f"elapsed={elapsed_ms:.1f}ms"
                )
                return cached.intent_result, score

            self._stats["misses"] += 1
            logger.debug(
                f"Cache miss: score={score:.4f}, "
                f"threshold={self.config.threshold}, "
                f"elapsed={elapsed_ms:.1f}ms"
            )
            return None, score

        except Exception as e:
            self._stats["misses"] += 1
            logger.warning(f"Semantic cache lookup failed: {e}")
            return None, 0.0

    async def store(self, query: str, result: IntentResult) -> None:
        """
        å­˜å‚¨æ„å›¾ç»“æœåˆ°ç¼“å­˜

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢æ–‡æœ¬
            result: æ„å›¾åˆ†æç»“æœ

        æ³¨æ„: æ­¤æ–¹æ³•åº”å¼‚æ­¥è°ƒç”¨ï¼Œä¸é˜»å¡ä¸»æµç¨‹
        """
        if not self.config.enabled:
            return

        try:
            # è·å– embeddingï¼ˆhash-only æ¨¡å¼æˆ–æ¨¡å‹ä¸å¯ç”¨æ—¶ä¸º Noneï¼‰
            embedding = None
            if self.config.semantic_enabled and self._embedding_service is not None:
                embedding = await self._embedding_service.embed(query)

            # åˆ›å»ºç¼“å­˜é¡¹ï¼ˆembedding=None æ—¶ä»…æ”¯æŒ L1 hash ç²¾ç¡®åŒ¹é…ï¼‰
            item = CachedIntentResult(
                query_text=query,
                query_hash=self._compute_hash(query),
                embedding=embedding,
                intent_result=result,
            )

            # å­˜å‚¨
            await self._backend.insert(item)
            self._stats["stores"] += 1
            if embedding is None:
                self._stats["hash_only_stores"] += 1

            logger.debug(
                f"Cache stored: hash={item.query_hash[:8]}..., "
                f"has_embedding={embedding is not None}, "
                f"size={self._backend.size()}"
            )

        except Exception as e:
            logger.warning(f"Cache store failed: {e}")

    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        total = self._stats["l1_hits"] + self._stats["l2_hits"] + self._stats["misses"]
        hit_rate = (self._stats["l1_hits"] + self._stats["l2_hits"]) / max(total, 1)

        # åˆ¤æ–­å½“å‰æ¨¡å¼
        if not self.config.semantic_enabled:
            mode = "hash_only"  # é…ç½®é»˜è®¤
        elif self._embedding_service and not self._embedding_service._unavailable:
            mode = "full"  # è¯­ä¹‰åŒ¹é…å¯ç”¨
        else:
            mode = "hash_only_degraded"  # é…ç½®ä¸º semantic ä½†æ¨¡å‹ä¸å¯ç”¨

        # ç©ºé—´ä¼°ç®—ï¼šhash-only ~1KB/æ¡ç›®ï¼Œfull ~5KB/æ¡ç›®ï¼ˆå« 1024-dim float32 å‘é‡ï¼‰
        size = self._backend.size()
        kb_per_entry = 5.0 if mode == "full" else 1.0

        return {
            "enabled": self.config.enabled,
            "mode": mode,  # "full"=L1+L2, "hash_only"=ä»… L1 ç²¾ç¡®åŒ¹é…
            "backend": self.config.backend,
            "threshold": self.config.threshold,
            "size": size,
            "max_size": self.config.max_size,
            "l1_hits": self._stats["l1_hits"],
            "l2_hits": self._stats["l2_hits"],
            "misses": self._stats["misses"],
            "stores": self._stats["stores"],
            "hash_only_stores": self._stats["hash_only_stores"],
            "hit_rate": hit_rate,
            "estimated_memory_mb": round(size * kb_per_entry / 1024, 2),
        }

    @staticmethod
    def _compute_hash(text: str) -> str:
        """è®¡ç®—æ–‡æœ¬ hash"""
        return hashlib.md5(text.encode()).hexdigest()


# ============================================================
# ä¾¿æ·å‡½æ•°
# ============================================================


def get_intent_cache(config: Optional[IntentCacheConfig] = None) -> IntentSemanticCache:
    """è·å–æ„å›¾ç¼“å­˜å®ä¾‹"""
    return IntentSemanticCache.get_instance(config)
