"""
V5.0 ä»»åŠ¡å¤æ‚åº¦æ£€æµ‹å™¨

æ ¸å¿ƒç†å¿µï¼š
- æ‰€æœ‰å¤æ‚åº¦åˆ¤æ–­éƒ½é€šè¿‡ LLM è¯­ä¹‰ç†è§£å®Œæˆ
- ä¸ä½¿ç”¨å…³é”®è¯åŒ¹é…æˆ–é•¿åº¦è§„åˆ™
- ä¿å®ˆçš„ fallbackï¼ˆMEDIUMï¼‰ï¼Œä¸åšå…³é”®è¯çŒœæµ‹

è®¾è®¡åŸåˆ™ï¼š
- è¿è¥æ— éœ€é…ç½®ä»»ä½•å…³é”®è¯è§„åˆ™
- LLM å­¦ä¹  Few-Shot ç¤ºä¾‹è¿›è¡Œè¯­ä¹‰æ³›åŒ–æ¨ç†
- ä»£ç åªåšè°ƒç”¨å’Œè§£æï¼Œä¸åšè§„åˆ™åˆ¤æ–­
"""

import asyncio
from typing import Any, Optional, Tuple

from logger import get_logger

from .prompt_layer import PromptSchema, TaskComplexity

logger = get_logger("complexity_detector")


class ComplexityDetector:
    """
    V5.0 ä»»åŠ¡å¤æ‚åº¦æ£€æµ‹å™¨

    ç­–ç•¥ï¼šLLM-First è¯­ä¹‰æ¨ç†
    - ç›´æ¥ä½¿ç”¨ LLM è¿›è¡Œè¯­ä¹‰ç†è§£
    - ä¸ä½¿ç”¨å…³é”®è¯åŒ¹é…
    - ä¸ä½¿ç”¨é•¿åº¦è§„åˆ™
    - ä¿å®ˆçš„ fallbackï¼ˆMEDIUMï¼‰
    """

    def __init__(
        self,
        schema: Optional[PromptSchema] = None,
        use_llm_fallback: bool = True,  # ä¿æŒå…¼å®¹ï¼Œä½†é»˜è®¤å°±æ˜¯ LLM
        llm_threshold: float = 0.5,  # ä¿æŒå…¼å®¹
    ):
        """
        åˆå§‹åŒ–æ£€æµ‹å™¨

        Args:
            schema: PromptSchemaï¼ˆä¿æŒå…¼å®¹ï¼ŒV5.0 ä¸ä½¿ç”¨å…¶ä¸­çš„ keywordsï¼‰
            use_llm_fallback: ä¿æŒå…¼å®¹
            llm_threshold: ä¿æŒå…¼å®¹
        """
        self.schema = schema
        self._semantic_inference = None

    def _get_semantic_inference(self):
        """è·å–è¯­ä¹‰æ¨ç†æœåŠ¡ï¼ˆæ‡’åŠ è½½ï¼‰"""
        if self._semantic_inference is None:
            try:
                from core.inference import SemanticInference

                self._semantic_inference = SemanticInference()
            except Exception as e:
                logger.warning(f"âš ï¸ è¯­ä¹‰æ¨ç†æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
                return None
        return self._semantic_inference

    def detect(self, query: str) -> Tuple[TaskComplexity, float]:
        """
        åŒæ­¥æ£€æµ‹ä»»åŠ¡å¤æ‚åº¦

        V5.0 ç­–ç•¥ï¼šä½¿ç”¨ä¿å®ˆé»˜è®¤å€¼ï¼Œæ¨èä½¿ç”¨å¼‚æ­¥æ–¹æ³• detect_async

        Args:
            query: ç”¨æˆ·è¾“å…¥

        Returns:
            (å¤æ‚åº¦çº§åˆ«, ç½®ä¿¡åº¦ 0-1)
        """
        _running = False
        try:
            asyncio.get_running_loop()
            _running = True
        except RuntimeError:
            _running = False

        if _running:
            # äº‹ä»¶å¾ªç¯å·²è¿è¡Œï¼Œä½¿ç”¨ä¿å®ˆé»˜è®¤å€¼
            logger.info("âš ï¸ äº‹ä»¶å¾ªç¯å·²è¿è¡Œï¼Œä½¿ç”¨ä¿å®ˆé»˜è®¤å€¼ MEDIUM")
            return TaskComplexity.MEDIUM, 0.5

        # æ²¡æœ‰è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯ï¼Œå®‰å…¨ä½¿ç”¨ asyncio.run()
        return asyncio.run(self.detect_async(query))

    async def detect_async(self, query: str) -> Tuple[TaskComplexity, float]:
        """
        å¼‚æ­¥æ£€æµ‹ä»»åŠ¡å¤æ‚åº¦ï¼ˆæ¨èæ–¹æ³•ï¼‰

        V5.0 ç­–ç•¥ï¼šLLM-First è¯­ä¹‰æ¨ç†

        Args:
            query: ç”¨æˆ·è¾“å…¥

        Returns:
            (å¤æ‚åº¦çº§åˆ«, ç½®ä¿¡åº¦ 0-1)
        """
        inference = self._get_semantic_inference()

        if inference is None:
            # LLM æœåŠ¡ä¸å¯ç”¨ï¼Œä½¿ç”¨ä¿å®ˆé»˜è®¤å€¼
            logger.info(f"âš ï¸ è¯­ä¹‰æ¨ç†æœåŠ¡ä¸å¯ç”¨ï¼Œä½¿ç”¨ä¿å®ˆé»˜è®¤å€¼ MEDIUM")
            return TaskComplexity.MEDIUM, 0.3

        try:
            # ä½¿ç”¨è¯­ä¹‰æ¨ç†
            result = await inference.infer_complexity(query)

            # è½¬æ¢ç»“æœ
            complexity_str = result.result.get("complexity", "medium")
            complexity_map = {
                "simple": TaskComplexity.SIMPLE,
                "medium": TaskComplexity.MEDIUM,
                "complex": TaskComplexity.COMPLEX,
            }

            complexity = complexity_map.get(complexity_str, TaskComplexity.MEDIUM)
            confidence = result.confidence

            logger.info(f"ğŸ§  å¤æ‚åº¦æ£€æµ‹: {complexity.value} (confidence={confidence:.2f})")
            logger.debug(f"   æ¨ç†: {result.reasoning}")

            return complexity, confidence

        except Exception as e:
            logger.warning(f"âš ï¸ LLM æ¨ç†å¤±è´¥: {e}ï¼Œä½¿ç”¨ä¿å®ˆé»˜è®¤å€¼ MEDIUM")
            return TaskComplexity.MEDIUM, 0.3

    def detect_with_llm_fallback(self, query: str) -> Tuple[TaskComplexity, float]:
        """
        æ£€æµ‹ä»»åŠ¡å¤æ‚åº¦ï¼ˆä¿æŒå…¼å®¹ï¼‰

        V5.0: ç›´æ¥è°ƒç”¨ detect()ï¼Œå› ä¸º LLM æ˜¯é»˜è®¤æ–¹æ³•
        """
        return self.detect(query)


# ============================================================
# ä¾¿æ·å‡½æ•°
# ============================================================


def detect_complexity(
    query: str,
    schema: Optional[PromptSchema] = None,
    use_llm: bool = True,  # V5.0: é»˜è®¤ä½¿ç”¨ LLM
) -> TaskComplexity:
    """
    æ£€æµ‹ä»»åŠ¡å¤æ‚åº¦ï¼ˆç®€åŒ–æ¥å£ï¼‰

    V5.0: å§‹ç»ˆä½¿ç”¨ LLM è¯­ä¹‰æ¨ç†

    Args:
        query: ç”¨æˆ·è¾“å…¥
        schema: å¯é€‰çš„ PromptSchemaï¼ˆV5.0 ä¸ä½¿ç”¨å…¶ä¸­çš„ keywordsï¼‰
        use_llm: ä¿æŒå…¼å®¹ï¼ˆV5.0 å§‹ç»ˆä¸º Trueï¼‰

    Returns:
        TaskComplexity æšä¸¾å€¼
    """
    detector = ComplexityDetector(schema)
    complexity, _ = detector.detect(query)
    return complexity


def detect_complexity_with_confidence(
    query: str,
    schema: Optional[PromptSchema] = None,
    use_llm: bool = True,  # V5.0: é»˜è®¤ä½¿ç”¨ LLM
) -> Tuple[TaskComplexity, float]:
    """
    æ£€æµ‹ä»»åŠ¡å¤æ‚åº¦ï¼ˆå¸¦ç½®ä¿¡åº¦ï¼‰

    V5.0: å§‹ç»ˆä½¿ç”¨ LLM è¯­ä¹‰æ¨ç†

    Args:
        query: ç”¨æˆ·è¾“å…¥
        schema: å¯é€‰çš„ PromptSchemaï¼ˆV5.0 ä¸ä½¿ç”¨å…¶ä¸­çš„ keywordsï¼‰
        use_llm: ä¿æŒå…¼å®¹ï¼ˆV5.0 å§‹ç»ˆä¸º Trueï¼‰

    Returns:
        (TaskComplexity, ç½®ä¿¡åº¦ 0-1)
    """
    detector = ComplexityDetector(schema)
    return detector.detect(query)


async def detect_complexity_async(
    query: str,
    schema: Optional[PromptSchema] = None,
) -> Tuple[TaskComplexity, float]:
    """
    å¼‚æ­¥æ£€æµ‹ä»»åŠ¡å¤æ‚åº¦ï¼ˆæ¨èæ–¹æ³•ï¼‰

    V5.0: ä½¿ç”¨ LLM è¯­ä¹‰æ¨ç†

    Args:
        query: ç”¨æˆ·è¾“å…¥
        schema: å¯é€‰çš„ PromptSchemaï¼ˆV5.0 ä¸ä½¿ç”¨å…¶ä¸­çš„ keywordsï¼‰

    Returns:
        (TaskComplexity, ç½®ä¿¡åº¦ 0-1)
    """
    detector = ComplexityDetector(schema)
    return await detector.detect_async(query)
