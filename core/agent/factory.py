"""
AgentFactory - Prompt é©±åŠ¨çš„ Agent åŠ¨æ€åˆå§‹åŒ–

V11.0: å›ºå®šä½¿ç”¨ RVR-B æ‰§è¡Œç­–ç•¥

æ ¸å¿ƒç†å¿µï¼š
- Prompt â†’ LLM ç”Ÿæˆ Schema â†’ åŠ¨æ€åˆå§‹åŒ– Agent
- ä¿®æ”¹ Prompt å³å¯æ”¹å˜ Agent è¡Œä¸º
- Prompt æ˜¯å”¯ä¸€çš„çœŸç›¸æ¥æº
- é€šè¿‡ Few-shot ç¤ºä¾‹å¼•å¯¼ LLM æŽ¨æ–­ï¼Œè€Œéžå…³é”®è¯åŒ¹é…

å‚è€ƒï¼šdocs/15-FRAMEWORK_PROMPT_CONTRACT.md
"""

# 1. æ ‡å‡†åº“
import json
import re
from enum import Enum
from pathlib import Path
from typing import TYPE_CHECKING, Any, Dict, List, Optional

from core.llm import Message, create_llm_service

# å¯¼å…¥å¼ºç±»åž‹ Schema
from core.schemas import (
    DEFAULT_AGENT_SCHEMA,
    AgentSchema,
    IntentAnalyzerConfig,
    MemoryManagerConfig,
    OutputFormatterConfig,
    PlanManagerConfig,
    SkillConfig,
    ToolSelectorConfig,
)

# 3. æœ¬åœ°æ¨¡å—
from logger import get_logger

# 2. ç¬¬ä¸‰æ–¹åº“ï¼ˆæ— ï¼‰

# ðŸ†• V7: ç±»åž‹æ£€æŸ¥å¯¼å…¥ï¼ˆé¿å…å¾ªçŽ¯ä¾èµ–ï¼‰
if TYPE_CHECKING:
    from core.agent.base import Agent
    from core.agent.execution.protocol import ExecutorProtocol
    from core.routing import RoutingDecision


# ============================================================
# ðŸ†• V10.0: Executor æ³¨å†Œè¡¨
# ============================================================


def _get_executor_registry() -> Dict[str, type]:
    """
    èŽ·å– Executor æ³¨å†Œè¡¨ï¼ˆå»¶è¿ŸåŠ è½½ï¼‰

    V11.0: å›ºå®šä½¿ç”¨ RVR-B æ‰§è¡Œç­–ç•¥

    æ‰©å±•ç‚¹ï¼šæ–°å¢žç­–ç•¥åªéœ€åœ¨è¿™é‡Œæ³¨å†Œ

    æ‰§è¡Œç­–ç•¥ï¼š
    - rvr: æ ‡å‡† RVR å¾ªçŽ¯
    - rvr-b: å¸¦å›žæº¯çš„ RVR-Bï¼ˆé»˜è®¤ï¼‰
    - rvrb: RVR-B çš„åˆ«å
    - simple: æ˜ å°„åˆ° RVR-B
    """
    from core.agent.execution import (
        RVRBExecutor,
        RVRExecutor,
    )

    return {
        "rvr": RVRExecutor,
        "rvr-b": RVRBExecutor,
        "rvrb": RVRBExecutor,
        "simple": RVRBExecutor,  # V11.0: simple æ˜ å°„åˆ° RVR-B
    }


def get_available_strategies() -> List[str]:
    """èŽ·å–æ‰€æœ‰å¯ç”¨çš„æ‰§è¡Œç­–ç•¥"""
    return list(_get_executor_registry().keys())


logger = get_logger(__name__)


# ============================================================
# ç»„ä»¶ç±»åž‹æžšä¸¾ï¼ˆç”¨äºŽç±»åž‹å®‰å…¨ï¼‰
# ============================================================


class ComponentType(Enum):
    """ç»„ä»¶ç±»åž‹"""

    INTENT_ANALYZER = "intent_analyzer"
    PLAN_MANAGER = "plan_manager"
    TOOL_SELECTOR = "tool_selector"
    MEMORY_MANAGER = "memory_manager"
    OUTPUT_FORMATTER = "output_formatter"


# ============================================================
# Schema ç”Ÿæˆ Prompt
# ============================================================

def _load_schema_generator_prompt() -> str:
    """åŠ è½½ Schema ç”Ÿæˆå™¨ Prompt"""
    from prompts import load_prompt

    try:
        return load_prompt("factory/schema_generator")
    except FileNotFoundError:
        logger.warning("âš ï¸ Schema ç”Ÿæˆå™¨ Prompt æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨å†…è” fallback")
        return "åˆ†æžä»¥ä¸‹ System Prompt å¹¶ç”Ÿæˆ Agent Schema é…ç½®ï¼ˆJSON æ ¼å¼ï¼‰ã€‚"


# ============================================================
# AgentFactory
# ============================================================


class AgentFactory:
    """
    Agent å·¥åŽ‚ - Prompt é©±åŠ¨çš„åŠ¨æ€åˆå§‹åŒ–

    V11.0: å›ºå®šä½¿ç”¨ RVR-B æ‰§è¡Œç­–ç•¥

    ç”¨æ³•ï¼š
        # æ–¹å¼ 1: ä»Ž Prompt åˆ›å»ºï¼ˆæŽ¨èï¼‰
        agent = await AgentFactory.from_prompt(system_prompt, event_manager)

        # æ–¹å¼ 2: ä»Ž Schema åˆ›å»ºï¼ˆç²¾ç¡®æŽ§åˆ¶ï¼‰
        schema = AgentSchema(name="DataAgent", tools=["plan"], ...)
        agent = AgentFactory.from_schema(schema, system_prompt, event_manager)

        # æ–¹å¼ 3: ä½¿ç”¨é»˜è®¤é…ç½®
        agent = AgentFactory.create_default(event_manager)

        # æ–¹å¼ 4: ä»Žè·¯ç”±å†³ç­–åˆ›å»ºï¼ˆV11.0 è·¯ç”±é›†æˆï¼‰
        routing_decision = await router.route(message, history)
        agent = await AgentFactory.create_from_decision(
            decision=routing_decision,
            event_manager=event_manager
        )
    """

    @classmethod
    async def from_prompt(
        cls,
        system_prompt: str,
        event_manager,
        conversation_service=None,
        llm_service=None,
        use_default_if_failed: bool = True,
        cache_dir: str = None,
        instance_path: str = None,
        force_refresh: bool = False,
        prompt_schema=None,  # ðŸ†• V4.6: PromptSchemaï¼ˆæç¤ºè¯åˆ†å±‚ï¼‰
    ):
        """
        ä»Ž System Prompt åˆ›å»º Agentï¼ˆæ ¸å¿ƒæ–¹æ³•ï¼‰

        æµç¨‹ï¼š
        1. æ£€æŸ¥ç¼“å­˜ï¼ˆå¦‚æžœæä¾› cache_dirï¼‰
        2. è°ƒç”¨ LLM æ ¹æ® Prompt ç”Ÿæˆ Schemaï¼ˆç¼“å­˜æœªå‘½ä¸­æˆ– force_refreshï¼‰
        3. éªŒè¯ Schemaï¼ˆä½¿ç”¨å¼ºç±»åž‹ Pydantic æ¨¡åž‹ï¼‰
        4. ä¿å­˜ç¼“å­˜ï¼ˆå¦‚æžœæä¾› cache_dirï¼‰
        5. æ ¹æ® Schema åˆå§‹åŒ– Agent

        Args:
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            event_manager: äº‹ä»¶ç®¡ç†å™¨
            conversation_service: ä¼šè¯æœåŠ¡
            llm_service: LLM æœåŠ¡ï¼ˆç”¨äºŽç”Ÿæˆ Schemaï¼Œé»˜è®¤ç”¨ Haikuï¼‰
            use_default_if_failed: ç”Ÿæˆå¤±è´¥æ—¶ä½¿ç”¨é»˜è®¤ Schema
            cache_dir: ç¼“å­˜ç›®å½•ï¼ˆå¦‚ instances/test_agent/.cacheï¼‰
            instance_path: å®žä¾‹ç›®å½•ï¼ˆç”¨äºŽç¼“å­˜å¤±æ•ˆæ£€æµ‹ï¼‰
            force_refresh: å¼ºåˆ¶åˆ·æ–°ç¼“å­˜ï¼Œé‡æ–°ç”Ÿæˆ Schema
            prompt_schema: ðŸ†• V4.6 PromptSchemaï¼ˆç”¨äºŽæ ¹æ®å¤æ‚åº¦åŠ¨æ€ç”Ÿæˆæç¤ºè¯ï¼‰

        Returns:
            é…ç½®å¥½çš„ Agent å®žä¾‹
        """
        schema = None
        schema_data = None

        # 1. å°è¯•ä»Žç¼“å­˜åŠ è½½
        if cache_dir and instance_path and not force_refresh:
            cache_path = Path(cache_dir)
            instance_dir = Path(instance_path)

            if cls._should_use_cache(cache_path, instance_dir):
                schema_data = cls._load_schema_from_cache(cache_path)
                if schema_data:
                    try:
                        schema = AgentSchema.from_dict(schema_data)
                        logger.info(f"âœ… ä»Žç¼“å­˜åŠ è½½ Schema: {schema.name}")
                    except Exception as e:
                        logger.warning(f"âš ï¸ ç¼“å­˜ Schema è§£æžå¤±è´¥: {e}ï¼Œå°†é‡æ–°ç”Ÿæˆ")
                        schema = None

        # 2. ç”Ÿæˆæ–° Schemaï¼ˆç¼“å­˜æœªå‘½ä¸­æˆ–å¤±æ•ˆï¼‰
        if schema is None:
            try:
                schema = await cls._generate_schema(system_prompt, llm_service)
                logger.info(f"âœ… Schema ç”ŸæˆæˆåŠŸ: {schema.name}")
                logger.debug(f"   Reasoning: {schema.reasoning}")

            except Exception as e:
                logger.warning(f"âš ï¸ Schema ç”Ÿæˆå¤±è´¥: {e}")
                if use_default_if_failed:
                    logger.info("ä½¿ç”¨é»˜è®¤ Schemaï¼ˆåŸºäºŽå…³é”®è¯æŽ¨æ–­ï¼‰")
                    schema = cls._infer_schema_from_prompt(system_prompt)
                else:
                    raise

            # ä¿å­˜åˆ°ç¼“å­˜ï¼ˆæ— è®ºæ˜¯ LLM ç”Ÿæˆè¿˜æ˜¯å…³é”®è¯æŽ¨æ–­ï¼‰
            if cache_dir and instance_path and schema:
                cls._save_schema_to_cache(Path(cache_dir), Path(instance_path), schema)

        # 3. æ ¹æ® Schema åˆ›å»º Agent
        return await cls.from_schema(
            schema=schema,
            system_prompt=system_prompt,
            event_manager=event_manager,
            conversation_service=conversation_service,
            prompt_schema=prompt_schema,  # ðŸ†• V4.6: ä¼ é€’ PromptSchema
        )

    @classmethod
    async def _generate_schema(cls, system_prompt: str, llm_service=None) -> AgentSchema:
        """è°ƒç”¨ LLM ç”Ÿæˆ Schema"""
        if llm_service is None:
            # ðŸ†• ä½¿ç”¨é…ç½®åŒ–çš„ LLM Profile
            from config.llm_config import get_llm_profile

            profile = await get_llm_profile("schema_generator")
            llm_service = create_llm_service(**profile)

        response = await llm_service.create_message_async(
            messages=[
                Message(
                    role="user",
                    content=f"åˆ†æžä»¥ä¸‹ System Prompt å¹¶ç”Ÿæˆ Agent Schema:\n\n{system_prompt}",
                )
            ],
            system=_load_schema_generator_prompt(),
        )

        # æå– JSONï¼ˆLLMResponse.content æ˜¯ str ç±»åž‹ï¼‰
        content = response.content if response.content else ""
        schema_json = cls._extract_json(content)

        # ä½¿ç”¨å¼ºç±»åž‹ Schema éªŒè¯å’Œè§£æž
        return AgentSchema.from_llm_output(schema_json)

    @classmethod
    def _infer_schema_from_prompt(cls, system_prompt: str) -> AgentSchema:
        """
        V5.0: èŽ·å–ä¿å®ˆé»˜è®¤ Schemaï¼ˆä¸åšå…³é”®è¯çŒœæµ‹ï¼‰

        ç”¨äºŽï¼š
        - LLM è°ƒç”¨å¤±è´¥æ—¶çš„ fallback
        - å¿«é€Ÿå¯åŠ¨åœºæ™¯

        V5.0 ç­–ç•¥ï¼š
        - ä¸ä½¿ç”¨å…³é”®è¯åŒ¹é…
        - è¿”å›žé€šç”¨é…ç½®ï¼Œè®© Agent è‡ªé€‚åº”
        - å·¥å…·/Skills ç”± instance çš„ config.yaml é…ç½®
        """
        logger.info("âš ï¸ ä½¿ç”¨ä¿å®ˆé»˜è®¤ Schemaï¼ˆLLM æŽ¨æ–­å¤±è´¥ï¼‰")

        # V5.0: ä¿å®ˆé»˜è®¤å€¼ï¼Œä¸åšå…³é”®è¯çŒœæµ‹
        # å·¥å…·/Skills åº”ç”± instance çš„ config.yaml é…ç½®
        return AgentSchema(
            name="GeneralAgent",
            description="é€šç”¨æ™ºèƒ½ä½“ï¼ˆä¿å®ˆé»˜è®¤é…ç½®ï¼‰",
            plan_manager=PlanManagerConfig(enabled=True),  # å¯ç”¨è§„åˆ’ï¼Œé€‚åº”å¤æ‚ä»»åŠ¡
            skills=[],  # ç”± instance é…ç½®
            tools=[],  # ç”± instance é…ç½®
            reasoning="V5.0 ä¿å®ˆé»˜è®¤é…ç½®ï¼šLLM æŽ¨æ–­å¤±è´¥ï¼Œä½¿ç”¨é€šç”¨é…ç½®",
        )

    @classmethod
    async def from_schema(
        cls,
        schema: AgentSchema,
        system_prompt: str,
        event_manager,
        conversation_service=None,
        prompt_schema=None,  # ðŸ†• V4.6: PromptSchemaï¼ˆæç¤ºè¯åˆ†å±‚ï¼‰
        prompt_cache=None,  # ðŸ†• V4.6.2: InstancePromptCacheï¼ˆæç¤ºè¯ç¼“å­˜ï¼‰
        apis_config=None,  # ðŸ†• é¢„é…ç½®çš„ APIsï¼ˆç”¨äºŽ api_calling è‡ªåŠ¨æ³¨å…¥ï¼‰
        terminator=None,  # V11: å¯é€‰ç»ˆæ­¢ç­–ç•¥ï¼ˆAdaptiveTerminatorï¼‰
    ):
        """
        æ ¹æ® Schema åˆ›å»º Agentï¼ˆè®¾è®¡å“²å­¦ï¼šSchema é©±åŠ¨ï¼‰

        è¿™æ˜¯æ ¸å¿ƒæ–¹æ³•ï¼šæ ¹æ®å¼ºç±»åž‹ Schema åŠ¨æ€åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶

        è®¾è®¡å“²å­¦ï¼š
        1. Schema å®šä¹‰ç»„ä»¶å¯ç”¨çŠ¶æ€å’Œé…ç½®å‚æ•°
        2. System Prompt ä½œä¸ºè¿è¡Œæ—¶æŒ‡ä»¤ä¼ é€’ç»™ Agent
        3. Agent æ ¹æ® Schema åŠ¨æ€åˆå§‹åŒ–ç»„ä»¶
        4. PromptSchema æ”¯æŒæ ¹æ®å¤æ‚åº¦åŠ¨æ€è£å‰ªæç¤ºè¯
        5. InstancePromptCache æä¾›é¢„ç”Ÿæˆçš„æç¤ºè¯ç‰ˆæœ¬
        6. apis_config: é¢„é…ç½®çš„ APIsï¼Œç”¨äºŽ api_calling å·¥å…·è‡ªåŠ¨æ³¨å…¥è®¤è¯
        7. V11.0: ç»Ÿä¸€ä½¿ç”¨ RVR-B æ‰§è¡Œç­–ç•¥
        """
        logger.info(f"ðŸ—ï¸ æ ¹æ® Schema åˆå§‹åŒ– Agent: {schema.name}")
        logger.debug(f"   Model: {schema.model}")
        logger.debug(
            f"   Skills: {[s.name if isinstance(s, SkillConfig) else s for s in schema.skills]}"
        )
        logger.debug(f"   Tools: {schema.tools}")
        logger.debug(f"   Intent Analyzer: {'å¯ç”¨' if schema.intent_analyzer.enabled else 'ç¦ç”¨'}")
        logger.debug(f"   Plan Manager: {'å¯ç”¨' if schema.plan_manager.enabled else 'ç¦ç”¨'}")
        logger.debug(f"   Tool Selector: {'å¯ç”¨' if schema.tool_selector.enabled else 'ç¦ç”¨'}")
        # æ³¨æ„ï¼šoutput_formatter é…ç½®ä¿ç•™åœ¨ Schema ä¸­ï¼Œä½† Agent ä¸ä½¿ç”¨ï¼ˆç”± API å±‚å¤„ç†ï¼‰
        if prompt_schema:
            logger.debug(
                f"   PromptSchema: {prompt_schema.agent_name} ({len(prompt_schema.modules)} æ¨¡å—)"
            )
        if prompt_cache:
            logger.debug(
                f"   PromptCache: {prompt_cache.instance_name} (loaded={prompt_cache.is_loaded})"
            )
        if apis_config:
            logger.debug(f"   APIs: {len(apis_config)} ä¸ªé¢„é…ç½®")

        # ðŸ†• V4.6.2: ä¼˜å…ˆä½¿ç”¨ prompt_cache ä¸­çš„ prompt_schema
        effective_prompt_schema = prompt_schema or (
            prompt_cache.prompt_schema if prompt_cache else None
        )

        # V11.0: ç»Ÿä¸€ä½¿ç”¨ RVR-B æ‰§è¡Œç­–ç•¥
        return await cls._create_single_agent(
            schema=schema,
            system_prompt=system_prompt,
            event_manager=event_manager,
            conversation_service=conversation_service,
            prompt_schema=effective_prompt_schema,
            prompt_cache=prompt_cache,
            apis_config=apis_config,
            strategy="rvr-b",  # V11.0: å›ºå®šä½¿ç”¨ RVR-Bï¼ˆå¿½ç•¥ schema.execution_strategyï¼Œé˜²æ­¢ LLM ç”Ÿæˆçš„ schema è®¾é”™ï¼‰
            terminator=terminator,
        )

    @classmethod
    async def _create_single_agent(
        cls,
        schema: AgentSchema,
        system_prompt: str,
        event_manager,
        conversation_service,
        prompt_schema,
        prompt_cache,
        apis_config,
        strategy: str = "rvr-b",
        terminator=None,
    ) -> "Agent":
        """
        V11.0: åˆ›å»º Agentï¼ˆç»Ÿä¸€ Agent + Executorï¼Œå›ºå®š RVR-Bï¼‰

        Args:
            schema: AgentSchema
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            event_manager: äº‹ä»¶ç®¡ç†å™¨
            conversation_service: ä¼šè¯æœåŠ¡
            prompt_schema: æç¤ºè¯æ¨¡å¼
            prompt_cache: æç¤ºè¯ç¼“å­˜
            apis_config: API é…ç½®
            strategy: æ‰§è¡Œç­–ç•¥ï¼ˆé»˜è®¤ rvr-bï¼‰

        Returns:
            Agent å®žä¾‹
        """
        import os

        from core.agent.base import Agent
        from core.context.compaction import QoSLevel, get_context_strategy
        from core.events.broadcaster import EventBroadcaster
        from core.tool import create_tool_context, create_tool_executor, create_tool_selector
        from core.tool.registry import create_capability_registry

        # 1. èŽ·å– Executorï¼ˆV11.0: é»˜è®¤ä½¿ç”¨ RVR-Bï¼‰
        registry = _get_executor_registry()
        strategy_key = strategy.lower().replace("-", "").replace("_", "")

        if strategy_key not in registry and strategy not in registry:
            logger.warning(f"æœªçŸ¥ç­–ç•¥ '{strategy}'ï¼Œä½¿ç”¨é»˜è®¤ 'rvr-b'")
            strategy_key = "rvrb"

        executor_cls = registry.get(strategy_key) or registry.get(strategy) or registry["rvr-b"]
        executor = executor_cls()

        # 2. åˆ›å»º LLM
        from config.llm_config import get_llm_profile
        from core.llm import ToolType

        # ðŸ†• V10.3: thinking_mode å†³å®šæ˜¯å¦å¯ç”¨åŽŸç”Ÿ thinking
        # - native: ä½¿ç”¨ LLM åŽŸç”Ÿ Extended Thinking
        # - simulated: ç¦ç”¨åŽŸç”Ÿ thinkingï¼Œç”± Agent ç”Ÿæˆæ¨¡æ‹Ÿæ€è€ƒ
        # - none: ä¸å±•ç¤ºæ€è€ƒ
        llm_enable_thinking = False  # é»˜è®¤å…³é—­
        if schema.thinking_mode == "native":
            llm_enable_thinking = (
                schema.enable_thinking if schema.enable_thinking is not None else True
            )
        elif schema.thinking_mode == "simulated":
            llm_enable_thinking = False  # æ¨¡æ‹Ÿæ€è€ƒæ¨¡å¼ä¸‹ç¦ç”¨åŽŸç”Ÿ thinking
        elif schema.thinking_mode == "none":
            llm_enable_thinking = False
        else:
            # å‘åŽå…¼å®¹ï¼šæœªé…ç½®æ—¶ä½¿ç”¨ enable_thinking
            llm_enable_thinking = (
                schema.enable_thinking if schema.enable_thinking is not None else True
            )

        llm_enable_caching = schema.enable_caching if schema.enable_caching is not None else True

        llm_kwargs = {
            "enable_thinking": llm_enable_thinking,
            "enable_caching": llm_enable_caching,
            "tools": [ToolType.BASH, ToolType.TEXT_EDITOR],
        }

        logger.info(
            f"ðŸ§  Thinking æ¨¡å¼: {schema.thinking_mode}, åŽŸç”Ÿ thinking: {llm_enable_thinking}"
        )

        if schema.temperature is not None:
            llm_kwargs["temperature"] = schema.temperature
        if schema.max_tokens is not None:
            llm_kwargs["max_tokens"] = schema.max_tokens

        # ä¸» Agent LLM å®Œå…¨ç”±å®žä¾‹ config.yaml é©±åŠ¨ï¼ˆå•ä¸€æ¥æºï¼‰
        # é€šè¿‡ ModelRegistry ä»Ž model name è‡ªåŠ¨è§£æž provider / base_url / api_key_env
        from core.llm.model_registry import ModelRegistry

        model_config = ModelRegistry.get(schema.model)
        if model_config:
            caps = model_config.capabilities

            # Capability validation: thinking
            if llm_enable_thinking and not caps.supports_thinking:
                logger.warning(
                    f"âš ï¸ Model '{model_config.model_name}' does not support thinking, "
                    f"disabling enable_thinking"
                )
                llm_enable_thinking = False
                llm_kwargs["enable_thinking"] = False

            # Capability validation: max_tokens
            if (
                schema.max_tokens
                and caps.max_tokens
                and schema.max_tokens > caps.max_tokens
            ):
                logger.warning(
                    f"âš ï¸ Requested max_tokens={schema.max_tokens} exceeds model limit "
                    f"{caps.max_tokens} for '{model_config.model_name}', capping"
                )
                llm_kwargs["max_tokens"] = caps.max_tokens

            # ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·æ¿€æ´»æ—¶ä¿å­˜çš„è‡ªå®šä¹‰ base_urlï¼Œå¦åˆ™ä½¿ç”¨ç›®å½•é»˜è®¤å€¼
            effective_base_url = model_config.base_url
            activated_entry = ModelRegistry.get_activated_entry(schema.model)
            if activated_entry and activated_entry.base_url:
                effective_base_url = activated_entry.base_url

            main_profile = {
                "provider": model_config.provider,
                "model": model_config.model_name,
                "api_key_env": model_config.api_key_env,
                "base_url": effective_base_url,
            }
            # ModelRegistry çš„é¢å¤–é…ç½®ï¼ˆå¦‚ regionï¼‰
            main_profile.update(model_config.extra_config)
            logger.info(
                f"ðŸ”§ ä¸» Agent LLM: model={model_config.model_name}, "
                f"provider={model_config.provider}, "
                f"thinking={llm_enable_thinking}, "
                f"vision={caps.supports_vision} "
                f"(from ModelRegistry)"
            )
        else:
            # æ¨¡åž‹æœªåœ¨ ModelRegistry æ³¨å†Œ
            # é¦–æ¬¡ç”¨æˆ·åœºæ™¯ï¼šschema.model ä¸ºç©º + æ²¡æœ‰æ¿€æ´»æ¨¡åž‹ â†’ æç¤ºç”¨æˆ·é…ç½® API Key
            if not schema.model:
                raise ValueError(
                    "å°šæœªé…ç½® LLM æ¨¡åž‹ã€‚è¯·å…ˆåœ¨è®¾ç½®é¡µé¢å¡«å†™ API Key å¹¶æ¿€æ´»æ¨¡åž‹ã€‚"
                )

            # éžç©ºä½†æœªæ³¨å†Œï¼šå°è¯• llm_profiles main_agent é…ç½®
            logger.warning(
                f"âš ï¸ æ¨¡åž‹ '{schema.model}' æœªåœ¨ ModelRegistry æ³¨å†Œï¼Œ"
                f"å›žé€€åˆ° llm_profiles main_agent é…ç½®"
            )
            try:
                main_profile = await get_llm_profile("main_agent")
            except KeyError:
                raise ValueError(
                    f"æ¨¡åž‹ '{schema.model}' æœªæ³¨å†Œï¼Œä¸” main_agent LLM Profile æœªé…ç½®ã€‚"
                    f"è¯·å…ˆåœ¨è®¾ç½®é¡µé¢å¡«å†™ API Key å¹¶æ¿€æ´»æ¨¡åž‹ã€‚"
                )

        main_profile.update(llm_kwargs)
        llm = create_llm_service(**main_profile)

        # 3. åˆ›å»º Broadcaster
        broadcaster = EventBroadcaster(event_manager, conversation_service=conversation_service)

        # 4. åˆ›å»º ToolExecutor
        capability_registry = create_capability_registry()
        tool_context = create_tool_context(
            event_manager=event_manager,
            workspace_dir=None,
            apis_config=apis_config or [],
        )
        tool_executor = create_tool_executor(
            registry=capability_registry,
            tool_context=tool_context,
        )

        # 5. Context Strategy
        qos_level_str = os.getenv("QOS_LEVEL", "pro")
        try:
            qos_level = QoSLevel(qos_level_str)
        except ValueError:
            qos_level = QoSLevel.PRO
        context_strategy = get_context_strategy(qos_level=qos_level)

        # 6. åˆ›å»º Agent
        agent = Agent(
            executor=executor,
            llm=llm,
            tool_executor=tool_executor,
            broadcaster=broadcaster,
            schema=schema,
            prompt_cache=prompt_cache,
            context_strategy=context_strategy,
            terminator=terminator,
        )

        # ä¿å­˜é¢å¤–å±žæ€§ï¼ˆç”¨äºŽå…‹éš†ï¼‰
        agent.model = schema.model
        agent.capability_registry = capability_registry
        agent.tool_selector = (
            create_tool_selector(registry=capability_registry)
            if schema.tool_selector.enabled
            else None
        )
        agent.apis_config = apis_config or []
        agent.workspace_dir = None
        agent.event_manager = event_manager
        agent.conversation_service = conversation_service

        logger.info(f"âœ… Agent åˆå§‹åŒ–å®Œæˆ: {schema.name}, executor={executor.name}")
        if schema.reasoning:
            logger.info(f"   Reasoning: {schema.reasoning}")

        return agent


    @classmethod
    async def create_default(cls, event_manager, conversation_service=None):
        """åˆ›å»ºé»˜è®¤é…ç½®çš„ Agent"""
        return await cls.from_schema(
            schema=DEFAULT_AGENT_SCHEMA,
            system_prompt="",
            event_manager=event_manager,
            conversation_service=conversation_service,
        )

    @classmethod
    def create_router(cls, llm_service=None, prompt_cache=None, enable_llm: bool = True):
        """
        åˆ›å»º AgentRouter å®žä¾‹

        ç”¨äºŽå»¶è¿Ÿåˆå§‹åŒ–è·¯ç”±å™¨ã€‚

        Args:
            llm_service: LLM æœåŠ¡ï¼ˆç”¨äºŽæ„å›¾åˆ†æžï¼‰
            prompt_cache: InstancePromptCache
            enable_llm: æ˜¯å¦å¯ç”¨ LLM åˆ†æž

        Returns:
            AgentRouter å®žä¾‹
        """
        from core.routing import AgentRouter

        return AgentRouter(
            llm_service=llm_service, prompt_cache=prompt_cache, enable_llm=enable_llm
        )

    @classmethod
    async def create_from_decision(
        cls,
        decision: "RoutingDecision",
        event_manager,
        conversation_service=None,
        workspace_dir: str = None,
        base_schema: "AgentSchema" = None,
        prompt_cache=None,
        system_prompt: str = None,
        apis_config=None,
        **kwargs,
    ):
        """
        æ ¹æ®è·¯ç”±å†³ç­–åˆ›å»º Agentï¼ˆV11.0ï¼‰

        æµç¨‹ï¼š
        1. ä»Ž decision èŽ·å– intent
        2. åœ¨ base_schema åŸºç¡€ä¸Šå¾®è°ƒè¿è¡Œæ—¶å‚æ•°
        3. åˆ›å»º RVR-B Agent

        Args:
            decision: RoutingDecision è·¯ç”±å†³ç­–
            event_manager: äº‹ä»¶ç®¡ç†å™¨
            conversation_service: ä¼šè¯æœåŠ¡
            workspace_dir: å·¥ä½œç›®å½•
            base_schema: å®žä¾‹çº§ Schemaï¼ˆæ¥è‡ª config.yamlï¼‰
            prompt_cache: InstancePromptCache
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            apis_config: é¢„é…ç½®çš„ APIs
            **kwargs: å…¶ä»–å‚æ•°

        Returns:
            Agent å®žä¾‹ï¼ˆRVR-B æ‰§è¡Œç­–ç•¥ï¼‰
        """
        intent = decision.intent

        logger.info(
            f"ðŸ—ï¸ AgentFactory.create_from_decision: "
            f"complexity={intent.complexity.value if intent else 'N/A'}"
        )

        # ç¡®å®šåŸºç¡€ Schema
        schema = base_schema or DEFAULT_AGENT_SCHEMA

        # ç»ˆæ­¢å®Œå…¨ç”± AdaptiveTerminator è‡ªä¸»å†³ç­–ï¼Œä¸æŒ‰ complexity é™åˆ¶ max_turns

        # V11.0: ç»Ÿä¸€ä½¿ç”¨ RVR-B æ‰§è¡Œç­–ç•¥
        return await cls._create_single_agent(
            schema=schema,
            system_prompt=system_prompt or "",
            event_manager=event_manager,
            conversation_service=conversation_service,
            prompt_schema=None,
            prompt_cache=prompt_cache,
            apis_config=apis_config,
            strategy="rvr-b",
        )


    @staticmethod
    def _extract_json(text: str) -> Dict[str, Any]:
        """ä»Žæ–‡æœ¬ä¸­æå– JSON"""
        # å°è¯•æ‰¾ ```json ... ``` å—
        json_match = re.search(r"```json\s*([\s\S]*?)\s*```", text)
        if json_match:
            return json.loads(json_match.group(1))

        # å°è¯•æ‰¾ { ... } å—
        brace_match = re.search(r"\{[\s\S]*\}", text)
        if brace_match:
            return json.loads(brace_match.group(0))

        raise ValueError("æ— æ³•ä»Žå“åº”ä¸­æå– JSON")

    @classmethod
    def _should_use_cache(cls, cache_dir, instance_dir) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦åº”è¯¥ä½¿ç”¨ç¼“å­˜

        Args:
            cache_dir: ç¼“å­˜ç›®å½• Path å¯¹è±¡
            instance_dir: å®žä¾‹ç›®å½• Path å¯¹è±¡

        Returns:
            True è¡¨ç¤ºå¯ä»¥ä½¿ç”¨ç¼“å­˜
        """
        try:
            from utils.cache_utils import is_cache_valid

            return is_cache_valid(cache_dir, instance_dir)
        except Exception as e:
            logger.warning(f"ç¼“å­˜æœ‰æ•ˆæ€§æ£€æŸ¥å¤±è´¥: {e}")
            return False

    @classmethod
    def _load_schema_from_cache(cls, cache_dir) -> Optional[Dict[str, Any]]:
        """
        ä»Žç¼“å­˜åŠ è½½ Schema

        Args:
            cache_dir: ç¼“å­˜ç›®å½• Path å¯¹è±¡

        Returns:
            Schema å­—å…¸ï¼Œå¤±è´¥è¿”å›ž None
        """
        try:
            from utils.cache_utils import load_schema_cache

            return load_schema_cache(cache_dir)
        except Exception as e:
            logger.error(f"åŠ è½½ Schema ç¼“å­˜å¤±è´¥: {e}")
            return None

    @classmethod
    def _save_schema_to_cache(cls, cache_dir, instance_dir, schema: AgentSchema) -> bool:
        """
        ä¿å­˜ Schema åˆ°ç¼“å­˜

        Args:
            cache_dir: ç¼“å­˜ç›®å½• Path å¯¹è±¡
            instance_dir: å®žä¾‹ç›®å½• Path å¯¹è±¡
            schema: AgentSchema å¯¹è±¡

        Returns:
            æˆåŠŸè¿”å›ž True
        """
        try:
            from utils.cache_utils import save_cache_metadata, save_schema_cache

            # è½¬æ¢ä¸ºå­—å…¸
            schema_data = schema.to_dict() if hasattr(schema, "to_dict") else schema.dict()

            # ä¿å­˜ Schema
            save_schema_cache(cache_dir, schema_data)

            # ä¿å­˜å…ƒæ•°æ®
            save_cache_metadata(cache_dir, instance_dir)

            logger.info(f"âœ… Schema å·²ä¿å­˜åˆ°ç¼“å­˜: {cache_dir}")
            return True
        except Exception as e:
            logger.error(f"ä¿å­˜ Schema ç¼“å­˜å¤±è´¥: {e}")
            return False


# ============================================================
# é¢„è®¾ Agent é…ç½®
# ============================================================


class AgentPresets:
    """é¢„è®¾ Agent é…ç½®ï¼Œå¿«é€Ÿåˆ›å»ºå¸¸ç”¨ Agent"""

    @staticmethod
    def data_analyst() -> AgentSchema:
        """æ•°æ®åˆ†æž Agent"""
        return AgentSchema(
            name="DataAnalysisAgent",
            description="ä¸“ä¸šæ•°æ®åˆ†æžåŠ©æ‰‹ï¼Œæ“…é•¿å¤„ç† CSV/Excel æ•°æ®å¹¶ç”ŸæˆæŠ¥è¡¨",
            skills=[SkillConfig(name="excel-generator")],
            tools=[],
            plan_manager=PlanManagerConfig(enabled=True, max_steps=10, granularity="medium"),
            output_formatter=OutputFormatterConfig(
                default_format="markdown", code_highlighting=True
            ),
            reasoning="æ•°æ®åˆ†æžä»»åŠ¡éœ€è¦æ‰§è¡Œ pandas ä»£ç ï¼Œxlsx ç”ŸæˆæŠ¥è¡¨",
        )

    @staticmethod
    def researcher() -> AgentSchema:
        """ç ”ç©¶åŠ©æ‰‹ Agent"""
        return AgentSchema(
            name="ResearchAgent",
            description="æ·±åº¦ç ”ç©¶åŠ©æ‰‹ï¼Œæ“…é•¿æœç´¢ã€åˆ†æžå’Œæ€»ç»“ä¿¡æ¯",
            skills=[],
            tools=[],
            plan_manager=PlanManagerConfig(enabled=True, max_steps=15, granularity="fine"),
            memory_manager=MemoryManagerConfig(retention_policy="session", working_memory_limit=30),
            reasoning="ç ”ç©¶ä»»åŠ¡éœ€è¦å¤šè½®æœç´¢å’Œä¿¡æ¯æ•´åˆï¼Œå¯ç”¨è®¡åˆ’ç®¡ç†",
        )

    @staticmethod
    def report_generator() -> AgentSchema:
        """æŠ¥å‘Šç”Ÿæˆ Agent"""
        return AgentSchema(
            name="ReportAgent",
            description="ä¸“ä¸šæŠ¥å‘Šç”ŸæˆåŠ©æ‰‹ï¼Œæ”¯æŒ Excel/PPT/PDF å¤šç§æ ¼å¼",
            skills=[
                SkillConfig(name="excel-generator"),
                SkillConfig(name="ppt-generator"),
                SkillConfig(name="pdf-generator"),
            ],
            tools=[],
            plan_manager=PlanManagerConfig(enabled=True, max_steps=12),
            output_formatter=OutputFormatterConfig(
                default_format="markdown", include_metadata=True
            ),
            reasoning="æŠ¥å‘Šç”Ÿæˆéœ€è¦å¤šç§ Skills å’Œæ•°æ®å¤„ç†èƒ½åŠ›",
        )

    @staticmethod
    def simple_qa() -> AgentSchema:
        """ç®€å•é—®ç­” Agent"""
        return AgentSchema(
            name="SimpleQAAgent",
            description="ç®€å•é—®ç­”åŠ©æ‰‹ï¼Œå¿«é€Ÿå“åº”",
            skills=[],
            tools=[],
            plan_manager=PlanManagerConfig(enabled=False),
            memory_manager=MemoryManagerConfig(working_memory_limit=10, auto_compress=False),
            reasoning="ç®€å•é—®ç­”ä¸éœ€è¦å·¥å…·å’Œè®¡åˆ’ï¼Œå¿«é€Ÿå“åº”",
        )


# ============================================================
# ä¾¿æ·å‡½æ•°
# ============================================================


async def create_agent_from_prompt(system_prompt: str, event_manager, **kwargs):
    """ä¾¿æ·å‡½æ•°ï¼šä»Ž Prompt åˆ›å»º Agent"""
    return await AgentFactory.from_prompt(system_prompt, event_manager, **kwargs)


async def create_agent_from_preset(
    preset_name: str, event_manager, system_prompt: str = "", **kwargs
):
    """
    ä¾¿æ·å‡½æ•°ï¼šä»Žé¢„è®¾åˆ›å»º Agent

    Args:
        preset_name: é¢„è®¾åç§° (data_analyst, researcher, report_generator, simple_qa)
        event_manager: äº‹ä»¶ç®¡ç†å™¨
        system_prompt: è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯
    """
    presets = {
        "data_analyst": AgentPresets.data_analyst,
        "researcher": AgentPresets.researcher,
        "report_generator": AgentPresets.report_generator,
        "simple_qa": AgentPresets.simple_qa,
    }

    if preset_name not in presets:
        raise ValueError(f"æœªçŸ¥é¢„è®¾: {preset_name}ï¼Œå¯ç”¨: {list(presets.keys())}")

    schema = presets[preset_name]()

    return await AgentFactory.from_schema(
        schema=schema, system_prompt=system_prompt, event_manager=event_manager, **kwargs
    )


def create_schema_from_dict(data: Dict[str, Any]) -> AgentSchema:
    """ä»Žå­—å…¸åˆ›å»ºå¼ºç±»åž‹ Schemaï¼ˆä¾›å¤–éƒ¨ä½¿ç”¨ï¼‰"""
    return AgentSchema.from_dict(data)
