"""
ToolExecutionFlow - ç»Ÿä¸€å·¥å…·æ‰§è¡Œæµ

èŒè´£ï¼š
- å•ä¸ªå·¥å…·æ‰§è¡Œï¼ˆå« Plan ç‰¹åˆ¤ã€HITL å¤„ç†ï¼‰
- å¹¶è¡Œ/ä¸²è¡Œå·¥å…·æ‰§è¡Œæ ¸å¿ƒé€»è¾‘
- æµå¼å·¥å…·æ‰§è¡Œ + SSE äº‹ä»¶å‘é€
- æœåŠ¡ç«¯å·¥å…·äº‹ä»¶å¤„ç†

Agent å·¥å…·å¤„ç† â€” æµå¼å·¥å…·æ‰§è¡Œä¸ç»“æœæ”¶é›†
"""

import asyncio
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from typing import TYPE_CHECKING, Any, AsyncGenerator, Dict, List, Optional

from core.agent.errors import create_error_tool_result, record_tool_error
from core.context import stable_json_dumps
from logger import get_logger

if TYPE_CHECKING:
    from core.context.context_engineering import ContextEngineeringManager
    from core.events.broadcaster import EventBroadcaster
    from core.orchestration import E2EPipelineTracer
    from core.tool.executor import ToolExecutor

logger = get_logger(__name__)


def _tool_result_content(result: Any) -> Any:
    """
    Normalize tool result for tool_result block content.
    If result is a list of content blocks (each dict with "type"), pass through for multimodal.
    Otherwise stringify (str as-is, other serialized to JSON).
    """
    if isinstance(result, str):
        return result
    if (
        isinstance(result, list)
        and result
        and all(isinstance(b, dict) and "type" in b for b in result)
    ):
        return result
    return stable_json_dumps(result)


@dataclass
class ToolExecutionContext:
    """
    å·¥å…·æ‰§è¡Œä¸Šä¸‹æ–‡

    åŒ…å«å·¥å…·æ‰§è¡Œæ‰€éœ€çš„æ‰€æœ‰ä¾èµ–å’ŒçŠ¶æ€ã€‚
    """

    session_id: str
    conversation_id: Optional[str] = None
    user_id: Optional[str] = None

    # ä¾èµ–
    tool_executor: Optional["ToolExecutor"] = None
    broadcaster: Optional["EventBroadcaster"] = None
    event_manager: Any = None
    context_engineering: Optional["ContextEngineeringManager"] = None
    tracer: Optional["E2EPipelineTracer"] = None

    # Plan ç›¸å…³
    plan_cache: Dict[str, Any] = field(default_factory=dict)
    plan_todo_tool: Any = None

    # é…ç½®
    serial_only_tools: set = field(default_factory=lambda: {"plan", "hitl"})
    allow_parallel: bool = True
    max_parallel: int = 5

    # V11: çŠ¶æ€ä¸€è‡´æ€§ï¼ˆç”¨äºæ–‡ä»¶æ“ä½œè®°å½•ï¼‰
    state_manager: Any = None  # Optional[StateConsistencyManager]

    # æ‰©å±•
    extra: Dict[str, Any] = field(default_factory=dict)


@dataclass
class ToolExecutionResult:
    """
    å·¥å…·æ‰§è¡Œç»“æœ
    """

    tool_id: str
    tool_name: str
    tool_input: Dict[str, Any]
    result: Any
    is_error: bool = False
    error_msg: Optional[str] = None


class SpecialToolHandler(ABC):
    """
    ç‰¹æ®Šå·¥å…·å¤„ç†å™¨åŸºç±»

    ç”¨äºå¤„ç†éœ€è¦ç‰¹æ®Šé€»è¾‘çš„å·¥å…·ï¼ˆå¦‚ plan_todo, HITLï¼‰ã€‚
    """

    @property
    @abstractmethod
    def tool_name(self) -> str:
        """å¤„ç†çš„å·¥å…·åç§°"""
        ...

    @abstractmethod
    async def execute(
        self, tool_input: Dict[str, Any], context: ToolExecutionContext, tool_id: str
    ) -> ToolExecutionResult:
        """æ‰§è¡Œå·¥å…·"""
        ...


class ToolExecutionFlow:
    """
    å·¥å…·æ‰§è¡Œæµ

    ç»Ÿä¸€ç®¡ç†å·¥å…·çš„æ‰§è¡Œæµç¨‹ï¼Œæ”¯æŒï¼š
    - å¹¶è¡Œ/ä¸²è¡Œæ‰§è¡Œ
    - ç‰¹æ®Šå·¥å…·å¤„ç†ï¼ˆé€šè¿‡ handler æ’ä»¶ï¼‰
    - æµå¼è¾“å‡º
    - é”™è¯¯å¤„ç†

    ä½¿ç”¨æ–¹å¼ï¼š
        flow = ToolExecutionFlow()
        flow.register_handler(PlanTodoHandler())

        results = await flow.execute(tool_calls, context)
    """

    def __init__(self):
        """åˆå§‹åŒ–æ‰§è¡Œæµ"""
        self._handlers: Dict[str, SpecialToolHandler] = {}

    def register_handler(self, handler: SpecialToolHandler) -> None:
        """
        æ³¨å†Œç‰¹æ®Šå·¥å…·å¤„ç†å™¨

        Args:
            handler: å¤„ç†å™¨å®ä¾‹
        """
        self._handlers[handler.tool_name] = handler
        logger.debug(f"âœ… æ³¨å†Œç‰¹æ®Šå·¥å…·å¤„ç†å™¨: {handler.tool_name}")

    def has_handler(self, tool_name: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„å¤„ç†å™¨"""
        return tool_name in self._handlers

    async def execute_single(
        self,
        tool_call: Dict[str, Any],
        context: ToolExecutionContext,
        inject_context_fn: Optional[callable] = None,
    ) -> ToolExecutionResult:
        """
        æ‰§è¡Œå•ä¸ªå·¥å…·

        Args:
            tool_call: å·¥å…·è°ƒç”¨ä¿¡æ¯ {id, name, input}
            context: æ‰§è¡Œä¸Šä¸‹æ–‡
            inject_context_fn: ä¸Šä¸‹æ–‡æ³¨å…¥å‡½æ•°

        Returns:
            æ‰§è¡Œç»“æœ
        """
        tool_name = tool_call["name"]
        tool_input = tool_call["input"] or {}
        tool_id = tool_call["id"]

        logger.debug(f"ğŸ”§ æ‰§è¡Œå·¥å…·: {tool_name}")

        try:
            # è·å–ä¼šè¯ä¸Šä¸‹æ–‡
            if context.event_manager and hasattr(context.event_manager, "storage"):
                session_context = await context.event_manager.storage.get_session_context(
                    context.session_id
                )
                context.user_id = session_context.get("user_id") or context.user_id
                context.conversation_id = (
                    session_context.get("conversation_id")
                    or context.conversation_id
                    or context.session_id
                )

            # åŒæ­¥ ToolExecutor ä¸Šä¸‹æ–‡
            if context.tool_executor:
                context.tool_executor.update_context(
                    session_id=context.session_id,
                    conversation_id=context.conversation_id,
                    user_id=context.user_id,
                )

            # ä¸Šä¸‹æ–‡æ³¨å…¥
            if inject_context_fn:
                tool_input = inject_context_fn(tool_name, tool_input)

            # æ£€æŸ¥æ˜¯å¦æœ‰ç‰¹æ®Šå¤„ç†å™¨
            if tool_name in self._handlers:
                return await self._handlers[tool_name].execute(tool_input, context, tool_id)

            # é€šç”¨å·¥å…·æ‰§è¡Œ
            if not context.tool_executor:
                raise ValueError("tool_executor æœªé…ç½®")

            # V11: æ–‡ä»¶æ“ä½œå‰ç½®æ•è· â€” æå– tool_input ä¸­çš„æ–‡ä»¶è·¯å¾„ï¼Œå¤‡ä»½åˆ°å¿«ç…§
            _pre_capture_files(context, tool_input)

            result = await context.tool_executor.execute(tool_name, tool_input)

            # V11: æ–‡ä»¶æ“ä½œåç½®è®°å½• â€” è®°å½•åˆ°æ“ä½œæ—¥å¿—ï¼ˆæ”¯æŒå›æ»šï¼‰
            _post_record_operation(context, tool_name, tool_input, result)

            return ToolExecutionResult(
                tool_id=tool_id,
                tool_name=tool_name,
                tool_input=tool_input,
                result=result,
                is_error=False,
            )

        except Exception as e:
            error_msg = f"å·¥å…·æ‰§è¡Œå¤±è´¥: {str(e)}"
            logger.error(f"âŒ {error_msg}")

            # é”™è¯¯ä¿ç•™
            if context.context_engineering:
                record_tool_error(context.context_engineering, tool_name, e, tool_input)

            return ToolExecutionResult(
                tool_id=tool_id,
                tool_name=tool_name,
                tool_input=tool_input,
                result={"error": str(e)},
                is_error=True,
                error_msg=error_msg,
            )

    async def execute(
        self,
        tool_calls: List[Dict[str, Any]],
        context: ToolExecutionContext,
        inject_context_fn: Optional[callable] = None,
    ) -> Dict[str, ToolExecutionResult]:
        """
        æ‰§è¡Œå¤šä¸ªå·¥å…·ï¼ˆæ”¯æŒå¹¶è¡Œï¼‰

        Args:
            tool_calls: å·¥å…·è°ƒç”¨åˆ—è¡¨
            context: æ‰§è¡Œä¸Šä¸‹æ–‡
            inject_context_fn: ä¸Šä¸‹æ–‡æ³¨å…¥å‡½æ•°

        Returns:
            {tool_id: result} æ˜ å°„
        """
        # åˆ†ç¦»å¯å¹¶è¡Œçš„å·¥å…·å’Œå¿…é¡»ä¸²è¡Œçš„ç‰¹æ®Šå·¥å…·
        parallel_tools = []
        serial_tools = []

        for tc in tool_calls:
            tool_name = tc.get("name", "")
            if tool_name in context.serial_only_tools or tool_name in self._handlers:
                serial_tools.append(tc)
            else:
                parallel_tools.append(tc)

        results: Dict[str, ToolExecutionResult] = {}

        # å¹¶è¡Œæ‰§è¡Œ
        if parallel_tools and context.allow_parallel and len(parallel_tools) > 1:
            logger.info(
                f"âš¡ å¹¶è¡Œæ‰§è¡Œ {len(parallel_tools)} ä¸ªå·¥å…·: {[t['name'] for t in parallel_tools]}"
            )

            # é™åˆ¶å¹¶è¡Œæ•°é‡
            tools_to_execute = parallel_tools[: context.max_parallel]
            if len(parallel_tools) > context.max_parallel:
                serial_tools = parallel_tools[context.max_parallel :] + serial_tools
                logger.warning(f"âš ï¸ è¶…å‡ºæœ€å¤§å¹¶è¡Œæ•° {context.max_parallel}ï¼Œéƒ¨åˆ†å·¥å…·å°†ä¸²è¡Œæ‰§è¡Œ")

            # è¿½è¸ª
            for tc in tools_to_execute:
                if context.tracer:
                    context.tracer.log_tool_call(tc["name"])

            # å¹¶è¡Œæ‰§è¡Œ
            parallel_results = await asyncio.gather(
                *[self.execute_single(tc, context, inject_context_fn) for tc in tools_to_execute],
                return_exceptions=True,
            )

            # å¤„ç†ç»“æœ
            for tc, result in zip(tools_to_execute, parallel_results):
                tool_id = tc["id"]
                if isinstance(result, Exception):
                    results[tool_id] = ToolExecutionResult(
                        tool_id=tool_id,
                        tool_name=tc["name"],
                        tool_input=tc.get("input", {}),
                        result={"error": str(result)},
                        is_error=True,
                        error_msg=str(result),
                    )
                else:
                    results[tool_id] = result
        else:
            # å…¨éƒ¨ä¸²è¡Œ
            serial_tools = parallel_tools + serial_tools

        # ä¸²è¡Œæ‰§è¡Œ
        for tc in serial_tools:
            tool_id = tc["id"]

            if context.tracer:
                context.tracer.log_tool_call(tc["name"])

            results[tool_id] = await self.execute_single(tc, context, inject_context_fn)

        return results

    async def execute_stream(
        self,
        tool_calls: List[Dict[str, Any]],
        context: ToolExecutionContext,
        content_handler,
        inject_context_fn: Optional[callable] = None,
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        æ‰§è¡Œå·¥å…·å¹¶å‘é€ SSE äº‹ä»¶ï¼ˆæµå¼ï¼‰

        Args:
            tool_calls: å·¥å…·è°ƒç”¨åˆ—è¡¨
            context: æ‰§è¡Œä¸Šä¸‹æ–‡
            content_handler: ContentHandler å®ä¾‹
            inject_context_fn: ä¸Šä¸‹æ–‡æ³¨å…¥å‡½æ•°

        Yields:
            SSE äº‹ä»¶
        """
        # åˆ†ç¦»æµå¼å’Œæ™®é€šå·¥å…·
        stream_tools = []
        normal_tools = []

        for tc in tool_calls:
            tool_name = tc.get("name", "")
            if tool_name in context.serial_only_tools or tool_name in self._handlers:
                stream_tools.append(tc)
            elif context.tool_executor and context.tool_executor.supports_stream(tool_name):
                stream_tools.append(tc)
            else:
                normal_tools.append(tc)

        # å…ˆæ‰§è¡Œæ™®é€šå·¥å…·
        normal_results: Dict[str, ToolExecutionResult] = {}
        if normal_tools:
            normal_results = await self.execute(normal_tools, context, inject_context_fn)

        # æŒ‰åŸå§‹é¡ºåºå‘é€äº‹ä»¶
        for tool_call in tool_calls:
            tool_name = tool_call["name"]
            tool_input = tool_call["input"] or {}
            tool_id = tool_call["id"]

            # å·²æ‰§è¡Œçš„æ™®é€šå·¥å…·
            if tool_id in normal_results:
                result_info = normal_results[tool_id]
                result = result_info.result
                result_content = _tool_result_content(result)

                # é€šè¿‡ broadcaster å‘é€ SSE äº‹ä»¶ï¼ˆcontent_start + content_stopï¼‰
                await content_handler.emit_block(
                    session_id=context.session_id,
                    block_type="tool_result",
                    content={
                        "tool_use_id": tool_id,
                        "content": result_content,
                        "is_error": result_info.is_error,
                    },
                )

                # yield tool_result äº‹ä»¶ç”¨äºæ¶ˆæ¯æ„å»ºï¼ˆ_handle_tool_calls ä¾èµ–æ­¤æ ¼å¼ï¼‰
                yield {
                    "type": "tool_result",
                    "content": {
                        "tool_use_id": tool_id,
                        "content": result_content,
                        "is_error": result_info.is_error,
                    },
                }
                continue

            # æµå¼/ç‰¹æ®Šå·¥å…·
            logger.debug(f"ğŸ”§ å¤„ç†å·¥å…·: {tool_name}")

            if context.tracer:
                context.tracer.log_tool_call(tool_name)

            if context.tool_executor and context.tool_executor.supports_stream(tool_name):
                # æµå¼å·¥å…·
                logger.info(f"ğŸŒŠ æµå¼æ‰§è¡Œå·¥å…·: {tool_name}")

                # ä¸Šä¸‹æ–‡æ³¨å…¥
                if inject_context_fn:
                    tool_input = inject_context_fn(tool_name, tool_input)

                async def stream_generator():
                    async for chunk in context.tool_executor.execute_stream(tool_name, tool_input):
                        yield chunk

                async for event in content_handler.emit_block_stream(
                    session_id=context.session_id,
                    block_type="tool_result",
                    initial={"tool_use_id": tool_id, "is_error": False},
                    delta_source=stream_generator(),
                ):
                    yield event
            else:
                # ä¸²è¡Œå·¥å…·
                result_info = await self.execute_single(tool_call, context, inject_context_fn)
                result = result_info.result
                result_content = _tool_result_content(result)

                # é€šè¿‡ broadcaster å‘é€ SSE äº‹ä»¶
                await content_handler.emit_block(
                    session_id=context.session_id,
                    block_type="tool_result",
                    content={
                        "tool_use_id": tool_id,
                        "content": result_content,
                        "is_error": result_info.is_error,
                    },
                )

                # yield tool_result äº‹ä»¶ç”¨äºæ¶ˆæ¯æ„å»º
                yield {
                    "type": "tool_result",
                    "content": {
                        "tool_use_id": tool_id,
                        "content": result_content,
                        "is_error": result_info.is_error,
                    },
                }


def create_tool_execution_flow() -> ToolExecutionFlow:
    """
    åˆ›å»ºå·¥å…·æ‰§è¡Œæµ

    Returns:
        ToolExecutionFlow å®ä¾‹
    """
    from core.agent.tools.special import PlanTodoHandler

    flow = ToolExecutionFlow()
    flow.register_handler(PlanTodoHandler())

    # NOTE: HumanConfirmationHandler å·²åˆ é™¤
    # hitl å·¥å…·é€šè¿‡ ToolExecutor â†’ HITLTool.execute() æ‰§è¡Œ
    # broadcaster åœ¨ content_stop æ—¶è‡ªåŠ¨å‘é€è¡¨å•äº‹ä»¶

    return flow


# ==================== V11: çŠ¶æ€ä¸€è‡´æ€§é’©å­ ====================

# ç ´åæ€§å‘½ä»¤é›†åˆï¼ˆçº¯ç¡®å®šæ€§å®‰å…¨è¾¹ç•Œæ£€æŸ¥ï¼Œéè¯­ä¹‰åˆ¤æ–­ï¼‰
_DESTRUCTIVE_COMMANDS = frozenset({
    "rm", "rmdir", "mv", "chmod", "chown",
    "truncate", "shred", "unlink",
})

# å†™å…¥ç±»å‘½ä»¤é›†åˆ
_WRITE_COMMANDS = frozenset({
    "cp", "tee", "dd", "install",
    "sed", "awk", "patch",
})

# ç›®å½•é€’å½’æ•è·çš„å®‰å…¨ä¸Šé™
_DIR_CAPTURE_MAX_FILES = 200
_DIR_CAPTURE_MAX_BYTES = 50 * 1024 * 1024  # 50 MB


def _extract_paths_from_tokens(tokens: List[str]) -> List[str]:
    """
    ä» shell å‘½ä»¤ token åˆ—è¡¨ä¸­æå–æ–‡ä»¶/ç›®å½•è·¯å¾„ã€‚

    ä»…æå–ä»¥ / æˆ– ~ å¼€å¤´ä¸”åœ¨ç£ç›˜ä¸Šå­˜åœ¨çš„è·¯å¾„ï¼ˆå®‰å…¨è¾¹ç•Œæ£€æŸ¥ï¼‰ã€‚
    """
    import os

    paths: List[str] = []
    for token in tokens:
        if token.startswith("-"):
            continue
        if token.startswith("/") or token.startswith("~"):
            expanded = os.path.expanduser(token)
            if os.path.exists(expanded):
                paths.append(expanded)
    return paths


def _detect_command_info(
    tool_input: Dict[str, Any],
) -> tuple:
    """
    ä»å·¥å…·è¾“å…¥ä¸­æ£€æµ‹ shell å‘½ä»¤ç±»å‹å’Œç›®æ ‡è·¯å¾„ã€‚

    Returns:
        (command_name, is_destructive, paths):
            command_name: å‘½ä»¤åï¼ˆå¦‚ "rm"ï¼‰ï¼Œé shell å‘½ä»¤æ—¶ä¸º ""
            is_destructive: æ˜¯å¦ä¸ºç ´åæ€§å‘½ä»¤
            paths: æå–åˆ°çš„æ–‡ä»¶/ç›®å½•è·¯å¾„åˆ—è¡¨
    """
    import os
    import shlex

    all_paths: List[str] = []
    cmd_name = ""
    is_destructive = False

    for key, value in tool_input.items():
        if isinstance(value, str):
            # ç›´æ¥è·¯å¾„å€¼ï¼ˆå¦‚ {"path": "/Users/foo/file.txt"}ï¼‰
            if value.startswith("/") or value.startswith("~"):
                expanded = os.path.expanduser(value)
                if os.path.exists(expanded):
                    all_paths.append(expanded)
            else:
                # å¯èƒ½æ˜¯ shell å‘½ä»¤å­—ç¬¦ä¸²ï¼ˆå¦‚ "rm -rf /path/to/file"ï¼‰
                try:
                    tokens = shlex.split(value)
                except ValueError:
                    continue
                if len(tokens) >= 2:
                    candidate_cmd = os.path.basename(tokens[0])
                    if candidate_cmd in _DESTRUCTIVE_COMMANDS or candidate_cmd in _WRITE_COMMANDS:
                        cmd_name = candidate_cmd
                        is_destructive = candidate_cmd in _DESTRUCTIVE_COMMANDS
                    all_paths.extend(_extract_paths_from_tokens(tokens))

        elif isinstance(value, list):
            # å‘½ä»¤æ•°ç»„ï¼ˆå¦‚ ["rm", "-rf", "/path/to/file"]ï¼‰
            str_tokens = [t for t in value if isinstance(t, str)]
            if str_tokens:
                candidate_cmd = os.path.basename(str_tokens[0])
                if candidate_cmd in _DESTRUCTIVE_COMMANDS or candidate_cmd in _WRITE_COMMANDS:
                    cmd_name = candidate_cmd
                    is_destructive = candidate_cmd in _DESTRUCTIVE_COMMANDS
                all_paths.extend(_extract_paths_from_tokens(str_tokens))

    return cmd_name, is_destructive, all_paths


def _extract_file_paths(tool_input: Dict[str, Any]) -> List[str]:
    """
    ä»å·¥å…·è¾“å…¥ä¸­æå–æ–‡ä»¶/ç›®å½•è·¯å¾„ã€‚

    æ”¯æŒï¼š
    1. ç›´æ¥è·¯å¾„å€¼ï¼ˆå¦‚ {"path": "/Users/foo/file.txt"}ï¼‰
    2. å‘½ä»¤æ•°ç»„ï¼ˆå¦‚ {"command": ["rm", "-rf", "/path"]}ï¼‰
    3. å‘½ä»¤å­—ç¬¦ä¸²ï¼ˆå¦‚ {"command": "rm -rf /path"}ï¼‰

    ä»…æå–å·²å­˜åœ¨çš„ç»å¯¹è·¯å¾„æˆ– ~ è·¯å¾„ï¼ˆå®‰å…¨è¾¹ç•Œæ£€æŸ¥ï¼Œéè¯­ä¹‰åˆ¤æ–­ï¼‰ã€‚
    """
    _, _, paths = _detect_command_info(tool_input)
    return paths


def _collect_dir_files(dir_path: str) -> List[str]:
    """
    é€’å½’æ”¶é›†ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶è·¯å¾„ï¼Œå—å®‰å…¨ä¸Šé™çº¦æŸã€‚

    Returns:
        æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼ˆæˆªæ–­åˆ° _DIR_CAPTURE_MAX_FILES ä¸”æ€»å¤§å°ä¸è¶…è¿‡ _DIR_CAPTURE_MAX_BYTESï¼‰
    """
    import os

    files: List[str] = []
    total_size = 0

    try:
        for root, _dirs, filenames in os.walk(dir_path):
            for fname in filenames:
                if len(files) >= _DIR_CAPTURE_MAX_FILES:
                    logger.debug(
                        f"ç›®å½•æ•è·è¾¾åˆ°æ–‡ä»¶æ•°ä¸Šé™ {_DIR_CAPTURE_MAX_FILES}: {dir_path}"
                    )
                    return files
                fpath = os.path.join(root, fname)
                try:
                    fsize = os.path.getsize(fpath)
                except OSError:
                    continue
                if total_size + fsize > _DIR_CAPTURE_MAX_BYTES:
                    logger.debug(
                        f"ç›®å½•æ•è·è¾¾åˆ°ä½“ç§¯ä¸Šé™ {_DIR_CAPTURE_MAX_BYTES // (1024*1024)}MB: {dir_path}"
                    )
                    return files
                total_size += fsize
                files.append(fpath)
    except OSError as e:
        logger.debug(f"ç›®å½•éå†å¤±è´¥ {dir_path}: {e}")

    return files


def _pre_capture_files(
    context: ToolExecutionContext,
    tool_input: Dict[str, Any],
) -> None:
    """
    å·¥å…·æ‰§è¡Œå‰ï¼šæå– tool_input ä¸­çš„æ–‡ä»¶/ç›®å½•è·¯å¾„ï¼Œå¤‡ä»½åˆ°çŠ¶æ€å¿«ç…§ã€‚

    å¯¹ç ´åæ€§å‘½ä»¤ï¼ˆrm, mv ç­‰ï¼‰é¢å¤–é€’å½’æ•è·ç›®å½•å†…å®¹ã€‚
    """
    import os

    state_mgr = context.state_manager
    if not state_mgr:
        return

    cmd_name, is_destructive, paths = _detect_command_info(tool_input)

    for fp in paths:
        try:
            if os.path.isfile(fp):
                state_mgr.ensure_file_captured(context.session_id, fp)
            elif os.path.isdir(fp) and is_destructive:
                # ç ´åæ€§å‘½ä»¤é’ˆå¯¹ç›®å½•æ—¶ï¼Œé€’å½’æ•è·ç›®å½•ä¸‹æ‰€æœ‰æ–‡ä»¶
                dir_files = _collect_dir_files(fp)
                if dir_files:
                    logger.info(
                        f"ç ´åæ€§å‘½ä»¤ '{cmd_name}' ç›®æ ‡ä¸ºç›®å½•ï¼Œ"
                        f"é¢„æ•è· {len(dir_files)} ä¸ªæ–‡ä»¶: {fp}"
                    )
                for df in dir_files:
                    try:
                        state_mgr.ensure_file_captured(context.session_id, df)
                    except Exception as e:
                        logger.debug(f"ç›®å½•å†…æ–‡ä»¶æ•è·è·³è¿‡ {df}: {e}")
        except Exception as e:
            logger.debug(f"æ–‡ä»¶å‰ç½®æ•è·è·³è¿‡ {fp}: {e}")


def _post_record_operation(
    context: ToolExecutionContext,
    tool_name: str,
    tool_input: Dict[str, Any],
    result: Any,
) -> None:
    """
    å·¥å…·æ‰§è¡Œåï¼šå°†æ–‡ä»¶æ“ä½œè®°å½•åˆ°æ“ä½œæ—¥å¿—ã€‚

    æ ¹æ®å‘½ä»¤ç±»å‹è®°å½•å‡†ç¡®çš„æ“ä½œç±»å‹ï¼ˆfile_write / file_delete / file_renameï¼‰ã€‚
    """
    import os

    state_mgr = context.state_manager
    if not state_mgr:
        return

    cmd_name, is_destructive, paths = _detect_command_info(tool_input)
    if not paths:
        return

    from core.state.operation_log import OperationRecord

    # æ ¹æ®å‘½ä»¤åæ¨æ–­æ“ä½œç±»å‹
    if cmd_name in ("rm", "rmdir", "unlink", "shred"):
        action = "file_delete"
    elif cmd_name in ("mv",):
        action = "file_rename"
    else:
        action = "file_write"

    for fp in paths:
        try:
            record = OperationRecord(
                operation_id=f"op_{tool_name}_{id(result)}",
                action=action,
                target=fp,
                before_state=None,  # å·²åœ¨ pre_capture ä¸­å¤‡ä»½åˆ°å¿«ç…§
                after_state=None,
            )
            state_mgr.record_operation(context.session_id, record)
        except Exception as e:
            logger.debug(f"æ“ä½œè®°å½•è·³è¿‡ {fp}: {e}")
