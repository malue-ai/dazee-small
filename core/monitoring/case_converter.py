"""
æ¡ˆä¾‹è½¬æ¢å™¨ï¼ˆCase Converterï¼‰

å®ç°é—­ç¯æœºåˆ¶ï¼š
1. å¤±è´¥æ¡ˆä¾‹ â†’ è¯„ä¼°ä»»åŠ¡
2. è¯„ä¼°ä»»åŠ¡ â†’ å›å½’æµ‹è¯•å¥—ä»¶
3. è‡ªåŠ¨æ·»åŠ åˆ°CI/CD
4. å®šæœŸæŠ¥å‘Šç”Ÿæˆ

è¿™æ˜¯ Swiss Cheese Model çš„å…³é”®ç¯èŠ‚ï¼Œç¡®ä¿ä»çœŸå®å¤±è´¥ä¸­å­¦ä¹ ã€‚
"""

from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

from utils.app_paths import get_user_data_dir

import aiofiles

from core.monitoring.failure_case_db import FailureCaseDB
from core.monitoring.failure_detector import FailureCase, FailureSeverity, FailureType
from logger import get_logger

logger = get_logger(__name__)


class CaseConverter:
    """
    æ¡ˆä¾‹è½¬æ¢å™¨

    ä½¿ç”¨æ–¹å¼ï¼š
        converter = CaseConverter(failure_db=failure_case_db)

        # è½¬æ¢å•ä¸ªæ¡ˆä¾‹
        task = converter.convert_to_eval_task(case)

        # æ‰¹é‡è½¬æ¢å¹¶ç”Ÿæˆå›å½’æµ‹è¯•å¥—ä»¶
        suite_path = converter.generate_regression_suite()

        # è‡ªåŠ¨é—­ç¯ï¼ˆå®šæœŸè¿è¡Œï¼‰
        await converter.auto_close_loop()
    """

    def __init__(
        self,
        failure_db: FailureCaseDB,
        eval_suites_dir: str = "",
        min_cases_for_suite: int = 5,
    ):
        """
        åˆå§‹åŒ–æ¡ˆä¾‹è½¬æ¢å™¨

        Args:
            failure_db: å¤±è´¥æ¡ˆä¾‹æ•°æ®åº“
            eval_suites_dir: è¯„ä¼°å¥—ä»¶ç›®å½•
            min_cases_for_suite: ç”Ÿæˆå¥—ä»¶çš„æœ€å°æ¡ˆä¾‹æ•°
        """
        self.failure_db = failure_db
        self.eval_suites_dir = Path(eval_suites_dir) if eval_suites_dir else get_user_data_dir() / "evaluation" / "suites" / "regression"
        self.min_cases_for_suite = min_cases_for_suite

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.eval_suites_dir.mkdir(parents=True, exist_ok=True)

    # ===================
    # æ¡ˆä¾‹è½¬æ¢
    # ===================

    def convert_to_eval_task(
        self, case: FailureCase, custom_graders: Optional[List[Dict]] = None
    ) -> Dict[str, Any]:
        """
        å°†å¤±è´¥æ¡ˆä¾‹è½¬æ¢ä¸ºè¯„ä¼°ä»»åŠ¡

        Args:
            case: å¤±è´¥æ¡ˆä¾‹
            custom_graders: è‡ªå®šä¹‰è¯„åˆ†å™¨é…ç½®

        Returns:
            Dict: è¯„ä¼°ä»»åŠ¡é…ç½®
        """
        # ç”ŸæˆåŸºç¡€ä»»åŠ¡ç»“æ„
        task = {
            "id": f"regression_{case.id}",
            "description": self._generate_task_description(case),
            "category": "regression",
            "source": {
                "type": "failure_case",
                "case_id": case.id,
                "failure_type": case.failure_type.value,
                "severity": case.severity.value,
                "original_timestamp": case.timestamp.isoformat(),
            },
            "input": {
                "user_query": case.user_query,
                "conversation_history": case.conversation_history,
                "context": case.context,
            },
            "expected_outcome": self._generate_expected_outcome(case),
            "graders": custom_graders or self._generate_graders(case),
            "trials": 3,
            "timeout_seconds": self._calculate_timeout(case),
            "tags": self._generate_tags(case),
            "metadata": {
                "converted_at": datetime.now().isoformat(),
                "original_error": case.error_message,
            },
        }

        return task

    def _generate_task_description(self, case: FailureCase) -> str:
        """ç”Ÿæˆä»»åŠ¡æè¿°"""
        type_descriptions = {
            FailureType.CONTEXT_OVERFLOW: "ä¸Šä¸‹æ–‡æº¢å‡ºå›å½’æµ‹è¯•",
            FailureType.TOOL_CALL_FAILURE: "å·¥å…·è°ƒç”¨å¤±è´¥å›å½’æµ‹è¯•",
            FailureType.CONSECUTIVE_TOOL_ERRORS: "è¿ç»­å·¥å…·é”™è¯¯å›å½’æµ‹è¯•",
            FailureType.USER_NEGATIVE_FEEDBACK: "ç”¨æˆ·è´Ÿé¢åé¦ˆæ”¹è¿›æµ‹è¯•",
            FailureType.INTENT_MISMATCH: "æ„å›¾è¯†åˆ«å›å½’æµ‹è¯•",
            FailureType.TIMEOUT: "è¶…æ—¶é—®é¢˜å›å½’æµ‹è¯•",
            FailureType.RESPONSE_QUALITY: "å“åº”è´¨é‡æ”¹è¿›æµ‹è¯•",
            FailureType.SAFETY_VIOLATION: "å®‰å…¨åˆè§„å›å½’æµ‹è¯•",
            FailureType.UNKNOWN_ERROR: "æœªçŸ¥é”™è¯¯å›å½’æµ‹è¯•",
        }

        base = type_descriptions.get(case.failure_type, "å›å½’æµ‹è¯•")
        query_preview = (
            case.user_query[:50] + "..." if len(case.user_query) > 50 else case.user_query
        )

        return f"{base}: {query_preview}"

    def _generate_expected_outcome(self, case: FailureCase) -> Dict[str, Any]:
        """ç”Ÿæˆé¢„æœŸç»“æœ"""
        outcome = {
            "should_succeed": True,  # å›å½’æµ‹è¯•çš„æ ¸å¿ƒç›®æ ‡
            "original_failure_type": case.failure_type.value,
        }

        # æ ¹æ®å¤±è´¥ç±»å‹æ·»åŠ ç‰¹å®šé¢„æœŸ
        if case.failure_type == FailureType.CONTEXT_OVERFLOW:
            max_tokens = case.token_usage.get("max", 200000)
            outcome["max_tokens"] = max_tokens
            outcome["token_efficiency"] = "high"

        elif case.failure_type == FailureType.TIMEOUT:
            timeout = case.context.get("timeout_seconds", 60)
            outcome["max_duration_seconds"] = timeout * 0.8  # æ¯”åŸæ¥æ›´å¿«

        elif case.failure_type == FailureType.INTENT_MISMATCH:
            outcome["expected_intent"] = case.context.get("expected_intent")

        return outcome

    def _generate_graders(self, case: FailureCase) -> List[Dict[str, Any]]:
        """ç”Ÿæˆè¯„åˆ†å™¨é…ç½®"""
        graders = []

        # é€šç”¨ï¼šæ£€æŸ¥æ— å·¥å…·é”™è¯¯
        graders.append(
            {
                "type": "code",
                "name": "no_tool_errors",
                "check": "check_no_tool_errors()",
            }
        )

        # æ ¹æ®å¤±è´¥ç±»å‹æ·»åŠ ç‰¹å®šè¯„åˆ†å™¨
        if case.failure_type == FailureType.CONTEXT_OVERFLOW:
            max_tokens = case.token_usage.get("max", 200000)
            graders.append(
                {
                    "type": "code",
                    "name": "token_limit",
                    "check": f"check_token_limit({int(max_tokens * 0.9)})",  # 90%é˜ˆå€¼
                }
            )
            graders.append(
                {
                    "type": "code",
                    "name": "token_efficiency",
                    "check": "check_token_efficiency(5000)",  # æ¯æ¬¡è°ƒç”¨æœ€å¤š5000 tokens
                }
            )

        elif case.failure_type == FailureType.TIMEOUT:
            timeout_ms = case.context.get("timeout_seconds", 60) * 1000
            graders.append(
                {
                    "type": "code",
                    "name": "execution_time",
                    "check": f"check_execution_time({int(timeout_ms * 0.8)})",  # 80%é˜ˆå€¼
                }
            )

        elif case.failure_type == FailureType.USER_NEGATIVE_FEEDBACK:
            graders.append(
                {
                    "type": "model",
                    "rubric": "grade_response_quality",
                    "min_score": 4,
                    "weight": 2.0,  # è´¨é‡è¯„åˆ†æƒé‡åŠ å€
                }
            )

        elif case.failure_type == FailureType.INTENT_MISMATCH:
            graders.append(
                {
                    "type": "model",
                    "rubric": "grade_intent_understanding",
                    "min_score": 4,
                }
            )

        elif case.failure_type == FailureType.SAFETY_VIOLATION:
            graders.append(
                {
                    "type": "model",
                    "rubric": "grade_safety_compliance",
                    "min_score": 5,  # å®‰å…¨å¿…é¡»æ»¡åˆ†
                }
            )

        # é€šç”¨ï¼šè¿‡åº¦å·¥ç¨‹åŒ–æ£€æµ‹
        graders.append(
            {
                "type": "model",
                "rubric": "grade_over_engineering",
                "min_score": 4,
            }
        )

        return graders

    def _calculate_timeout(self, case: FailureCase) -> int:
        """è®¡ç®—è¶…æ—¶æ—¶é—´"""
        if case.failure_type == FailureType.TIMEOUT:
            # è¶…æ—¶æ¡ˆä¾‹ä½¿ç”¨æ›´é•¿çš„è¶…æ—¶æ—¶é—´
            return case.context.get("timeout_seconds", 60) * 2

        return 60  # é»˜è®¤60ç§’

    def _generate_tags(self, case: FailureCase) -> List[str]:
        """ç”Ÿæˆæ ‡ç­¾"""
        tags = [
            "regression",
            case.failure_type.value,
            case.severity.value,
        ]

        # æ·»åŠ ç”¨æˆ·ç›¸å…³æ ‡ç­¾
        if case.user_id:
            tags.append("user_specific")

        # æ·»åŠ æ—¶é—´ç›¸å…³æ ‡ç­¾
        if case.timestamp.weekday() >= 5:
            tags.append("weekend")

        return tags

    # ===================
    # æ‰¹é‡è½¬æ¢
    # ===================

    async def generate_regression_suite(
        self,
        failure_types: Optional[List[FailureType]] = None,
        max_cases: int = 100,
        output_filename: Optional[str] = None,
    ) -> Optional[str]:
        """
        ç”Ÿæˆå›å½’æµ‹è¯•å¥—ä»¶ï¼ˆå¼‚æ­¥ï¼‰

        Args:
            failure_types: å¤±è´¥ç±»å‹ç­›é€‰
            max_cases: æœ€å¤§æ¡ˆä¾‹æ•°
            output_filename: è¾“å‡ºæ–‡ä»¶å

        Returns:
            str: ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœæ¡ˆä¾‹æ•°è¶³å¤Ÿï¼‰
        """
        # è·å–å¾…è½¬æ¢çš„æ¡ˆä¾‹
        cases = self.failure_db.query(status="reviewed", limit=max_cases)

        if failure_types:
            cases = [c for c in cases if c.failure_type in failure_types]

        if len(cases) < self.min_cases_for_suite:
            logger.info(f"æ¡ˆä¾‹æ•° ({len(cases)}) ä¸è¶³ {self.min_cases_for_suite}ï¼Œè·³è¿‡ç”Ÿæˆ")
            return None

        # è½¬æ¢ä¸ºè¯„ä¼°ä»»åŠ¡
        tasks = [self.convert_to_eval_task(case) for case in cases]

        # ç”Ÿæˆå¥—ä»¶
        suite = {
            "id": f"regression_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            "name": f"å›å½’æµ‹è¯•å¥—ä»¶ ({len(tasks)} ä¸ªä»»åŠ¡)",
            "description": "ä»å¤±è´¥æ¡ˆä¾‹è‡ªåŠ¨ç”Ÿæˆçš„å›å½’æµ‹è¯•å¥—ä»¶",
            "category": "regression",
            "default_trials": 3,
            "metadata": {
                "generated_at": datetime.now().isoformat(),
                "source_cases": [c.id for c in cases],
                "failure_types": list(set(c.failure_type.value for c in cases)),
            },
            "tasks": tasks,
        }

        # ä¿å­˜åˆ°æ–‡ä»¶ï¼ˆå¼‚æ­¥ï¼‰
        if output_filename is None:
            output_filename = f"regression_{datetime.now().strftime('%Y%m%d')}.yaml"

        output_path = self.eval_suites_dir / output_filename

        import yaml

        content = yaml.dump(suite, allow_unicode=True, default_flow_style=False)
        async with aiofiles.open(output_path, "w", encoding="utf-8") as f:
            await f.write(content)

        # æ›´æ–°æ¡ˆä¾‹çŠ¶æ€ï¼ˆå¼‚æ­¥ï¼‰
        for case in cases:
            case.status = "converted"
            await self.failure_db.update(case)

        logger.info(f"ğŸ“‹ ç”Ÿæˆå›å½’æµ‹è¯•å¥—ä»¶: {output_path} ({len(tasks)} ä¸ªä»»åŠ¡)")

        return str(output_path)

    # ===================
    # è‡ªåŠ¨é—­ç¯
    # ===================

    async def auto_close_loop(self) -> Dict[str, Any]:
        """
        è‡ªåŠ¨é—­ç¯æµç¨‹

        æµç¨‹ï¼š
        1. æ£€æŸ¥æ–°å¢çš„å¤±è´¥æ¡ˆä¾‹
        2. è‡ªåŠ¨å®¡æŸ¥ç®€å•æ¡ˆä¾‹
        3. ç”Ÿæˆå›å½’æµ‹è¯•å¥—ä»¶
        4. è¿”å›å¤„ç†æŠ¥å‘Š

        Returns:
            Dict: å¤„ç†æŠ¥å‘Š
        """
        report = {
            "timestamp": datetime.now().isoformat(),
            "new_cases_found": 0,
            "auto_reviewed": 0,
            "suite_generated": False,
            "suite_path": None,
        }

        # 1. è·å–æ–°æ¡ˆä¾‹
        new_cases = self.failure_db.query(status="new", limit=100)
        report["new_cases_found"] = len(new_cases)

        # 2. è‡ªåŠ¨å®¡æŸ¥ç®€å•æ¡ˆä¾‹
        auto_reviewed_count = 0
        for case in new_cases:
            if self._can_auto_review(case):
                case.status = "reviewed"
                case.reviewed_by = "auto_reviewer"
                case.reviewed_at = datetime.now()
                self.failure_db.update(case)
                auto_reviewed_count += 1

        report["auto_reviewed"] = auto_reviewed_count

        # 3. æ£€æŸ¥æ˜¯å¦éœ€è¦ç”Ÿæˆæ–°å¥—ä»¶
        reviewed_count = self.failure_db.count(status="reviewed")
        if reviewed_count >= self.min_cases_for_suite:
            suite_path = self.generate_regression_suite()
            if suite_path:
                report["suite_generated"] = True
                report["suite_path"] = suite_path

        logger.info(f"ğŸ”„ é—­ç¯å¤„ç†å®Œæˆ: {report}")

        return report

    def _can_auto_review(self, case: FailureCase) -> bool:
        """
        åˆ¤æ–­æ¡ˆä¾‹æ˜¯å¦å¯ä»¥è‡ªåŠ¨å®¡æŸ¥

        è‡ªåŠ¨å®¡æŸ¥æ¡ä»¶ï¼š
        1. é«˜ä¸¥é‡åº¦æ¡ˆä¾‹ï¼ˆCRITICAL/HIGHï¼‰å¿…é¡»äººå·¥å®¡æŸ¥
        2. å®‰å…¨è¿è§„å¿…é¡»äººå·¥å®¡æŸ¥
        3. å…¶ä»–æ¡ˆä¾‹å¯ä»¥è‡ªåŠ¨å®¡æŸ¥

        Args:
            case: å¤±è´¥æ¡ˆä¾‹

        Returns:
            bool: æ˜¯å¦å¯ä»¥è‡ªåŠ¨å®¡æŸ¥
        """
        # é«˜ä¸¥é‡åº¦éœ€è¦äººå·¥å®¡æŸ¥
        if case.severity in [FailureSeverity.CRITICAL, FailureSeverity.HIGH]:
            return False

        # å®‰å…¨è¿è§„éœ€è¦äººå·¥å®¡æŸ¥
        if case.failure_type == FailureType.SAFETY_VIOLATION:
            return False

        # ç”¨æˆ·è´Ÿé¢åé¦ˆéœ€è¦äººå·¥å®¡æŸ¥ï¼ˆå¯èƒ½éœ€è¦åˆ†æåŸå› ï¼‰
        if case.failure_type == FailureType.USER_NEGATIVE_FEEDBACK:
            return False

        return True

    # ===================
    # æŠ¥å‘Šç”Ÿæˆ
    # ===================

    def generate_weekly_report(self) -> Dict[str, Any]:
        """
        ç”Ÿæˆæ¯å‘¨é—­ç¯æŠ¥å‘Š

        Returns:
            Dict: å‘¨æŠ¥æ•°æ®
        """
        from datetime import timedelta

        # æœ¬å‘¨æ—¶é—´èŒƒå›´
        now = datetime.now()
        week_start = now - timedelta(days=7)

        # ç»Ÿè®¡æ•°æ®
        stats = self.failure_db.get_statistics()

        # æœ¬å‘¨æ¡ˆä¾‹
        weekly_cases = self.failure_db.query(start_date=week_start, limit=1000)

        # æŒ‰ç±»å‹ç»Ÿè®¡
        by_type = {}
        for ft in FailureType:
            count = sum(1 for c in weekly_cases if c.failure_type == ft)
            if count > 0:
                by_type[ft.value] = count

        # è½¬åŒ–ç‡
        converted = sum(1 for c in weekly_cases if c.status == "converted")
        conversion_rate = converted / len(weekly_cases) if weekly_cases else 0

        return {
            "report_type": "weekly_close_loop",
            "period": {
                "start": week_start.isoformat(),
                "end": now.isoformat(),
            },
            "summary": {
                "total_cases": len(weekly_cases),
                "converted_to_tests": converted,
                "conversion_rate": f"{conversion_rate:.1%}",
                "pending_review": stats["pending_review"],
            },
            "by_failure_type": by_type,
            "top_issues": self._identify_top_issues(weekly_cases),
            "recommendations": self._generate_recommendations(weekly_cases),
        }

    def _identify_top_issues(
        self, cases: List[FailureCase], top_n: int = 3
    ) -> List[Dict[str, Any]]:
        """è¯†åˆ«æœ€å¸¸è§é—®é¢˜"""
        from collections import Counter

        # æŒ‰é”™è¯¯æ¶ˆæ¯èšåˆ
        error_counts = Counter(c.error_message[:100] for c in cases)

        top_issues = []
        for error, count in error_counts.most_common(top_n):
            # æ‰¾åˆ°ä»£è¡¨æ€§æ¡ˆä¾‹
            example = next(c for c in cases if c.error_message.startswith(error[:100]))

            top_issues.append(
                {
                    "error_pattern": error,
                    "count": count,
                    "failure_type": example.failure_type.value,
                    "severity": example.severity.value,
                    "example_case_id": example.id,
                }
            )

        return top_issues

    def _generate_recommendations(self, cases: List[FailureCase]) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []

        # ç»Ÿè®¡å¤±è´¥ç±»å‹
        type_counts = {}
        for case in cases:
            type_counts[case.failure_type] = type_counts.get(case.failure_type, 0) + 1

        # æ ¹æ®æœ€å¸¸è§é—®é¢˜ç”Ÿæˆå»ºè®®
        if type_counts.get(FailureType.CONTEXT_OVERFLOW, 0) > 5:
            recommendations.append(
                "ä¸Šä¸‹æ–‡æº¢å‡ºé¢‘ç¹å‘ç”Ÿï¼Œå»ºè®®ï¼š\n"
                "1. ä¼˜åŒ–å¯¹è¯å†å²å‹ç¼©ç­–ç•¥\n"
                "2. è€ƒè™‘ä½¿ç”¨æ›´é•¿ä¸Šä¸‹æ–‡çª—å£çš„æ¨¡å‹"
            )

        if type_counts.get(FailureType.TIMEOUT, 0) > 5:
            recommendations.append(
                "è¶…æ—¶é—®é¢˜è¾ƒå¤šï¼Œå»ºè®®ï¼š\n" "1. åˆ†æè¶…æ—¶æ¡ˆä¾‹çš„å·¥å…·è°ƒç”¨æ¨¡å¼\n" "2. ä¼˜åŒ–å·¥å…·æ‰§è¡Œæ•ˆç‡"
            )

        if type_counts.get(FailureType.INTENT_MISMATCH, 0) > 5:
            recommendations.append(
                "æ„å›¾è¯†åˆ«é”™è¯¯è¾ƒå¤šï¼Œå»ºè®®ï¼š\n" "1. å¢åŠ æ„å›¾è¯†åˆ«çš„è®­ç»ƒæ ·æœ¬\n" "2. ä¼˜åŒ–æ„å›¾åˆ†ææç¤ºè¯"
            )

        if type_counts.get(FailureType.USER_NEGATIVE_FEEDBACK, 0) > 3:
            recommendations.append(
                "ç”¨æˆ·è´Ÿé¢åé¦ˆè¾ƒå¤šï¼Œå»ºè®®ï¼š\n"
                "1. åˆ†æåé¦ˆå†…å®¹ï¼Œè¯†åˆ«å…±æ€§é—®é¢˜\n"
                "2. æ”¹è¿›å“åº”è´¨é‡å’Œç”¨æˆ·ä½“éªŒ"
            )

        if not recommendations:
            recommendations.append("æœ¬å‘¨å¤±è´¥æ¡ˆä¾‹è¾ƒå°‘ï¼Œç³»ç»Ÿè¿è¡Œç¨³å®šã€‚")

        return recommendations
