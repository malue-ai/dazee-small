"""
ç”Ÿäº§ç›‘æŽ§å™¨ï¼ˆProduction Monitorï¼‰

å®žæ—¶ç›‘æŽ§ç”Ÿäº§çŽ¯å¢ƒï¼Œè´Ÿè´£ï¼š
1. é‡‡é›†æ€§èƒ½æŒ‡æ ‡ï¼ˆå“åº”å»¶è¿Ÿã€Tokenæ¶ˆè€—ã€å·¥å…·è°ƒç”¨æˆåŠŸçŽ‡ï¼‰
2. è§¦å‘å‘Šè­¦ï¼ˆé˜ˆå€¼è¶…é™æ—¶ï¼‰
3. è®°å½•å®¡è®¡æ—¥å¿—ï¼ˆç”¨äºŽé—®é¢˜è¿½æº¯ï¼‰
4. ä¸Žå¤±è´¥æ£€æµ‹å™¨ååŒå·¥ä½œ
"""

import asyncio
import time
from collections import deque
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from typing import Any, Callable, Dict, List, Optional

from logger import get_logger

logger = get_logger(__name__)


class MetricType(str, Enum):
    """æŒ‡æ ‡ç±»åž‹"""

    LATENCY = "latency"  # å“åº”å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰
    TOKEN_INPUT = "token_input"  # è¾“å…¥Tokenæ•°
    TOKEN_OUTPUT = "token_output"  # è¾“å‡ºTokenæ•°
    TOKEN_TOTAL = "token_total"  # æ€»Tokenæ•°
    TOOL_CALL_SUCCESS = "tool_call_success"  # å·¥å…·è°ƒç”¨æˆåŠŸçŽ‡
    TOOL_CALL_ERROR = "tool_call_error"  # å·¥å…·è°ƒç”¨é”™è¯¯æ•°
    CONTEXT_OVERFLOW = "context_overflow"  # ä¸Šä¸‹æ–‡æº¢å‡ºæ¬¡æ•°
    USER_FEEDBACK_NEGATIVE = "user_feedback_negative"  # è´Ÿé¢åé¦ˆæ•°


class AlertLevel(str, Enum):
    """å‘Šè­¦çº§åˆ«"""

    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"


@dataclass
class MetricPoint:
    """æŒ‡æ ‡æ•°æ®ç‚¹"""

    metric_type: MetricType
    value: float
    timestamp: datetime = field(default_factory=datetime.now)
    labels: Dict[str, str] = field(default_factory=dict)

    def to_dict(self) -> Dict[str, Any]:
        return {
            "type": self.metric_type.value,
            "value": self.value,
            "timestamp": self.timestamp.isoformat(),
            "labels": self.labels,
        }


@dataclass
class Alert:
    """å‘Šè­¦"""

    level: AlertLevel
    metric_type: MetricType
    message: str
    value: float
    threshold: float
    timestamp: datetime = field(default_factory=datetime.now)
    labels: Dict[str, str] = field(default_factory=dict)

    def to_dict(self) -> Dict[str, Any]:
        return {
            "level": self.level.value,
            "metric": self.metric_type.value,
            "message": self.message,
            "value": self.value,
            "threshold": self.threshold,
            "timestamp": self.timestamp.isoformat(),
            "labels": self.labels,
        }


class ProductionMonitor:
    """
    ç”Ÿäº§ç›‘æŽ§å™¨

    ä½¿ç”¨æ–¹å¼ï¼š
        monitor = ProductionMonitor()

        # è®°å½•æŒ‡æ ‡
        monitor.record_latency(conversation_id="conv_123", latency_ms=500)
        monitor.record_token_usage(conversation_id="conv_123", input=1000, output=500)

        # èŽ·å–ç»Ÿè®¡
        stats = monitor.get_statistics(time_range_minutes=60)

        # èŽ·å–å‘Šè­¦
        alerts = monitor.get_recent_alerts()
    """

    def __init__(
        self,
        alert_handlers: Optional[List[Callable[[Alert], None]]] = None,
        max_history_size: int = 10000,
    ):
        """
        åˆå§‹åŒ–ç”Ÿäº§ç›‘æŽ§å™¨

        Args:
            alert_handlers: å‘Šè­¦å¤„ç†å™¨åˆ—è¡¨
            max_history_size: åŽ†å²æ•°æ®æœ€å¤§æ¡æ•°
        """
        self.alert_handlers = alert_handlers or []
        self.max_history_size = max_history_size

        # æŒ‡æ ‡åŽ†å²ï¼ˆä½¿ç”¨dequeè‡ªåŠ¨é™åˆ¶å¤§å°ï¼‰
        self.metrics_history: deque[MetricPoint] = deque(maxlen=max_history_size)

        # å‘Šè­¦åŽ†å²
        self.alerts_history: deque[Alert] = deque(maxlen=1000)

        # å‘Šè­¦é˜ˆå€¼é…ç½®
        self.thresholds = {
            MetricType.LATENCY: {
                AlertLevel.WARNING: 5000,  # 5ç§’
                AlertLevel.ERROR: 10000,  # 10ç§’
                AlertLevel.CRITICAL: 30000,  # 30ç§’
            },
            MetricType.TOKEN_TOTAL: {
                AlertLevel.WARNING: 150000,  # 150K
                AlertLevel.ERROR: 190000,  # 190K
                AlertLevel.CRITICAL: 200000,  # 200Kï¼ˆæŽ¥è¿‘æº¢å‡ºï¼‰
            },
            MetricType.TOOL_CALL_ERROR: {
                AlertLevel.WARNING: 3,  # 3æ¬¡é”™è¯¯
                AlertLevel.ERROR: 5,  # 5æ¬¡é”™è¯¯
                AlertLevel.CRITICAL: 10,  # 10æ¬¡é”™è¯¯
            },
            MetricType.CONTEXT_OVERFLOW: {
                AlertLevel.ERROR: 1,  # ä»»ä½•æº¢å‡ºéƒ½æ˜¯é”™è¯¯
            },
        }

        # è®¡æ•°å™¨ï¼ˆç”¨äºŽç»Ÿè®¡ï¼‰
        self._counters: Dict[str, int] = {}

    # ===================
    # æŒ‡æ ‡è®°å½•
    # ===================

    def record_metric(
        self, metric_type: MetricType, value: float, labels: Optional[Dict[str, str]] = None
    ) -> None:
        """
        è®°å½•æŒ‡æ ‡

        Args:
            metric_type: æŒ‡æ ‡ç±»åž‹
            value: æŒ‡æ ‡å€¼
            labels: æ ‡ç­¾ï¼ˆå¦‚conversation_id, user_idç­‰ï¼‰
        """
        point = MetricPoint(
            metric_type=metric_type,
            value=value,
            labels=labels or {},
        )
        self.metrics_history.append(point)

        # æ£€æŸ¥æ˜¯å¦éœ€è¦å‘Šè­¦
        self._check_threshold(point)

        logger.debug(f"ðŸ“Š è®°å½•æŒ‡æ ‡: {metric_type.value}={value}")

    def record_latency(
        self,
        latency_ms: float,
        conversation_id: Optional[str] = None,
        user_id: Optional[str] = None,
    ) -> None:
        """
        è®°å½•å“åº”å»¶è¿Ÿ

        Args:
            latency_ms: å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰
            conversation_id: ä¼šè¯ID
            user_id: ç”¨æˆ·ID
        """
        labels = {}
        if conversation_id:
            labels["conversation_id"] = conversation_id
        if user_id:
            labels["user_id"] = user_id

        self.record_metric(MetricType.LATENCY, latency_ms, labels)

    def record_token_usage(
        self,
        input_tokens: int,
        output_tokens: int,
        thinking_tokens: int = 0,
        conversation_id: Optional[str] = None,
        user_id: Optional[str] = None,
    ) -> None:
        """
        è®°å½•Tokenä½¿ç”¨é‡

        Args:
            input_tokens: è¾“å…¥Tokenæ•°
            output_tokens: è¾“å‡ºTokenæ•°
            thinking_tokens: æ€è€ƒTokenæ•°
            conversation_id: ä¼šè¯ID
            user_id: ç”¨æˆ·ID
        """
        labels = {}
        if conversation_id:
            labels["conversation_id"] = conversation_id
        if user_id:
            labels["user_id"] = user_id

        self.record_metric(MetricType.TOKEN_INPUT, input_tokens, labels)
        self.record_metric(MetricType.TOKEN_OUTPUT, output_tokens, labels)
        self.record_metric(
            MetricType.TOKEN_TOTAL, input_tokens + output_tokens + thinking_tokens, labels
        )

    def record_tool_call(
        self,
        tool_name: str,
        success: bool,
        duration_ms: Optional[float] = None,
        error: Optional[str] = None,
        conversation_id: Optional[str] = None,
    ) -> None:
        """
        è®°å½•å·¥å…·è°ƒç”¨

        Args:
            tool_name: å·¥å…·åç§°
            success: æ˜¯å¦æˆåŠŸ
            duration_ms: æ‰§è¡Œæ—¶é•¿
            error: é”™è¯¯ä¿¡æ¯
            conversation_id: ä¼šè¯ID
        """
        labels = {"tool": tool_name}
        if conversation_id:
            labels["conversation_id"] = conversation_id

        if success:
            self.record_metric(MetricType.TOOL_CALL_SUCCESS, 1, labels)
        else:
            self.record_metric(MetricType.TOOL_CALL_ERROR, 1, labels)
            logger.warning(f"âš ï¸ å·¥å…·è°ƒç”¨å¤±è´¥: {tool_name}, é”™è¯¯: {error}")

    def record_context_overflow(
        self, conversation_id: str, current_tokens: int, max_tokens: int
    ) -> None:
        """
        è®°å½•ä¸Šä¸‹æ–‡æº¢å‡º

        Args:
            conversation_id: ä¼šè¯ID
            current_tokens: å½“å‰Tokenæ•°
            max_tokens: æœ€å¤§Tokenæ•°
        """
        labels = {
            "conversation_id": conversation_id,
            "current_tokens": str(current_tokens),
            "max_tokens": str(max_tokens),
        }

        self.record_metric(MetricType.CONTEXT_OVERFLOW, 1, labels)
        logger.error(f"ðŸš¨ ä¸Šä¸‹æ–‡æº¢å‡º: {conversation_id}, {current_tokens}/{max_tokens}")

    def record_user_feedback(
        self,
        feedback_type: str,
        conversation_id: str,
        user_id: Optional[str] = None,
        comment: Optional[str] = None,
    ) -> None:
        """
        è®°å½•ç”¨æˆ·åé¦ˆ

        Args:
            feedback_type: åé¦ˆç±»åž‹ï¼ˆpositive/negativeï¼‰
            conversation_id: ä¼šè¯ID
            user_id: ç”¨æˆ·ID
            comment: ç”¨æˆ·è¯„è®º
        """
        labels = {
            "conversation_id": conversation_id,
            "feedback_type": feedback_type,
        }
        if user_id:
            labels["user_id"] = user_id
        if comment:
            labels["comment"] = comment[:100]  # æˆªæ–­

        if feedback_type == "negative":
            self.record_metric(MetricType.USER_FEEDBACK_NEGATIVE, 1, labels)
            logger.warning(f"ðŸ‘Ž ç”¨æˆ·è´Ÿé¢åé¦ˆ: {conversation_id}")

    # ===================
    # é˜ˆå€¼æ£€æŸ¥ä¸Žå‘Šè­¦
    # ===================

    def _check_threshold(self, point: MetricPoint) -> None:
        """
        æ£€æŸ¥æŒ‡æ ‡æ˜¯å¦è¶…è¿‡é˜ˆå€¼ï¼Œè§¦å‘å‘Šè­¦

        Args:
            point: æŒ‡æ ‡æ•°æ®ç‚¹
        """
        thresholds = self.thresholds.get(point.metric_type, {})

        for level, threshold in thresholds.items():
            if point.value >= threshold:
                alert = Alert(
                    level=level,
                    metric_type=point.metric_type,
                    message=f"{point.metric_type.value} è¶…è¿‡é˜ˆå€¼: {point.value} >= {threshold}",
                    value=point.value,
                    threshold=threshold,
                    labels=point.labels,
                )
                self._trigger_alert(alert)
                break  # åªè§¦å‘æœ€é«˜çº§åˆ«çš„å‘Šè­¦

    def _trigger_alert(self, alert: Alert) -> None:
        """
        è§¦å‘å‘Šè­¦

        Args:
            alert: å‘Šè­¦å¯¹è±¡
        """
        self.alerts_history.append(alert)

        # è®°å½•æ—¥å¿—
        log_msg = f"ðŸš¨ å‘Šè­¦ [{alert.level.value}]: {alert.message}"
        if alert.level == AlertLevel.CRITICAL:
            logger.critical(log_msg)
        elif alert.level == AlertLevel.ERROR:
            logger.error(log_msg)
        elif alert.level == AlertLevel.WARNING:
            logger.warning(log_msg)
        else:
            logger.info(log_msg)

        # è°ƒç”¨å‘Šè­¦å¤„ç†å™¨
        for handler in self.alert_handlers:
            try:
                handler(alert)
            except Exception as e:
                logger.error(f"å‘Šè­¦å¤„ç†å™¨æ‰§è¡Œå¤±è´¥: {e}")

    def add_alert_handler(self, handler: Callable[[Alert], None]) -> None:
        """
        æ·»åŠ å‘Šè­¦å¤„ç†å™¨

        Args:
            handler: å‘Šè­¦å¤„ç†å‡½æ•°
        """
        self.alert_handlers.append(handler)

    # ===================
    # ç»Ÿè®¡æŸ¥è¯¢
    # ===================

    def get_statistics(
        self, time_range_minutes: int = 60, metric_types: Optional[List[MetricType]] = None
    ) -> Dict[str, Any]:
        """
        èŽ·å–ç»Ÿè®¡ä¿¡æ¯

        Args:
            time_range_minutes: æ—¶é—´èŒƒå›´ï¼ˆåˆ†é’Ÿï¼‰
            metric_types: æŒ‡å®šçš„æŒ‡æ ‡ç±»åž‹

        Returns:
            Dict: ç»Ÿè®¡ä¿¡æ¯
        """
        cutoff = datetime.now() - timedelta(minutes=time_range_minutes)

        # ç­›é€‰æ—¶é—´èŒƒå›´å†…çš„æŒ‡æ ‡
        recent_metrics = [m for m in self.metrics_history if m.timestamp >= cutoff]

        # æŒ‰ç±»åž‹åˆ†ç»„
        by_type: Dict[MetricType, List[float]] = {}
        for m in recent_metrics:
            if metric_types is None or m.metric_type in metric_types:
                if m.metric_type not in by_type:
                    by_type[m.metric_type] = []
                by_type[m.metric_type].append(m.value)

        # è®¡ç®—ç»Ÿè®¡é‡
        stats = {}
        for metric_type, values in by_type.items():
            if values:
                stats[metric_type.value] = {
                    "count": len(values),
                    "sum": sum(values),
                    "avg": sum(values) / len(values),
                    "min": min(values),
                    "max": max(values),
                }

        return {
            "time_range_minutes": time_range_minutes,
            "total_points": len(recent_metrics),
            "metrics": stats,
        }

    def get_recent_alerts(
        self, limit: int = 100, level: Optional[AlertLevel] = None
    ) -> List[Dict[str, Any]]:
        """
        èŽ·å–æœ€è¿‘çš„å‘Šè­¦

        Args:
            limit: è¿”å›žæ•°é‡é™åˆ¶
            level: å‘Šè­¦çº§åˆ«ç­›é€‰

        Returns:
            List[Dict]: å‘Šè­¦åˆ—è¡¨
        """
        alerts = list(self.alerts_history)

        if level:
            alerts = [a for a in alerts if a.level == level]

        # æŒ‰æ—¶é—´å€’åº
        alerts.sort(key=lambda a: a.timestamp, reverse=True)

        return [a.to_dict() for a in alerts[:limit]]

    def get_health_status(self) -> Dict[str, Any]:
        """
        èŽ·å–å¥åº·çŠ¶æ€

        Returns:
            Dict: å¥åº·çŠ¶æ€
        """
        # æœ€è¿‘5åˆ†é’Ÿçš„ç»Ÿè®¡
        stats = self.get_statistics(time_range_minutes=5)

        # æœ€è¿‘çš„å‘Šè­¦
        recent_alerts = self.get_recent_alerts(limit=10)

        # è®¡ç®—å¥åº·è¯„åˆ†
        health_score = 100

        # æ ¹æ®å‘Šè­¦æ‰£åˆ†
        for alert in recent_alerts:
            if alert["level"] == "critical":
                health_score -= 30
            elif alert["level"] == "error":
                health_score -= 10
            elif alert["level"] == "warning":
                health_score -= 5

        health_score = max(0, health_score)

        # ç¡®å®šçŠ¶æ€
        if health_score >= 80:
            status = "healthy"
        elif health_score >= 50:
            status = "degraded"
        else:
            status = "unhealthy"

        return {
            "status": status,
            "health_score": health_score,
            "statistics": stats,
            "recent_alerts_count": len(recent_alerts),
            "timestamp": datetime.now().isoformat(),
        }


class MonitoringContext:
    """
    ç›‘æŽ§ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼ˆç”¨äºŽè‡ªåŠ¨è®°å½•æŒ‡æ ‡ï¼‰

    ä½¿ç”¨æ–¹å¼ï¼š
        async with MonitoringContext(monitor, conversation_id="conv_123") as ctx:
            # æ‰§è¡ŒAgent
            result = await agent.chat(...)

            # è®°å½•Tokenä½¿ç”¨
            ctx.record_tokens(input=1000, output=500)

        # è‡ªåŠ¨è®°å½•å»¶è¿Ÿ
    """

    def __init__(
        self,
        monitor: ProductionMonitor,
        conversation_id: Optional[str] = None,
        user_id: Optional[str] = None,
    ):
        self.monitor = monitor
        self.conversation_id = conversation_id
        self.user_id = user_id
        self.start_time: Optional[float] = None

    async def __aenter__(self):
        self.start_time = time.time()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.start_time:
            latency_ms = (time.time() - self.start_time) * 1000
            self.monitor.record_latency(
                latency_ms=latency_ms,
                conversation_id=self.conversation_id,
                user_id=self.user_id,
            )

        # å¦‚æžœæœ‰å¼‚å¸¸ï¼Œè®°å½•
        if exc_type:
            logger.error(f"ç›‘æŽ§ä¸Šä¸‹æ–‡å¼‚å¸¸: {exc_val}")

        return False

    def record_tokens(
        self, input_tokens: int, output_tokens: int, thinking_tokens: int = 0
    ) -> None:
        """è®°å½•Tokenä½¿ç”¨"""
        self.monitor.record_token_usage(
            input_tokens=input_tokens,
            output_tokens=output_tokens,
            thinking_tokens=thinking_tokens,
            conversation_id=self.conversation_id,
            user_id=self.user_id,
        )

    def record_tool_call(
        self,
        tool_name: str,
        success: bool,
        duration_ms: Optional[float] = None,
        error: Optional[str] = None,
    ) -> None:
        """è®°å½•å·¥å…·è°ƒç”¨"""
        self.monitor.record_tool_call(
            tool_name=tool_name,
            success=success,
            duration_ms=duration_ms,
            error=error,
            conversation_id=self.conversation_id,
        )
