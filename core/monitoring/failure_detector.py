"""
å¤±è´¥æ£€æµ‹å™¨ï¼ˆFailure Detectorï¼‰

æ£€æµ‹å„ç±»å¤±è´¥æƒ…å†µï¼š
1. ä¸Šä¸‹æ–‡æº¢å‡ºï¼ˆè§¦å‘L3é¢„è­¦ä½†æœªå‹ç¼©ï¼‰
2. å·¥å…·è°ƒç”¨å¤±è´¥ï¼ˆè¿ç»­3æ¬¡å¤±è´¥ï¼‰
3. ç”¨æˆ·è´Ÿé¢åé¦ˆï¼ˆthumbs-downï¼‰
4. æ„å›¾è¯†åˆ«é”™è¯¯ï¼ˆè·¯ç”±åˆ°é”™è¯¯çš„æ™ºèƒ½ä½“ï¼‰
5. è¶…æ—¶å¼‚å¸¸
6. å“åº”è´¨é‡é—®é¢˜
"""

from collections import defaultdict
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from typing import Any, Callable, Dict, List, Optional

from logger import get_logger

logger = get_logger(__name__)


class FailureType(str, Enum):
    """å¤±è´¥ç±»å‹"""

    CONTEXT_OVERFLOW = "context_overflow"  # ä¸Šä¸‹æ–‡æº¢å‡º
    TOOL_CALL_FAILURE = "tool_call_failure"  # å·¥å…·è°ƒç”¨å¤±è´¥
    CONSECUTIVE_TOOL_ERRORS = "consecutive_tool_errors"  # è¿ç»­å·¥å…·é”™è¯¯
    USER_NEGATIVE_FEEDBACK = "user_negative_feedback"  # ç”¨æˆ·è´Ÿé¢åé¦ˆ
    INTENT_MISMATCH = "intent_mismatch"  # æ„å›¾è¯†åˆ«é”™è¯¯
    TIMEOUT = "timeout"  # è¶…æ—¶
    RESPONSE_QUALITY = "response_quality"  # å“åº”è´¨é‡é—®é¢˜
    SAFETY_VIOLATION = "safety_violation"  # å®‰å…¨è¿è§„
    UNKNOWN_ERROR = "unknown_error"  # æœªçŸ¥é”™è¯¯
    OVER_ENGINEERING = "over_engineering"  # è¿‡åº¦å·¥ç¨‹åŒ– [æ–°å¢]
    LOGICAL_INCOHERENCE = "logical_incoherence"  # é€»è¾‘ä¸è¿è´¯ [æ–°å¢]
    USER_RETRY = "user_retry"  # ç”¨æˆ·é‡è¯•ï¼ˆéšå¼ä¸æ»¡ï¼‰ [æ–°å¢]


class FailureSeverity(str, Enum):
    """å¤±è´¥ä¸¥é‡ç¨‹åº¦"""

    LOW = "low"  # è½»å¾®ï¼ˆå¯è‡ªåŠ¨æ¢å¤ï¼‰
    MEDIUM = "medium"  # ä¸­ç­‰ï¼ˆéœ€è¦å…³æ³¨ï¼‰
    HIGH = "high"  # ä¸¥é‡ï¼ˆéœ€è¦ç«‹å³å¤„ç†ï¼‰
    CRITICAL = "critical"  # è‡´å‘½ï¼ˆå¯èƒ½å½±å“æœåŠ¡ï¼‰


@dataclass
class FailureCase:
    """
    å¤±è´¥æ¡ˆä¾‹

    è®°å½•ä¸€æ¬¡å¤±è´¥çš„å®Œæ•´ä¿¡æ¯ï¼Œç”¨äºï¼š
    1. é—®é¢˜è¿½æº¯å’Œåˆ†æ
    2. è½¬åŒ–ä¸ºè¯„ä¼°ä»»åŠ¡
    3. æ”¹è¿›ç³»ç»Ÿ
    """

    id: str
    failure_type: FailureType
    severity: FailureSeverity
    conversation_id: str
    user_id: Optional[str]
    timestamp: datetime = field(default_factory=datetime.now)

    # è¾“å…¥ä¸Šä¸‹æ–‡
    user_query: str = ""
    conversation_history: List[Dict[str, Any]] = field(default_factory=list)

    # å¤±è´¥è¯¦æƒ…
    error_message: str = ""
    stack_trace: Optional[str] = None

    # æ‰§è¡Œè®°å½•
    tool_calls: List[Dict[str, Any]] = field(default_factory=list)
    agent_response: str = ""

    # Tokenä½¿ç”¨
    token_usage: Dict[str, int] = field(default_factory=dict)

    # é¢å¤–ä¸Šä¸‹æ–‡
    context: Dict[str, Any] = field(default_factory=dict)

    # å¤„ç†çŠ¶æ€
    status: str = "new"  # new, reviewed, converted, resolved
    reviewed_by: Optional[str] = None
    reviewed_at: Optional[datetime] = None

    def to_dict(self) -> Dict[str, Any]:
        return {
            "id": self.id,
            "failure_type": self.failure_type.value,
            "severity": self.severity.value,
            "conversation_id": self.conversation_id,
            "user_id": self.user_id,
            "timestamp": self.timestamp.isoformat(),
            "user_query": self.user_query,
            "conversation_history": self.conversation_history,
            "error_message": self.error_message,
            "stack_trace": self.stack_trace,
            "tool_calls": self.tool_calls,
            "agent_response": self.agent_response,
            "token_usage": self.token_usage,
            "context": self.context,
            "status": self.status,
            "reviewed_by": self.reviewed_by,
            "reviewed_at": self.reviewed_at.isoformat() if self.reviewed_at else None,
        }


class FailureDetector:
    """
    å¤±è´¥æ£€æµ‹å™¨

    ä½¿ç”¨æ–¹å¼ï¼š
        detector = FailureDetector()

        # æ³¨å†Œå¤±è´¥å¤„ç†å™¨
        detector.on_failure(lambda case: print(f"æ£€æµ‹åˆ°å¤±è´¥: {case.id}"))

        # æ£€æµ‹å¤±è´¥
        detector.detect_context_overflow(
            conversation_id="conv_123",
            current_tokens=210000,
            max_tokens=200000,
            user_query="..."
        )

        # è·å–å¤±è´¥æ¡ˆä¾‹
        cases = detector.get_cases(failure_type=FailureType.CONTEXT_OVERFLOW)
    """

    def __init__(
        self,
        consecutive_error_threshold: int = 3,
        failure_handlers: Optional[List[Callable[[FailureCase], None]]] = None,
    ):
        """
        åˆå§‹åŒ–å¤±è´¥æ£€æµ‹å™¨

        Args:
            consecutive_error_threshold: è¿ç»­é”™è¯¯é˜ˆå€¼
            failure_handlers: å¤±è´¥å¤„ç†å™¨åˆ—è¡¨
        """
        self.consecutive_error_threshold = consecutive_error_threshold
        self.failure_handlers = failure_handlers or []

        # å¤±è´¥æ¡ˆä¾‹å­˜å‚¨
        self.cases: List[FailureCase] = []

        # è¿ç»­é”™è¯¯è®¡æ•°ï¼ˆæŒ‰conversation_idï¼‰
        self._consecutive_errors: Dict[str, List[datetime]] = defaultdict(list)

        # ç»Ÿè®¡è®¡æ•°
        self._stats = defaultdict(int)

    # ===================
    # å¤±è´¥æ£€æµ‹æ–¹æ³•
    # ===================

    def detect_context_overflow(
        self,
        conversation_id: str,
        current_tokens: int,
        max_tokens: int,
        user_query: str,
        conversation_history: Optional[List[Dict]] = None,
        user_id: Optional[str] = None,
    ) -> FailureCase:
        """
        æ£€æµ‹ä¸Šä¸‹æ–‡æº¢å‡º

        Args:
            conversation_id: ä¼šè¯ID
            current_tokens: å½“å‰Tokenæ•°
            max_tokens: æœ€å¤§Tokenæ•°
            user_query: ç”¨æˆ·æŸ¥è¯¢
            conversation_history: å¯¹è¯å†å²
            user_id: ç”¨æˆ·ID

        Returns:
            FailureCase: å¤±è´¥æ¡ˆä¾‹
        """
        case = FailureCase(
            id=self._generate_id("ctx_overflow"),
            failure_type=FailureType.CONTEXT_OVERFLOW,
            severity=FailureSeverity.HIGH,
            conversation_id=conversation_id,
            user_id=user_id,
            user_query=user_query,
            conversation_history=conversation_history or [],
            error_message=f"ä¸Šä¸‹æ–‡æº¢å‡º: {current_tokens}/{max_tokens} tokens",
            token_usage={
                "current": current_tokens,
                "max": max_tokens,
                "overflow_ratio": current_tokens / max_tokens if max_tokens > 0 else 0,
            },
        )

        self._record_case(case)
        return case

    def detect_tool_failure(
        self,
        conversation_id: str,
        tool_name: str,
        error: str,
        user_query: str,
        tool_arguments: Optional[Dict] = None,
        user_id: Optional[str] = None,
    ) -> Optional[FailureCase]:
        """
        æ£€æµ‹å·¥å…·è°ƒç”¨å¤±è´¥

        Args:
            conversation_id: ä¼šè¯ID
            tool_name: å·¥å…·åç§°
            error: é”™è¯¯ä¿¡æ¯
            user_query: ç”¨æˆ·æŸ¥è¯¢
            tool_arguments: å·¥å…·å‚æ•°
            user_id: ç”¨æˆ·ID

        Returns:
            FailureCase: å¤±è´¥æ¡ˆä¾‹ï¼ˆå¦‚æœæ£€æµ‹åˆ°è¿ç»­é”™è¯¯ï¼‰
        """
        # è®°å½•é”™è¯¯
        now = datetime.now()
        self._consecutive_errors[conversation_id].append(now)

        # æ¸…ç†è¿‡æœŸè®°å½•ï¼ˆ5åˆ†é’Ÿå‰çš„ï¼‰
        cutoff = now - timedelta(minutes=5)
        self._consecutive_errors[conversation_id] = [
            t for t in self._consecutive_errors[conversation_id] if t > cutoff
        ]

        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°è¿ç»­é”™è¯¯é˜ˆå€¼
        if len(self._consecutive_errors[conversation_id]) >= self.consecutive_error_threshold:
            case = FailureCase(
                id=self._generate_id("tool_error"),
                failure_type=FailureType.CONSECUTIVE_TOOL_ERRORS,
                severity=FailureSeverity.MEDIUM,
                conversation_id=conversation_id,
                user_id=user_id,
                user_query=user_query,
                error_message=f"è¿ç»­{self.consecutive_error_threshold}æ¬¡å·¥å…·è°ƒç”¨å¤±è´¥: {tool_name}",
                tool_calls=[
                    {
                        "name": tool_name,
                        "arguments": tool_arguments or {},
                        "error": error,
                    }
                ],
                context={
                    "consecutive_errors": len(self._consecutive_errors[conversation_id]),
                },
            )

            self._record_case(case)

            # é‡ç½®è®¡æ•°
            self._consecutive_errors[conversation_id] = []

            return case

        return None

    def detect_user_negative_feedback(
        self,
        conversation_id: str,
        user_query: str,
        agent_response: str,
        feedback_comment: Optional[str] = None,
        user_id: Optional[str] = None,
    ) -> FailureCase:
        """
        æ£€æµ‹ç”¨æˆ·è´Ÿé¢åé¦ˆ

        Args:
            conversation_id: ä¼šè¯ID
            user_query: ç”¨æˆ·æŸ¥è¯¢
            agent_response: æ™ºèƒ½ä½“å›å¤
            feedback_comment: ç”¨æˆ·è¯„è®º
            user_id: ç”¨æˆ·ID

        Returns:
            FailureCase: å¤±è´¥æ¡ˆä¾‹
        """
        case = FailureCase(
            id=self._generate_id("negative_feedback"),
            failure_type=FailureType.USER_NEGATIVE_FEEDBACK,
            severity=FailureSeverity.MEDIUM,
            conversation_id=conversation_id,
            user_id=user_id,
            user_query=user_query,
            agent_response=agent_response,
            error_message=f"ç”¨æˆ·è´Ÿé¢åé¦ˆ: {feedback_comment or 'æ— è¯„è®º'}",
            context={
                "feedback_comment": feedback_comment,
            },
        )

        self._record_case(case)
        return case

    def detect_intent_mismatch(
        self,
        conversation_id: str,
        user_query: str,
        detected_intent: str,
        expected_intent: str,
        conversation_history: Optional[List[Dict]] = None,
        user_id: Optional[str] = None,
    ) -> FailureCase:
        """
        æ£€æµ‹æ„å›¾è¯†åˆ«é”™è¯¯

        Args:
            conversation_id: ä¼šè¯ID
            user_query: ç”¨æˆ·æŸ¥è¯¢
            detected_intent: æ£€æµ‹åˆ°çš„æ„å›¾
            expected_intent: é¢„æœŸæ„å›¾
            conversation_history: å¯¹è¯å†å²
            user_id: ç”¨æˆ·ID

        Returns:
            FailureCase: å¤±è´¥æ¡ˆä¾‹
        """
        case = FailureCase(
            id=self._generate_id("intent_mismatch"),
            failure_type=FailureType.INTENT_MISMATCH,
            severity=FailureSeverity.MEDIUM,
            conversation_id=conversation_id,
            user_id=user_id,
            user_query=user_query,
            conversation_history=conversation_history or [],
            error_message=f"æ„å›¾è¯†åˆ«é”™è¯¯: é¢„æœŸ'{expected_intent}', æ£€æµ‹åˆ°'{detected_intent}'",
            context={
                "detected_intent": detected_intent,
                "expected_intent": expected_intent,
            },
        )

        self._record_case(case)
        return case

    def detect_timeout(
        self,
        conversation_id: str,
        user_query: str,
        timeout_seconds: float,
        partial_response: Optional[str] = None,
        user_id: Optional[str] = None,
    ) -> FailureCase:
        """
        æ£€æµ‹è¶…æ—¶

        Args:
            conversation_id: ä¼šè¯ID
            user_query: ç”¨æˆ·æŸ¥è¯¢
            timeout_seconds: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            partial_response: éƒ¨åˆ†å“åº”
            user_id: ç”¨æˆ·ID

        Returns:
            FailureCase: å¤±è´¥æ¡ˆä¾‹
        """
        case = FailureCase(
            id=self._generate_id("timeout"),
            failure_type=FailureType.TIMEOUT,
            severity=FailureSeverity.HIGH,
            conversation_id=conversation_id,
            user_id=user_id,
            user_query=user_query,
            agent_response=partial_response or "",
            error_message=f"æ‰§è¡Œè¶…æ—¶: {timeout_seconds}ç§’",
            context={
                "timeout_seconds": timeout_seconds,
                "has_partial_response": bool(partial_response),
            },
        )

        self._record_case(case)
        return case

    def detect_generic_error(
        self,
        conversation_id: str,
        user_query: str,
        error: Exception,
        stack_trace: Optional[str] = None,
        user_id: Optional[str] = None,
    ) -> FailureCase:
        """
        æ£€æµ‹é€šç”¨é”™è¯¯

        Args:
            conversation_id: ä¼šè¯ID
            user_query: ç”¨æˆ·æŸ¥è¯¢
            error: å¼‚å¸¸å¯¹è±¡
            stack_trace: å †æ ˆè·Ÿè¸ª
            user_id: ç”¨æˆ·ID

        Returns:
            FailureCase: å¤±è´¥æ¡ˆä¾‹
        """
        case = FailureCase(
            id=self._generate_id("error"),
            failure_type=FailureType.UNKNOWN_ERROR,
            severity=FailureSeverity.HIGH,
            conversation_id=conversation_id,
            user_id=user_id,
            user_query=user_query,
            error_message=str(error),
            stack_trace=stack_trace,
            context={
                "error_type": type(error).__name__,
            },
        )

        self._record_case(case)
        return case

    async def detect_response_quality(
        self,
        conversation_id: str,
        user_query: str,
        agent_response: str,
        transcript: Dict[str, Any],
        llm_judge: Any,
        user_id: Optional[str] = None,
    ) -> Optional[FailureCase]:
        """
        ä½¿ç”¨ LLM Judge æ£€æµ‹å“åº”è´¨é‡é—®é¢˜

        æ£€æµ‹ç»´åº¦ï¼š
        1. å›ç­”è´¨é‡ï¼ˆå‡†ç¡®æ€§ã€å®Œæ•´æ€§ã€æµç•…æ€§ï¼‰
        2. è¿‡åº¦å·¥ç¨‹åŒ–ï¼ˆå·¥å…·è°ƒç”¨è¿‡å¤šã€Plan è¿‡äºå¤æ‚ï¼‰
        3. é€»è¾‘è¿è´¯æ€§ï¼ˆæ¨ç†è¿‡ç¨‹æ˜¯å¦åˆç†ï¼‰

        Args:
            conversation_id: ä¼šè¯ID
            user_query: ç”¨æˆ·æŸ¥è¯¢
            agent_response: æ™ºèƒ½ä½“å›å¤
            transcript: è½¬å½•è®°å½•ï¼ˆåŒ…å«å·¥å…·è°ƒç”¨ã€æ¶ˆæ¯å†å²ç­‰ï¼‰
            llm_judge: ModelBasedGraders å®ä¾‹
            user_id: ç”¨æˆ·ID

        Returns:
            FailureCase: å¤±è´¥æ¡ˆä¾‹ï¼ˆå¦‚æœæ£€æµ‹åˆ°è´¨é‡é—®é¢˜ï¼‰
        """
        try:
            # æ„å»º Transcript å¯¹è±¡ï¼ˆå¦‚æœä¼ å…¥çš„æ˜¯å­—å…¸ï¼‰
            from evaluation.models import Message, ToolCall, Transcript
            from models.usage import TokenUsage

            if isinstance(transcript, dict):
                # ä»å­—å…¸æ„å»º Transcript
                messages = [
                    Message(**msg) if isinstance(msg, dict) else msg
                    for msg in transcript.get("messages", [])
                ]
                tool_calls = [
                    ToolCall(**tc) if isinstance(tc, dict) else tc
                    for tc in transcript.get("tool_calls", [])
                ]
                token_usage = TokenUsage(**transcript.get("token_usage", {}))

                transcript_obj = Transcript(
                    messages=messages,
                    tool_calls=tool_calls,
                    token_usage=token_usage,
                    duration_ms=transcript.get("duration_ms", 0),
                    metadata=transcript.get("metadata", {}),
                )
            else:
                transcript_obj = transcript

            # è°ƒç”¨ ModelBasedGraders è¯„ä¼°
            quality_result = await llm_judge.grade_response_quality(
                user_query=user_query,
                agent_response=agent_response,
            )

            over_eng_result = await llm_judge.grade_over_engineering(
                user_query=user_query,
                transcript=transcript_obj,
            )

            # åˆ¤æ–­æ˜¯å¦å¤±è´¥
            quality_failed = quality_result.score is not None and quality_result.score < 0.6
            over_eng_failed = over_eng_result.score is not None and over_eng_result.score < 0.6

            if quality_failed or over_eng_failed:
                failure_type = (
                    FailureType.OVER_ENGINEERING
                    if over_eng_failed
                    else FailureType.RESPONSE_QUALITY
                )

                case = FailureCase(
                    id=self._generate_id("quality"),
                    failure_type=failure_type,
                    severity=FailureSeverity.MEDIUM,
                    conversation_id=conversation_id,
                    user_id=user_id,
                    user_query=user_query,
                    agent_response=agent_response,
                    error_message=f"å“åº”è´¨é‡é—®é¢˜: è´¨é‡è¯„åˆ†={quality_result.score:.2f}, è¿‡åº¦å·¥ç¨‹åŒ–è¯„åˆ†={over_eng_result.score:.2f}",
                    tool_calls=[
                        {
                            "name": tc.name,
                            "arguments": tc.arguments if hasattr(tc, "arguments") else {},
                        }
                        for tc in transcript_obj.tool_calls
                    ],
                    context={
                        "quality_score": quality_result.score,
                        "over_engineering_score": over_eng_result.score,
                        "quality_explanation": quality_result.explanation,
                        "over_engineering_explanation": over_eng_result.explanation,
                    },
                )

                self._record_case(case)
                return case

        except Exception as e:
            logger.error(f"æ£€æµ‹å“åº”è´¨é‡å¤±è´¥: {e}", exc_info=True)

        return None

    def detect_user_retry(
        self,
        conversation_id: str,
        current_query: str,
        previous_queries: List[str],
        similarity_threshold: float = 0.85,
        user_id: Optional[str] = None,
    ) -> Optional[FailureCase]:
        """
        æ£€æµ‹ç”¨æˆ·é‡è¯•ï¼ˆéšå¼ä¸æ»¡ï¼‰

        å½“ç”¨æˆ·é‡æ–°æé—®ç›¸ä¼¼é—®é¢˜æ—¶ï¼Œè¯´æ˜ä¹‹å‰çš„å›ç­”å¯èƒ½ä¸æ»¡æ„

        Args:
            conversation_id: ä¼šè¯ID
            current_query: å½“å‰æŸ¥è¯¢
            previous_queries: ä¹‹å‰çš„æŸ¥è¯¢åˆ—è¡¨ï¼ˆæœ€è¿‘Næ¡ï¼‰
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆé»˜è®¤0.85ï¼‰
            user_id: ç”¨æˆ·ID

        Returns:
            FailureCase: å¤±è´¥æ¡ˆä¾‹ï¼ˆå¦‚æœæ£€æµ‹åˆ°é‡è¯•ï¼‰
        """
        # è®¡ç®—ä¸ä¹‹å‰é—®é¢˜çš„ç›¸ä¼¼åº¦
        for prev_query in previous_queries[-3:]:  # æ£€æŸ¥æœ€è¿‘ 3 æ¡
            similarity = self._compute_similarity(current_query, prev_query)
            if similarity > similarity_threshold:
                case = FailureCase(
                    id=self._generate_id("retry"),
                    failure_type=FailureType.USER_RETRY,
                    severity=FailureSeverity.LOW,
                    conversation_id=conversation_id,
                    user_id=user_id,
                    user_query=current_query,
                    error_message=f"ç”¨æˆ·é‡è¯•ç›¸ä¼¼é—®é¢˜: ç›¸ä¼¼åº¦={similarity:.2f}, ä¹‹å‰é—®é¢˜='{prev_query[:50]}...'",
                    context={
                        "previous_query": prev_query,
                        "similarity": similarity,
                        "similarity_threshold": similarity_threshold,
                    },
                )

                self._record_case(case)
                return case

        return None

    def _compute_similarity(self, text1: str, text2: str) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªæ–‡æœ¬çš„ç›¸ä¼¼åº¦ï¼ˆç®€åŒ–ç‰ˆï¼Œä½¿ç”¨ Jaccard ç›¸ä¼¼åº¦ï¼‰

        Args:
            text1: æ–‡æœ¬1
            text2: æ–‡æœ¬2

        Returns:
            float: ç›¸ä¼¼åº¦ï¼ˆ0-1ï¼‰
        """
        # ç®€å•çš„åŸºäºè¯æ±‡çš„ç›¸ä¼¼åº¦
        words1 = set(text1.lower().split())
        words2 = set(text2.lower().split())

        if not words1 or not words2:
            return 0.0

        intersection = len(words1 & words2)
        union = len(words1 | words2)

        return intersection / union if union > 0 else 0.0

    # ===================
    # æ¡ˆä¾‹ç®¡ç†
    # ===================

    def _generate_id(self, prefix: str) -> str:
        """ç”Ÿæˆå”¯ä¸€ID"""
        import uuid

        return f"{prefix}_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4()}"

    def _record_case(self, case: FailureCase) -> None:
        """
        è®°å½•å¤±è´¥æ¡ˆä¾‹

        Args:
            case: å¤±è´¥æ¡ˆä¾‹
        """
        self.cases.append(case)
        self._stats[case.failure_type.value] += 1

        logger.warning(
            f"ğŸ”´ æ£€æµ‹åˆ°å¤±è´¥: [{case.failure_type.value}] {case.error_message} "
            f"(conversation: {case.conversation_id})"
        )

        # è°ƒç”¨å¤„ç†å™¨
        for handler in self.failure_handlers:
            try:
                handler(case)
            except Exception as e:
                logger.error(f"å¤±è´¥å¤„ç†å™¨æ‰§è¡Œå¼‚å¸¸: {e}")

    def on_failure(self, handler: Callable[[FailureCase], None]) -> None:
        """
        æ³¨å†Œå¤±è´¥å¤„ç†å™¨

        Args:
            handler: å¤„ç†å‡½æ•°
        """
        self.failure_handlers.append(handler)

    def get_cases(
        self,
        failure_type: Optional[FailureType] = None,
        severity: Optional[FailureSeverity] = None,
        status: Optional[str] = None,
        time_range_hours: Optional[int] = None,
        limit: int = 100,
    ) -> List[FailureCase]:
        """
        è·å–å¤±è´¥æ¡ˆä¾‹

        Args:
            failure_type: å¤±è´¥ç±»å‹ç­›é€‰
            severity: ä¸¥é‡ç¨‹åº¦ç­›é€‰
            status: çŠ¶æ€ç­›é€‰
            time_range_hours: æ—¶é—´èŒƒå›´ï¼ˆå°æ—¶ï¼‰
            limit: è¿”å›æ•°é‡é™åˆ¶

        Returns:
            List[FailureCase]: å¤±è´¥æ¡ˆä¾‹åˆ—è¡¨
        """
        cases = self.cases.copy()

        if failure_type:
            cases = [c for c in cases if c.failure_type == failure_type]

        if severity:
            cases = [c for c in cases if c.severity == severity]

        if status:
            cases = [c for c in cases if c.status == status]

        if time_range_hours:
            cutoff = datetime.now() - timedelta(hours=time_range_hours)
            cases = [c for c in cases if c.timestamp >= cutoff]

        # æŒ‰æ—¶é—´å€’åº
        cases.sort(key=lambda c: c.timestamp, reverse=True)

        return cases[:limit]

    def mark_reviewed(self, case_id: str, reviewer: str) -> Optional[FailureCase]:
        """
        æ ‡è®°æ¡ˆä¾‹ä¸ºå·²å®¡æŸ¥

        Args:
            case_id: æ¡ˆä¾‹ID
            reviewer: å®¡æŸ¥äºº

        Returns:
            FailureCase: æ›´æ–°åçš„æ¡ˆä¾‹
        """
        for case in self.cases:
            if case.id == case_id:
                case.status = "reviewed"
                case.reviewed_by = reviewer
                case.reviewed_at = datetime.now()
                return case
        return None

    def get_statistics(self) -> Dict[str, Any]:
        """
        è·å–ç»Ÿè®¡ä¿¡æ¯

        Returns:
            Dict: ç»Ÿè®¡ä¿¡æ¯
        """
        # æŒ‰ç±»å‹ç»Ÿè®¡
        by_type = defaultdict(int)
        by_severity = defaultdict(int)
        by_status = defaultdict(int)

        for case in self.cases:
            by_type[case.failure_type.value] += 1
            by_severity[case.severity.value] += 1
            by_status[case.status] += 1

        # æœ€è¿‘24å°æ—¶
        cutoff = datetime.now() - timedelta(hours=24)
        recent_cases = [c for c in self.cases if c.timestamp >= cutoff]

        return {
            "total_cases": len(self.cases),
            "recent_24h": len(recent_cases),
            "by_type": dict(by_type),
            "by_severity": dict(by_severity),
            "by_status": dict(by_status),
            "pending_review": by_status.get("new", 0),
        }
