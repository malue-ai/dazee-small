"""
PlaybookManager - ç­–ç•¥åº“ç®¡ç†å™¨

V8.0 æ–°å¢
V10.0 é‡æ„ï¼šç»Ÿä¸€èµ° Storage Backendï¼Œåˆ é™¤åŒé‡æ–‡ä»¶æ“ä½œï¼Œä¿®å¤å®ä¾‹éš”ç¦»
V10.1 é‡æ„ï¼šç‹¬ç«‹å‘é‡åº“ï¼ŒPlaybook å‘é‡ä¸ç”¨æˆ·è®°å¿†ç‰©ç†éš”ç¦»

èŒè´£ï¼š
- ä»æˆåŠŸä¼šè¯ä¸­æå–ç­–ç•¥æ¨¡å¼
- ç®¡ç†ç­–ç•¥çš„ç”Ÿå‘½å‘¨æœŸï¼ˆè‰ç¨¿/å¾…å®¡æ ¸/å·²å‘å¸ƒ/å·²åºŸå¼ƒï¼‰
- ç­–ç•¥æ£€ç´¢å’ŒåŒ¹é…ï¼ˆä¸¤å±‚ï¼štask_type é¢„ç­› + ç‹¬ç«‹å‘é‡åº“è¯­ä¹‰æœç´¢ï¼‰

å‘é‡å­˜å‚¨æ¶æ„ï¼š
- Playbook ä½¿ç”¨ç‹¬ç«‹çš„ playbook_vectors.dbï¼ˆSqliteVecVectorStoreï¼‰
- ä¸ç”¨æˆ·è®°å¿† mem0_vectors.db ç‰©ç†éš”ç¦»ï¼ŒKNN æœç´¢ä¸å—ç”¨æˆ·è®°å¿†æ•°é‡å½±å“
- Embedding å¤ç”¨å…¨å±€ GGUF å•ä¾‹ï¼ˆGGUFEmbeddingProviderï¼‰ï¼Œé›¶é¢å¤–å†…å­˜
"""

import hashlib
import json
import os
import uuid
from dataclasses import asdict, dataclass, field
from datetime import datetime
from enum import Enum
from typing import Any, Dict, List, Optional

from logger import get_logger
from utils.app_paths import get_instance_playbooks_dir, get_instance_playbook_vectors_path

logger = get_logger(__name__)

# Playbook unused for longer than this is considered stale and skipped during matching.
# Lazy evaluation: checked at match time, no background scan needed.
STALE_DAYS = 30


class PlaybookStatus(Enum):
    """ç­–ç•¥çŠ¶æ€"""

    DRAFT = "draft"  # è‰ç¨¿ï¼ˆè‡ªåŠ¨ç”Ÿæˆï¼‰
    PENDING_REVIEW = "pending"  # å¾…å®¡æ ¸
    APPROVED = "approved"  # å·²å‘å¸ƒ
    REJECTED = "rejected"  # å·²æ‹’ç»
    DEPRECATED = "deprecated"  # å·²åºŸå¼ƒ


@dataclass
class PlaybookEntry:
    """
    ç­–ç•¥æ¡ç›®

    æè¿°ä¸€ä¸ªæˆåŠŸçš„æ‰§è¡Œæ¨¡å¼ï¼ŒåŒ…æ‹¬ï¼š
    - è§¦å‘æ¡ä»¶ï¼ˆä»€ä¹ˆåœºæ™¯ä¸‹ä½¿ç”¨ï¼‰
    - æ‰§è¡Œç­–ç•¥ï¼ˆæ€ä¹ˆæ‰§è¡Œï¼‰
    - å·¥å…·åºåˆ—ï¼ˆä½¿ç”¨å“ªäº›å·¥å…·ï¼‰
    - è´¨é‡æŒ‡æ ‡ï¼ˆé¢„æœŸæ•ˆæœï¼‰
    """

    id: str  # å”¯ä¸€ ID
    name: str  # ç­–ç•¥åç§°
    description: str  # ç­–ç•¥æè¿°

    # è§¦å‘æ¡ä»¶
    trigger: Dict[str, Any] = field(default_factory=dict)
    # {
    #   "task_types": ["data_analysis"],
    #   "complexity_range": [4, 7],
    # }

    # æ‰§è¡Œç­–ç•¥
    strategy: Dict[str, Any] = field(default_factory=dict)
    # {
    #   "execution_strategy": "rvr-b",
    #   "suggested_tools": ["data_analysis_skill", "chart_generation"],
    #   "max_turns": 15,
    #   "planning_depth": "full"
    # }

    # å·¥å…·åºåˆ—æ¨¡æ¿
    tool_sequence: List[Dict[str, Any]] = field(default_factory=list)
    # [
    #   {"tool": "data_analysis_skill", "purpose": "æ•°æ®æŸ¥è¯¢"},
    #   {"tool": "chart_generation", "purpose": "ç”Ÿæˆå›¾è¡¨"}
    # ]

    # è´¨é‡æŒ‡æ ‡
    quality_metrics: Dict[str, float] = field(default_factory=dict)
    # {
    #   "avg_reward": 0.85,
    #   "success_rate": 0.92,
    #   "avg_turns": 8.5
    # }

    # å…ƒæ•°æ®
    status: PlaybookStatus = PlaybookStatus.DRAFT
    source: str = "auto"  # auto / manual / import
    source_session_id: Optional[str] = None  # æ¥æºä¼šè¯ ID
    created_at: str = field(default_factory=lambda: datetime.now().isoformat())
    updated_at: str = field(default_factory=lambda: datetime.now().isoformat())
    reviewed_by: Optional[str] = None  # å®¡æ ¸äºº
    review_notes: Optional[str] = None  # å®¡æ ¸å¤‡æ³¨
    usage_count: int = 0  # ä½¿ç”¨æ¬¡æ•°
    last_used_at: Optional[str] = None  # æœ€åä¸€æ¬¡è¢«åŒ¹é…æ³¨å…¥çš„æ—¶é—´ï¼ˆISO 8601ï¼‰

    def is_stale(self, stale_days: int = STALE_DAYS) -> bool:
        """
        Check if this entry has been unused for too long.

        Uses last_used_at if available, otherwise falls back to updated_at.
        Newly approved entries (never used) get a grace period from updated_at.
        """
        ref = self.last_used_at or self.updated_at or self.created_at
        try:
            ref_dt = datetime.fromisoformat(ref)
            return (datetime.now() - ref_dt).days > stale_days
        except (ValueError, TypeError):
            return False

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        data = asdict(self)
        data["status"] = self.status.value
        return data

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "PlaybookEntry":
        """ä»å­—å…¸åˆ›å»ºï¼ˆè¿‡æ»¤æœªçŸ¥å­—æ®µï¼Œé¿å… TypeErrorï¼‰"""
        data = data.copy()
        if isinstance(data.get("status"), str):
            data["status"] = PlaybookStatus(data["status"])
        known_fields = set(cls.__dataclass_fields__.keys())
        filtered = {k: v for k, v in data.items() if k in known_fields}
        return cls(**filtered)

    def matches_task_type(self, task_type: str) -> bool:
        """
        Layer 1 é¢„ç­›ï¼štask_type ç¡®å®šæ€§åŒ¹é…ï¼ˆ<1msï¼‰

        ä»…ç”¨äºå¿«é€Ÿè¿‡æ»¤å€™é€‰é›†ï¼Œä¸åšè¯­ä¹‰åˆ¤æ–­ã€‚
        å±äº"ç®€å•ç¡®å®šæ€§ä»»åŠ¡"ï¼ˆè§„åˆ™å…è®¸çš„åœºæ™¯ï¼‰ã€‚

        Args:
            task_type: æ„å›¾è¯†åˆ«è¾“å‡ºçš„ä»»åŠ¡ç±»å‹

        Returns:
            æ˜¯å¦å±äºåŒç±»å‹ä»»åŠ¡
        """
        # è°ƒç”¨æ–¹æœªæä¾› task_type æ—¶ä¸åšé¢„ç­›ï¼ˆäº¤ç»™ Layer 2 è¯­ä¹‰åˆ¤æ–­ï¼‰
        if not task_type:
            return True
        if "task_types" in self.trigger:
            return task_type in self.trigger["task_types"]
        # æ—  task_types é™åˆ¶çš„ç­–ç•¥å¯¹æ‰€æœ‰ç±»å‹é€‚ç”¨
        return True

    def get_searchable_text(self) -> str:
        """
        ç”Ÿæˆç”¨äºè¯­ä¹‰æœç´¢çš„æ–‡æœ¬æè¿°ã€‚

        æè¿°è´¨é‡ç›´æ¥å†³å®šåŒ¹é…ç²¾åº¦ï¼ˆPrecision-Firstï¼‰ã€‚
        åˆå¹¶åç§°ã€æè¿°ã€å·¥å…·åºåˆ—ã€è§¦å‘æ¡ä»¶ä¸ºä¸€æ®µæ–‡æœ¬ï¼Œ
        ä¾› Mem0 å‘é‡/FTS5 æœç´¢ä½¿ç”¨ã€‚

        Returns:
            å¯æœç´¢çš„æ–‡æœ¬ï¼ˆä¸å«"[ç­–ç•¥]"ç­‰å‰ç¼€ï¼Œé¿å…æœç´¢å™ªéŸ³ï¼‰
        """
        parts = [self.name, self.description]

        # å·¥å…·åºåˆ—ï¼šå…¼å®¹ purpose / description / tool ä¸‰ç§ key
        if self.tool_sequence:
            tools = [
                step.get("purpose", step.get("description", step.get("tool", "")))
                for step in self.tool_sequence
            ]
            tools = [t for t in tools if t]
            if tools:
                parts.append("æ­¥éª¤: " + " -> ".join(tools))

        # è§¦å‘æ¡ä»¶ä¸­çš„ task_types æœ‰åŠ©äº FTS5 å…³é”®è¯å‘½ä¸­
        task_types = self.trigger.get("task_types", [])
        if task_types:
            parts.append("ä»»åŠ¡ç±»å‹: " + ", ".join(task_types))

        return " | ".join(filter(None, parts))


class PlaybookManager:
    """
    ç­–ç•¥åº“ç®¡ç†å™¨

    æ‰€æœ‰ IO æ“ä½œç»Ÿä¸€èµ° Storage Backendï¼Œä¸ç›´æ¥æ“ä½œæ–‡ä»¶ã€‚

    ä½¿ç”¨æ–¹å¼ï¼š
        manager = create_playbook_manager()
        await manager.load_all_async()

        # ä»é«˜åˆ†ä¼šè¯æå–ç­–ç•¥
        entry = await manager.extract_from_session(session_reward)

        # å®¡æ ¸ç­–ç•¥
        await manager.approve(entry.id, reviewer="admin", notes="verified")

        # æ£€ç´¢åŒ¹é…ç­–ç•¥
        matches = await manager.find_matching_async(query, task_type)
    """

    def __init__(
        self,
        storage_path: str = None,
        auto_save: bool = True,
        min_reward_threshold: float = 0.7,
        llm_service=None,
    ):
        """
        åˆå§‹åŒ–ç­–ç•¥åº“ç®¡ç†å™¨

        Args:
            storage_path: å­˜å‚¨è·¯å¾„ï¼Œé»˜è®¤ä½¿ç”¨å®ä¾‹éš”ç¦»è·¯å¾„
            auto_save: æ˜¯å¦è‡ªåŠ¨ä¿å­˜
            min_reward_threshold: æœ€ä½å¥–åŠ±é˜ˆå€¼ï¼ˆç”¨äºè‡ªåŠ¨æå–ï¼‰
            llm_service: LLM æœåŠ¡ï¼ˆç”¨äºç­–ç•¥æå–ï¼Œå¯é€‰ï¼Œæœªä¼ æ—¶æ‡’åŠ è½½ï¼‰
        """
        if storage_path is None:
            instance_name = os.getenv("AGENT_INSTANCE", "default")
            storage_path = str(get_instance_playbooks_dir(instance_name))

        self._storage_path = storage_path
        self._instance_name = os.getenv("AGENT_INSTANCE", "default")
        self.auto_save = auto_save
        self.min_reward_threshold = min_reward_threshold
        self._llm_service = llm_service

        # å»¶è¿Ÿåˆå§‹åŒ–çš„å­˜å‚¨åç«¯ï¼ˆJSON æ–‡ä»¶ï¼‰
        self._storage = None

        # å»¶è¿Ÿåˆå§‹åŒ–çš„å‘é‡å­˜å‚¨ï¼ˆç‹¬ç«‹ playbook_vectors.dbï¼‰
        self._vector_store = None
        self._embedding_model = None

        # å†…å­˜ç¼“å­˜
        self._entries: Dict[str, PlaybookEntry] = {}
        self._loaded = False

        logger.info(f"âœ… PlaybookManager åˆå§‹åŒ–: storage={storage_path}")

    async def _get_llm_service(self):
        """
        Async getter for LLM service (lazy-loaded from config).

        ä½¿ç”¨ background_task profileï¼ˆlight tierï¼‰ï¼Œä½†è¦†ç›– max_tokens
        ä»¥æ»¡è¶³ playbook æè¿°ç”Ÿæˆï¼ˆ~200-300 tokens JSON è¾“å‡ºï¼‰ã€‚

        Follows the same pattern as MemoryExtractor.get_llm_service(),
        QualityController.get_llm_service(), etc.
        """
        if self._llm_service is None:
            try:
                from config.llm_config import get_llm_profile
                from core.llm import create_llm_service

                profile = await get_llm_profile(
                    "background_task", max_tokens=512
                )
                self._llm_service = create_llm_service(**profile)
            except Exception as e:
                logger.debug(f"LLM æœåŠ¡æ‡’åŠ è½½å¤±è´¥ï¼ˆapprove æ—¶ä¸ç”Ÿæˆæè¿°ï¼‰: {e}")
                return None
        return self._llm_service

    def _get_storage(self):
        """è·å–å­˜å‚¨åç«¯ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰"""
        if self._storage is None:
            from core.playbook.storage import create_storage_backend

            self._storage = create_storage_backend(storage_path=self._storage_path)
        return self._storage

    def _get_vector_store(self):
        """
        è·å– Playbook ä¸“ç”¨çš„å‘é‡å­˜å‚¨ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰ã€‚

        ä½¿ç”¨ç‹¬ç«‹çš„ playbook_vectors.dbï¼Œä¸ç”¨æˆ·è®°å¿† mem0_vectors.db ç‰©ç†éš”ç¦»ã€‚
        sqlite-vec KNN æŸ¥è¯¢ä¸æ”¯æŒ WHERE é¢„è¿‡æ»¤ï¼Œå…±äº«è¡¨ä¼šå¯¼è‡´ playbook
        å‘é‡è¢«å¤§é‡ç”¨æˆ·è®°å¿†æŒ¤å‡ºç»“æœé›†ã€‚ç‹¬ç«‹è¡¨ç¡®ä¿ KNN 100% å‘½ä¸­ playbookã€‚
        """
        if self._vector_store is None:
            from core.memory.mem0.sqlite_vec_store import SqliteVecVectorStore

            embedding = self._get_embedding_model()
            dims = embedding.config.embedding_dims if hasattr(embedding, "config") else 1024

            db_path = str(get_instance_playbook_vectors_path(self._instance_name))
            self._vector_store = SqliteVecVectorStore(
                collection_name="playbook_vectors",
                embedding_model_dims=dims,
                db_path=db_path,
            )
            logger.info(f"âœ… Playbook ç‹¬ç«‹å‘é‡åº“åˆå§‹åŒ–: {db_path} (dims={dims})")
        return self._vector_store

    def _get_embedding_model(self):
        """
        è·å– Embedding æ¨¡å‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼Œå¤ç”¨å…¨å±€ GGUF å•ä¾‹ï¼‰ã€‚

        ä¸ Mem0 Pool å…±äº«åŒä¸€ä¸ª GGUFEmbeddingProvider å®ä¾‹ï¼ˆé€šè¿‡å•ä¾‹æ¨¡å¼ï¼‰ï¼Œ
        é›¶é¢å¤–å†…å­˜å¼€é”€ã€‚é€šè¿‡ _GGUFEmbedderAdapter åŒ…è£…ä¸ºåŒæ­¥æ¥å£ã€‚
        """
        if self._embedding_model is None:
            from core.memory.mem0.pool import _GGUFEmbedderAdapter, Mem0MemoryPool

            adapter = Mem0MemoryPool._create_local_embedder()
            if adapter is not None:
                self._embedding_model = adapter
                logger.info("âœ… Playbook embedding: å¤ç”¨æœ¬åœ° GGUF (BGE-M3)")
            else:
                raise RuntimeError(
                    "Playbook å‘é‡æœç´¢éœ€è¦æœ¬åœ° GGUF embedding æ¨¡å‹ï¼Œ"
                    "è¯·ç¡®è®¤ data/shared/models/bge-m3-Q4_K_M.gguf å­˜åœ¨"
                )
        return self._embedding_model

    async def load_all_async(self):
        """
        å¼‚æ­¥åŠ è½½æ‰€æœ‰ç­–ç•¥

        ä½¿ç”¨æ–¹å¼ï¼š
            await manager.load_all_async()
        """
        if self._loaded:
            return

        try:
            storage = self._get_storage()
            entries_data = await storage.list_all()

            for data in entries_data:
                entry = PlaybookEntry.from_dict(data)
                self._entries[entry.id] = entry

            self._loaded = True
            logger.info(f"ğŸ“š åŠ è½½ {len(self._entries)} ä¸ªç­–ç•¥æ¡ç›®")
        except Exception as e:
            logger.error(f"âŒ åŠ è½½ç­–ç•¥åº“å¤±è´¥: {e}")

    async def _save_entry(self, entry: PlaybookEntry):
        """é€šè¿‡ Storage Backend ä¿å­˜å•ä¸ªç­–ç•¥"""
        if not self.auto_save:
            return

        try:
            storage = self._get_storage()
            await storage.save(entry.id, entry.to_dict())
            await self._save_index()
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜ç­–ç•¥å¤±è´¥: {e}")

    async def _save_index(self):
        """é€šè¿‡ Storage Backend ä¿å­˜ç´¢å¼•"""
        try:
            storage = self._get_storage()
            index = {
                "entries": list(self._entries.keys()),
                "updated_at": datetime.now().isoformat(),
                "stats": {
                    "total": len(self._entries),
                    "approved": sum(
                        1 for e in self._entries.values() if e.status == PlaybookStatus.APPROVED
                    ),
                    "pending": sum(
                        1
                        for e in self._entries.values()
                        if e.status == PlaybookStatus.PENDING_REVIEW
                    ),
                },
            }
            await storage.save_index(index)
        except Exception as e:
            logger.warning(f"âš ï¸ ä¿å­˜ç´¢å¼•å¤±è´¥: {e}")

    def _generate_id(self, name: str, session_id: str = None) -> str:
        """ç”Ÿæˆç­–ç•¥ IDï¼ˆåŒ…å«æ—¶é—´æˆ³é¿å…åŒ session ç¢°æ’ï¼‰"""
        ts = datetime.now().isoformat()
        content = f"{name}:{session_id or ts}:{ts}"
        return hashlib.md5(content.encode()).hexdigest()[:12]

    # ==================== å‘é‡å­˜å‚¨åŒæ­¥ ====================

    async def _delete_from_vector_store(self, entry_id: str):
        """
        ä»ç‹¬ç«‹å‘é‡åº“åˆ é™¤æŒ‡å®š playbook çš„å‘é‡è®°å½•ã€‚

        é€šè¿‡ vector_store.list(filters={"playbook_id": id}) æŸ¥æ‰¾ï¼Œ
        å†é€æ¡åˆ é™¤ã€‚Best-effortï¼šå¤±è´¥æ—¶é™é»˜è·³è¿‡ã€‚
        """
        try:
            store = self._get_vector_store()
            results_and_count = store.list(
                filters={"playbook_id": entry_id}
            )
            results = results_and_count[0] if results_and_count else []

            deleted = 0
            for item in results:
                try:
                    store.delete(item.id)
                    deleted += 1
                except Exception:
                    pass

            if deleted:
                logger.debug(f"å‘é‡åˆ é™¤: playbook={entry_id}, åˆ é™¤ {deleted} æ¡")
        except Exception as e:
            logger.debug(f"å‘é‡åˆ é™¤è·³è¿‡: {e}")

    async def _sync_to_vector_store(self, entry: PlaybookEntry):
        """
        å°† Playbook æè¿°å†™å…¥ç‹¬ç«‹å‘é‡åº“ï¼ˆupsert è¯­ä¹‰ï¼šå…ˆåˆ åå¢ï¼‰ã€‚

        å†™å…¥å find_matching_async() çš„ Layer 2 æ‰èƒ½æœç´¢åˆ°è¯¥æ¡ç›®ã€‚
        JSON æ–‡ä»¶æ˜¯ source of truthï¼Œå‘é‡åº“æ˜¯æœç´¢ç´¢å¼•ã€‚
        Best-effortï¼šå‘é‡åº“ä¸å¯ç”¨æ—¶é™é»˜è·³è¿‡ã€‚
        """
        try:
            # Step 1: åˆ é™¤æ—§è®°å½•ï¼ˆé¿å…é‡å¤æ¡ç›®ï¼‰
            await self._delete_from_vector_store(entry.id)

            # Step 2: embed + å†™å…¥
            store = self._get_vector_store()
            embedding = self._get_embedding_model()

            searchable_text = entry.get_searchable_text()
            vec = embedding.embed(searchable_text)
            if not isinstance(vec, list):
                vec = vec.tolist() if hasattr(vec, "tolist") else list(vec)

            vec_id = str(uuid.uuid4())
            payload = {
                "playbook_id": entry.id,
                "data": searchable_text,
                "source": "playbook_manager",
                "task_types": ",".join(entry.trigger.get("task_types", [])),
                "created_at": datetime.now().isoformat(),
            }

            store.insert(
                vectors=[vec],
                ids=[vec_id],
                payloads=[payload],
            )
            logger.info(
                f"å‘é‡åŒæ­¥: playbook={entry.id}, "
                f"text={searchable_text[:60]}..."
            )
        except Exception as e:
            logger.warning(f"å‘é‡åŒæ­¥å¤±è´¥ï¼ˆplaybook æš‚æ—¶ä¸å¯æœç´¢ï¼‰: {e}")

    # ==================== CRUD æ“ä½œ ====================

    async def create(
        self,
        name: str,
        description: str,
        trigger: Dict[str, Any],
        strategy: Dict[str, Any],
        tool_sequence: List[Dict[str, Any]] = None,
        quality_metrics: Dict[str, float] = None,
        source: str = "manual",
        source_session_id: str = None,
    ) -> PlaybookEntry:
        """
        åˆ›å»ºæ–°ç­–ç•¥

        Args:
            name: ç­–ç•¥åç§°
            description: æè¿°
            trigger: è§¦å‘æ¡ä»¶
            strategy: æ‰§è¡Œç­–ç•¥
            tool_sequence: å·¥å…·åºåˆ—
            quality_metrics: è´¨é‡æŒ‡æ ‡
            source: æ¥æºï¼ˆauto/manual/importï¼‰
            source_session_id: æ¥æºä¼šè¯ ID

        Returns:
            PlaybookEntry
        """
        entry_id = self._generate_id(name, source_session_id)

        entry = PlaybookEntry(
            id=entry_id,
            name=name,
            description=description,
            trigger=trigger,
            strategy=strategy,
            tool_sequence=tool_sequence or [],
            quality_metrics=quality_metrics or {},
            source=source,
            source_session_id=source_session_id,
            status=PlaybookStatus.DRAFT if source == "auto" else PlaybookStatus.PENDING_REVIEW,
        )

        self._entries[entry_id] = entry
        await self._save_entry(entry)
        await self._sync_to_vector_store(entry)

        logger.info(f"ğŸ“ åˆ›å»ºç­–ç•¥: {name} (id={entry_id})")
        return entry

    def get(self, entry_id: str) -> Optional[PlaybookEntry]:
        """è·å–ç­–ç•¥"""
        return self._entries.get(entry_id)

    def list_all(self, status: Optional[PlaybookStatus] = None, source: Optional[str] = None) -> List[PlaybookEntry]:
        """
        åˆ—å‡ºæ‰€æœ‰ç­–ç•¥

        Args:
            status: è¿‡æ»¤çŠ¶æ€
            source: è¿‡æ»¤æ¥æº

        Returns:
            ç­–ç•¥åˆ—è¡¨
        """
        entries = list(self._entries.values())

        if status:
            entries = [e for e in entries if e.status == status]

        if source:
            entries = [e for e in entries if e.source == source]

        return sorted(entries, key=lambda e: e.created_at, reverse=True)

    async def update(self, entry_id: str, **updates) -> Optional[PlaybookEntry]:
        """æ›´æ–°ç­–ç•¥ï¼ˆåŒæ­¥å‘é‡ç´¢å¼•ä»¥ä¿æŒæœç´¢æ•°æ®ä¸€è‡´ï¼‰"""
        entry = self._entries.get(entry_id)
        if not entry:
            return None

        for key, value in updates.items():
            if hasattr(entry, key):
                setattr(entry, key, value)

        entry.updated_at = datetime.now().isoformat()
        await self._save_entry(entry)

        # å·²å®¡æ ¸çš„æ¡ç›®æ›´æ–°åéœ€è¦åŒæ­¥å‘é‡ç´¢å¼•
        if entry.status == PlaybookStatus.APPROVED:
            await self._sync_to_vector_store(entry)

        return entry

    async def delete(self, entry_id: str) -> bool:
        """åˆ é™¤ç­–ç•¥ï¼ˆåŒæ­¥æ¸…ç†å‘é‡ç´¢å¼•ï¼‰"""
        if entry_id not in self._entries:
            return False

        del self._entries[entry_id]

        try:
            storage = self._get_storage()
            await storage.delete(entry_id)
        except Exception as e:
            logger.warning(f"âš ï¸ åˆ é™¤ç­–ç•¥æ–‡ä»¶å¤±è´¥: {e}")

        await self._delete_from_vector_store(entry_id)
        await self._save_index()
        return True

    # ==================== å®¡æ ¸æµç¨‹ ====================

    async def submit_for_review(self, entry_id: str) -> bool:
        """æäº¤å®¡æ ¸ï¼ˆä»… DRAFT â†’ PENDING_REVIEWï¼‰"""
        entry = self._entries.get(entry_id)
        if not entry or entry.status != PlaybookStatus.DRAFT:
            return False

        entry.status = PlaybookStatus.PENDING_REVIEW
        entry.updated_at = datetime.now().isoformat()
        await self._save_entry(entry)

        logger.info(f"ğŸ“¤ ç­–ç•¥æäº¤å®¡æ ¸: {entry.name}")
        return True

    async def approve(self, entry_id: str, reviewer: str, notes: Optional[str] = None) -> bool:
        """
        å®¡æ ¸é€šè¿‡ï¼ˆä»… PENDING_REVIEW â†’ APPROVEDï¼‰

        å½“ description ä»ä¸ºè‡ªåŠ¨æå–çš„æ³›åŒ–æ¨¡æ¿æ—¶ï¼Œå°è¯•ç”¨ LLM é‡æ–°ç”Ÿæˆã€‚
        é«˜è´¨é‡çš„ description ç›´æ¥å†³å®š Mem0 è¯­ä¹‰åŒ¹é…çš„ç²¾åº¦ã€‚
        """
        entry = self._entries.get(entry_id)
        if not entry or entry.status != PlaybookStatus.PENDING_REVIEW:
            return False

        # å¦‚æœ description ä»æ˜¯é»˜è®¤æ¨¡æ¿ï¼ˆä½åŒºåˆ†åº¦ï¼‰ï¼Œå°è¯• LLM é‡æ–°ç”Ÿæˆ
        if self._is_default_description(entry):
            llm = await self._get_llm_service()
            if llm:
                try:
                    name, description = await self._regenerate_description(entry)
                    entry.name = name
                    entry.description = description
                    logger.info(f"ğŸ“ LLM é‡æ–°ç”Ÿæˆæè¿°: {name}")
                except Exception as e:
                    logger.warning(f"LLM æè¿°é‡æ–°ç”Ÿæˆå¤±è´¥ï¼Œä¿ç•™åŸæè¿°: {e}")

        entry.status = PlaybookStatus.APPROVED
        entry.reviewed_by = reviewer
        entry.review_notes = notes
        entry.updated_at = datetime.now().isoformat()
        await self._save_entry(entry)
        await self._sync_to_vector_store(entry)

        logger.info(f"âœ… ç­–ç•¥å®¡æ ¸é€šè¿‡: {entry.name} (by {reviewer})")
        return True

    @staticmethod
    def _is_default_description(entry: "PlaybookEntry") -> bool:
        """Check if description is a low-discriminability default template."""
        if not entry.description:
            return True
        default_patterns = ["è‡ªåŠ¨æå–çš„ç­–ç•¥", "è‡ªåŠ¨ç”Ÿæˆçš„ç­–ç•¥"]
        return any(p in entry.description for p in default_patterns)

    async def _regenerate_description(
        self, entry: "PlaybookEntry"
    ) -> tuple[str, str]:
        """Regenerate name + description from entry's tool_sequence via LLM."""

        @dataclass
        class _FakeStep:
            action: str
            reward: float = 0.8
            is_critical: bool = False

        @dataclass
        class _FakeReward:
            session_id: str
            total_reward: float = 0.8
            success: bool = True
            step_rewards: list = None  # type: ignore[assignment]

            def __post_init__(self):
                if self.step_rewards is None:
                    self.step_rewards = []

        steps = [
            _FakeStep(action=f"tool:{t.get('tool', '')}")
            for t in (entry.tool_sequence or [])
        ]
        fake_reward = _FakeReward(
            session_id=entry.source_session_id or entry.id,
            step_rewards=steps,
        )
        return await self._generate_description_with_llm(
            fake_reward, entry.tool_sequence or []
        )

    async def reject(self, entry_id: str, reviewer: str, reason: str) -> bool:
        """å®¡æ ¸æ‹’ç»ï¼ˆä»… PENDING_REVIEW â†’ REJECTEDï¼‰"""
        entry = self._entries.get(entry_id)
        if not entry or entry.status != PlaybookStatus.PENDING_REVIEW:
            return False

        entry.status = PlaybookStatus.REJECTED
        entry.reviewed_by = reviewer
        entry.review_notes = reason
        entry.updated_at = datetime.now().isoformat()
        await self._save_entry(entry)

        logger.info(f"âŒ ç­–ç•¥å®¡æ ¸æ‹’ç»: {entry.name} (by {reviewer})")
        return True

    async def deprecate(self, entry_id: str, reason: str = None) -> bool:
        """åºŸå¼ƒç­–ç•¥ï¼ˆä»… APPROVED â†’ DEPRECATEDï¼ŒåŒæ­¥æ¸…ç† Mem0 ç´¢å¼•ï¼‰"""
        entry = self._entries.get(entry_id)
        if not entry or entry.status != PlaybookStatus.APPROVED:
            return False

        entry.status = PlaybookStatus.DEPRECATED
        entry.review_notes = reason
        entry.updated_at = datetime.now().isoformat()
        await self._save_entry(entry)

        # åºŸå¼ƒçš„ç­–ç•¥ä¸åº”å‡ºç°åœ¨æœç´¢ç»“æœä¸­
        await self._delete_from_vector_store(entry_id)

        logger.info(f"ğŸ—‘ï¸ ç­–ç•¥å·²åºŸå¼ƒ: {entry.name}")
        return True

    # ==================== ç­–ç•¥æå– ====================

    async def extract_from_session(
        self,
        session_reward,
        use_llm: bool = True,
        user_query: str = "",
    ) -> Optional[PlaybookEntry]:
        """
        ä»æˆåŠŸä¼šè¯ä¸­æå–ç­–ç•¥

        Args:
            session_reward: ä¼šè¯å¥–åŠ±ç»“æœ
            use_llm: æ˜¯å¦ä½¿ç”¨ LLM ç”Ÿæˆæè¿°
            user_query: ç”¨æˆ·åŸå§‹æŸ¥è¯¢ï¼ˆç”¨äºç”Ÿæˆæœ‰è¯­ä¹‰çš„ç­–ç•¥æè¿°ï¼Œæé«˜åç»­åŒ¹é…ç‡ï¼‰

        Returns:
            æå–çš„ç­–ç•¥æ¡ç›®ï¼Œæˆ– None
        """
        # Dedup: skip if a playbook already exists for this session
        sid = session_reward.session_id
        for existing in self._entries.values():
            if existing.source_session_id == sid:
                logger.debug(
                    f"Playbook already exists for session {sid[:8]}..., "
                    f"skipping extraction (id={existing.id})"
                )
                return None

        # æ£€æŸ¥å¥–åŠ±é˜ˆå€¼
        if session_reward.total_reward < self.min_reward_threshold:
            logger.debug(
                f"ä¼šè¯å¥–åŠ± {session_reward.total_reward:.2f} "
                f"< é˜ˆå€¼ {self.min_reward_threshold}"
            )
            return None

        # æå–å·¥å…·åºåˆ—
        tool_sequence = []
        for step in session_reward.step_rewards:
            if step.action.startswith("tool:"):
                tool_name = step.action.replace("tool:", "")
                tool_sequence.append(
                    {"tool": tool_name, "reward": step.reward, "is_critical": step.is_critical}
                )

        # æ„å»ºè§¦å‘æ¡ä»¶
        trigger = {
            "task_types": (
                [session_reward.task_type] if hasattr(session_reward, "task_type") else []
            ),
            "complexity_range": [4, 8],  # é»˜è®¤èŒƒå›´
        }

        # æ„å»ºæ‰§è¡Œç­–ç•¥
        strategy = {
            "execution_strategy": (
                session_reward.execution_strategy
                if hasattr(session_reward, "execution_strategy")
                else "rvr"
            ),
            "suggested_tools": [t["tool"] for t in tool_sequence],
            "max_turns": len(session_reward.step_rewards),
        }

        # è´¨é‡æŒ‡æ ‡
        quality_metrics = {
            "avg_reward": session_reward.total_reward,
            "success_rate": 1.0 if session_reward.success else 0.0,
            "avg_turns": len(session_reward.step_rewards),
        }

        # ç”Ÿæˆåç§°å’Œæè¿°
        # ä¼˜å…ˆç”¨ user_query ä¿ç•™è¯­ä¹‰ä¿¡æ¯ï¼ˆæé«˜åç»­ Mem0 åŒ¹é…ç‡ï¼‰ï¼Œ
        # å¦åˆ™ç”¨å·¥å…·åæ‘˜è¦ä½œé»˜è®¤å€¼ï¼ˆä¸æš´éœ² session_idï¼‰
        if user_query:
            name = user_query[:40].strip()
            description = user_query[:200].strip()
        else:
            tools_brief = ", ".join([t["tool"] for t in tool_sequence[:3]])
            name = f"Auto-{tools_brief}" if tool_sequence else "Auto-strategy"
            description = "è‡ªåŠ¨æå–çš„ç­–ç•¥"

        if use_llm:
            llm = await self._get_llm_service()
            if llm:
                try:
                    name, description = await self._generate_description_with_llm(
                        session_reward, tool_sequence
                    )
                except Exception as e:
                    logger.warning(f"LLM ç”Ÿæˆæè¿°å¤±è´¥: {e}")

        # åˆ›å»ºç­–ç•¥æ¡ç›®ï¼ˆquality_metrics ç›´æ¥ä¼ å…¥ï¼Œé¿å…åŒé‡ä¿å­˜ï¼‰
        entry = await self.create(
            name=name,
            description=description,
            trigger=trigger,
            strategy=strategy,
            tool_sequence=tool_sequence,
            quality_metrics=quality_metrics,
            source="auto",
            source_session_id=session_reward.session_id,
        )

        logger.info(
            f"ğŸ¯ è‡ªåŠ¨æå–ç­–ç•¥: {name} (reward={session_reward.total_reward:.2f})"
        )

        return entry

    async def _generate_description_with_llm(
        self, session_reward, tool_sequence: List[Dict]
    ) -> tuple[str, str]:
        """
        ä½¿ç”¨ LLM ç”Ÿæˆç­–ç•¥åç§°å’Œæè¿°ã€‚

        æè¿°è´¨é‡ç›´æ¥å†³å®š Mem0 è¯­ä¹‰åŒ¹é…çš„ç²¾åº¦ã€‚
        æ³›åŒ–çš„æè¿°ï¼ˆå¦‚"è‡ªåŠ¨æå–çš„ç­–ç•¥"ï¼‰ä¼šå¯¼è‡´å‡é˜³æ€§åŒ¹é…ã€‚
        """
        from core.llm import Message

        tools_str = ", ".join([t["tool"] for t in tool_sequence])

        prompt = f"""æ ¹æ®ä»¥ä¸‹ä¼šè¯æ‰§è¡Œä¿¡æ¯ï¼Œç”Ÿæˆç­–ç•¥åç§°å’Œæè¿°ã€‚

ä¼šè¯ä¿¡æ¯ï¼š
- ä½¿ç”¨çš„å·¥å…·åºåˆ—ï¼š{tools_str}
- æ‰§è¡Œæ­¥éª¤æ•°ï¼š{len(session_reward.step_rewards)}
- æˆåŠŸç‡ï¼š100%

è¦æ±‚ï¼š
1. åç§°ï¼š10-20 å­—ï¼Œè¯´æ˜è¿™ä¸ªç­–ç•¥åšä»€ä¹ˆ
2. æè¿°ï¼š1-2 å¥è¯ï¼Œè¯´æ˜ä»€ä¹ˆåœºæ™¯ã€ä»€ä¹ˆè¾“å…¥æ•°æ®ä¸‹ä½¿ç”¨è¿™ä¸ªç­–ç•¥ã€‚æè¿°å¿…é¡»**å…·ä½“**ï¼Œèƒ½å’Œä¸ç›¸å…³çš„ä»»åŠ¡åŒºåˆ†å¼€

<examples>
<example>
<tools>data_analysis_skill, chart_generation</tools>
<output>{{"name": "Excel æ•°æ®åˆ†æå¹¶ç”Ÿæˆå›¾è¡¨", "description": "ç”¨æˆ·ä¸Šä¼  Excel/CSV è¡¨æ ¼æ–‡ä»¶ï¼Œéœ€è¦åˆ†ææ•°æ®ç‰¹å¾å¹¶ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨æ—¶ä½¿ç”¨"}}</output>
</example>
<example>
<tools>web_search, web_scraping</tools>
<output>{{"name": "ç½‘ç»œæœç´¢ä¸ä¿¡æ¯æ•´ç†", "description": "ç”¨æˆ·éœ€è¦ä»äº’è”ç½‘æœç´¢ç‰¹å®šä¸»é¢˜çš„ä¿¡æ¯å¹¶æ•´ç†æˆç»“æ„åŒ–æ‘˜è¦æ—¶ä½¿ç”¨"}}</output>
</example>
<example>
<tools>nodes, file_operation</tools>
<output>{{"name": "æœ¬åœ°æ–‡ä»¶æ‰¹é‡æ•´ç†", "description": "ç”¨æˆ·éœ€è¦æ‰«ææœ¬åœ°æ–‡ä»¶å¤¹ã€æŒ‰ç±»å‹åˆ†ç±»æˆ–æ‰¹é‡é‡å‘½åæ–‡ä»¶æ—¶ä½¿ç”¨"}}</output>
</example>
</examples>

è¾“å‡º JSON æ ¼å¼ï¼š
{{"name": "ç­–ç•¥åç§°", "description": "ç­–ç•¥æè¿°"}}
"""

        llm = await self._get_llm_service()
        if not llm:
            return "è‡ªåŠ¨ç­–ç•¥", "è‡ªåŠ¨ç”Ÿæˆçš„ç­–ç•¥"

        response = await llm.create_message_async(
            messages=[Message(role="user", content=prompt)],
            system="ä½ æ˜¯ä¸€ä¸ªç­–ç•¥åº“ç®¡ç†åŠ©æ‰‹ã€‚ç”Ÿæˆçš„æè¿°å¿…é¡»å…·ä½“ã€æœ‰åŒºåˆ†åº¦ï¼Œé¿å…æ³›åŒ–ã€‚",
        )

        import re

        match = re.search(r"\{[\s\S]*\}", response.content)
        if match:
            data = json.loads(match.group())
            return data.get("name", "è‡ªåŠ¨ç­–ç•¥"), data.get("description", "è‡ªåŠ¨ç”Ÿæˆçš„ç­–ç•¥")

        return "è‡ªåŠ¨ç­–ç•¥", "è‡ªåŠ¨ç”Ÿæˆçš„ç­–ç•¥"

    # ==================== ç­–ç•¥åŒ¹é…ï¼ˆLLM-First è¯­ä¹‰åŒ¹é…ï¼‰====================

    async def find_matching_async(
        self,
        query: str,
        task_type: str = "",
        top_k: int = 3,
        min_score: float = 0.0,
        only_approved: bool = True,
    ) -> List[tuple["PlaybookEntry", float]]:
        """
        è¯­ä¹‰åŒ¹é…ç­–ç•¥ï¼ˆLLM-First è®¾è®¡ï¼‰

        ä¸¤å±‚åŒ¹é…ï¼š
        1. Layer 1: task_type é¢„ç­›ï¼ˆç¡®å®šæ€§è§„åˆ™ï¼Œ<1msï¼‰
        2. Layer 2: ç‹¬ç«‹å‘é‡åº“è¯­ä¹‰æœç´¢ï¼ˆå‘é‡ç›¸ä¼¼åº¦ï¼Œé›¶é¢å¤– LLM è°ƒç”¨ï¼‰

        ç‹¬ç«‹å‘é‡åº“ï¼šplaybook_vectors.db åªåŒ…å« playbook æ¡ç›®ï¼Œ
        KNN æœç´¢ 100% å‘½ä¸­ playbookï¼Œä¸å—ç”¨æˆ·è®°å¿†æ•°é‡å½±å“ã€‚

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢ï¼ˆè‡ªç„¶è¯­è¨€ï¼‰
            task_type: æ„å›¾è¯†åˆ«è¾“å‡ºçš„ä»»åŠ¡ç±»å‹ï¼ˆå¯é€‰ï¼‰
            top_k: è¿”å›å‰ k ä¸ª
            min_score: æœ€ä½åŒ¹é…åˆ†æ•°ï¼ˆé»˜è®¤ 0.0ï¼Œä¸åšç¡¬é—¨æ§ï¼‰
            only_approved: ä»…è¿”å›å·²å®¡æ ¸é€šè¿‡çš„ç­–ç•¥

        Returns:
            [(ç­–ç•¥, åŒ¹é…åˆ†æ•°), ...]
        """
        # Layer 1: task_type é¢„ç­› + è¿‡æœŸè¿‡æ»¤ï¼ˆlazy evaluationï¼‰
        candidates = {
            entry_id: entry
            for entry_id, entry in self._entries.items()
            if (not only_approved or entry.status == PlaybookStatus.APPROVED)
            and entry.matches_task_type(task_type)
            and not entry.is_stale()
        }

        if not candidates:
            return []

        # Layer 2: ç‹¬ç«‹å‘é‡åº“æœç´¢ï¼ˆè¡¨é‡Œåªæœ‰ playbookï¼Œæ— éœ€ user_id è¿‡æ»¤ï¼‰
        try:
            store = self._get_vector_store()
            embedding = self._get_embedding_model()

            query_vector = embedding.embed(query)
            if not isinstance(query_vector, list):
                query_vector = query_vector.tolist() if hasattr(query_vector, "tolist") else list(query_vector)

            search_results_raw = store.search(
                query=query,
                vectors=[query_vector],
                limit=top_k * 3,
            )

            logger.info(
                f"Playbook å‘é‡æœç´¢: query={query[:40]}..., "
                f"results={len(search_results_raw)}, "
                f"candidates={list(candidates.keys())}"
            )

            # åŒ¹é…æœç´¢ç»“æœå’Œå€™é€‰ Playbookï¼ˆæŒ‰ playbook_id å»é‡ï¼‰
            matched = []
            seen_ids: set = set()
            for item in search_results_raw:
                payload = item.payload if hasattr(item, "payload") else {}
                playbook_id = payload.get("playbook_id", "")
                score = item.score if hasattr(item, "score") else 0.0

                if playbook_id in candidates and playbook_id not in seen_ids:
                    logger.info(
                        f"Playbook åŒ¹é…å€™é€‰: id={playbook_id[:8]}, "
                        f"score={score:.3f}, min={min_score}, "
                        f"pass={'Y' if score >= min_score else 'N'}"
                    )

                if (
                    playbook_id in candidates
                    and playbook_id not in seen_ids
                    and score >= min_score
                ):
                    seen_ids.add(playbook_id)
                    matched.append((candidates[playbook_id], score))

            if matched:
                matched.sort(key=lambda x: x[1], reverse=True)
                return matched[:top_k]

        except Exception as e:
            logger.warning(f"Playbook å‘é‡æœç´¢å¤±è´¥: {e}")

        return []

    def find_matching(
        self,
        context: Dict[str, Any],
        top_k: int = 3,
        min_score: float = 0.5,
        only_approved: bool = True,
    ) -> List[tuple["PlaybookEntry", float]]:
        """
        åŒæ­¥åŒ¹é…ç­–ç•¥ï¼ˆä»… task_type é¢„ç­›ï¼‰

        æ¨èä½¿ç”¨ find_matching_async() è¿›è¡Œè¯­ä¹‰åŒ¹é…ã€‚

        Args:
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆtask_type, query, complexity_scoreï¼‰
            top_k: è¿”å›å‰ k ä¸ª
            min_score: æœ€ä½åŒ¹é…åˆ†æ•°
            only_approved: ä»…è¿”å›å·²å®¡æ ¸é€šè¿‡çš„ç­–ç•¥

        Returns:
            [(ç­–ç•¥, åŒ¹é…åˆ†æ•°), ...]
        """
        task_type = context.get("task_type", "")
        candidates = []

        for entry in self._entries.values():
            if only_approved and entry.status != PlaybookStatus.APPROVED:
                continue
            if entry.matches_task_type(task_type):
                candidates.append((entry, 0.5))

        # æŒ‰ä½¿ç”¨æ¬¡æ•°æ’åº
        candidates.sort(key=lambda x: x[0].usage_count, reverse=True)
        return candidates[:top_k]

    async def record_usage(self, entry_id: str):
        """Record a successful match+injection (updates usage_count and last_used_at)."""
        entry = self._entries.get(entry_id)
        if entry:
            entry.usage_count += 1
            entry.last_used_at = datetime.now().isoformat()
            await self._save_entry(entry)

    # ==================== ç»Ÿè®¡ä¿¡æ¯ ====================

    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        entries = list(self._entries.values())
        approved = [e for e in entries if e.status == PlaybookStatus.APPROVED]

        return {
            "total": len(entries),
            "by_status": {
                status.value: sum(1 for e in entries if e.status == status)
                for status in PlaybookStatus
            },
            "by_source": {
                "auto": sum(1 for e in entries if e.source == "auto"),
                "manual": sum(1 for e in entries if e.source == "manual"),
                "import": sum(1 for e in entries if e.source == "import"),
            },
            "total_usage": sum(e.usage_count for e in entries),
            "stale_count": sum(1 for e in approved if e.is_stale()),
            "stale_days_threshold": STALE_DAYS,
            "avg_quality": (
                sum(e.quality_metrics.get("avg_reward", 0) for e in entries) / len(entries)
                if entries
                else 0
            ),
        }


def create_playbook_manager(
    storage_path: str = None,
    llm_service=None,
    **kwargs,
) -> PlaybookManager:
    """
    åˆ›å»ºç­–ç•¥åº“ç®¡ç†å™¨

    Args:
        storage_path: å­˜å‚¨è·¯å¾„ï¼Œé»˜è®¤ä½¿ç”¨å®ä¾‹éš”ç¦»è·¯å¾„
        llm_service: LLM æœåŠ¡
        **kwargs: å…¶ä»–å‚æ•°

    Returns:
        PlaybookManager å®ä¾‹

    ä½¿ç”¨ç¤ºä¾‹ï¼š
        manager = create_playbook_manager()
        await manager.load_all_async()
    """
    return PlaybookManager(
        storage_path=storage_path,
        llm_service=llm_service,
        **kwargs,
    )
