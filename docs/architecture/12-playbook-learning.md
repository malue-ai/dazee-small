# 12 â€” Playbook Online Learning

> The agent learns reusable strategies from successful sessions, confirmed by users, and applies them to similar future tasks â€” a closed-loop online learning system.

[< Prev: Evaluation & Quality](11-evaluation.md) | [Back to Overview](README.md)

---

## Design Goals

1. **Learn from success** â€” Automatically extract reusable strategies from sessions where the agent used tools effectively.
2. **Human-in-the-loop confirmation** â€” Users approve or dismiss suggested strategies. No strategy is applied without user consent.
3. **Semantic matching** â€” When a new task arrives, find the most relevant approved strategy using vector similarity, not keyword matching.
4. **Non-intrusive injection** â€” Matched strategies are injected as hints the agent can reference but is not forced to follow.

## Architecture

```
â”â”â” Strategy Extraction â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

  Successful Session (tools used, response complete)
       â”‚
       â–¼
  playbook_extraction (background task)
       â”‚
       â–¼
  PlaybookManager.extract_from_session() â”€â”€â†’ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                                     â”‚ Storage                      â”‚
       â–¼                                     â”‚   JSON files (per-instance)  â”‚
  PlaybookEntry (status: DRAFT)              â”‚   Mem0 vectors (semantic)    â”‚
       â”‚                                     â”‚   index.json (entry list)    â”‚
       â”‚                                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â” User Confirmation â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
       â”‚
       â–¼
  WebSocket: playbook_suggestion event
       â”‚
       â–¼
  PlaybookSuggestionCard (frontend)
       â”‚
       â”œâ”€ "è®°ä½" â”€â”€â†’ POST /api/v1/playbook/{id}/action (approve) â”€â”€â†’ APPROVED
       â””â”€ "å¿½ç•¥" â”€â”€â†’ POST /api/v1/playbook/{id}/action (dismiss) â”€â”€â†’ deleted

â”â”â” Strategy Application â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

  New user query
       â”‚
       â–¼
  PlaybookHintInjector (Phase 2)
       â”‚
       â–¼
  Two-layer matching: task_type filter â†’ Mem0 semantic search
       â”‚                                   â–²
       â–¼                                   â”‚ (reads from Storage)
  <playbook_hint> injected into agent context
       â”‚
       â–¼
  Agent references hint (not mandatory)
```

## The Learning Loop

The full lifecycle of a playbook, from extraction to application:

```
Step 1: EXTRACT
  User completes a chat session with tool usage
    â†’ Background task fires (fire-and-forget, never blocks chat)
    â†’ Pre-filter: skip trivial sessions (short response, no tools)
    â†’ Build lightweight SessionReward from conversation messages
    â†’ PlaybookManager.extract_from_session() creates DRAFT entry
    â†’ Entry saved to JSON file + indexed in Mem0 vectors

Step 2: CONFIRM
  â†’ playbook_suggestion event pushed via WebSocket
  â†’ Frontend shows PlaybookSuggestionCard: "å­¦åˆ°äº†ä¸€ä¸ªæ–°æŠ€å·§"
  â†’ User clicks "è®°ä½" â†’ POST /api/v1/playbook/{id}/action (approve)
  â†’ LLM regenerates description if still default template (light model, ~1s)
  â†’ Mem0 upsert: old vectors deleted, new vectors indexed
  â†’ Status: DRAFT â†’ PENDING_REVIEW â†’ APPROVED
  (Or user clicks "å¿½ç•¥" â†’ entry deleted + Mem0 cleaned)

Step 3: APPLY
  â†’ New chat request arrives
  â†’ PlaybookHintInjector (Phase 2, priority 80) activates
  â†’ Two-layer matching finds best strategy:
      Layer 1: task_type pre-filter + staleness check, 30 days (<1ms)
      Layer 2: Mem0 semantic search (vector similarity, score â‰¥ 0.5)
  â†’ Best match formatted as <playbook_hint>
  â†’ Injected into agent context (not mandatory, reference only)
  â†’ Fire-and-forget: record_usage updates last_used_at (never blocks chat)

Step 4: EXPIRE (automatic, lazy evaluation)
  â†’ On every match attempt, stale entries (unused > 30 days) are skipped
  â†’ No background scan, no cron job â€” checked at match time
  â†’ Stale playbooks remain in storage (user can still see/manage them)
  â†’ API response includes is_stale flag for frontend display
```

## PlaybookEntry

Each playbook captures a complete execution pattern:

```python
PlaybookEntry(
    id="a1b2c3d4e5f6",
    name="Excel data analysis with chart",
    description="Analyze Excel data and generate visual charts",

    # When to use this strategy
    trigger={
        "task_types": ["data_analysis"],
        "complexity_range": [4, 8],
    },

    # How to execute
    strategy={
        "execution_strategy": "rvr-b",
        "suggested_tools": ["data_analysis_skill", "chart_generation"],
        "max_turns": 15,
    },

    # Tool sequence template
    tool_sequence=[
        {"tool": "data_analysis_skill", "purpose": "Load and analyze data"},
        {"tool": "chart_generation", "purpose": "Generate visualization"},
    ],

    # Quality metrics from source session
    quality_metrics={
        "avg_reward": 0.85,
        "success_rate": 1.0,
        "avg_turns": 8,
    },

    # Lifecycle
    status=PlaybookStatus.APPROVED,
    source="auto",
    source_session_id="sess-abc123",
    usage_count=5,
    last_used_at="2026-01-15T10:30:00",  # Auto-updated on injection
)
```

## Status Lifecycle

```
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚   DRAFT   â”‚  â† Auto-extracted from session
     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
           â”‚ submit_for_review()
     â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ PENDING_REVIEW  â”‚  â† Waiting for user action
     â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
        â”‚          â”‚
  approve()    reject()
        â”‚          â”‚
  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
  â”‚ APPROVED â”‚  â”‚ REJECTED â”‚
  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â”œâ”€â”€ used within 30 days â”€â”€â†’ stays APPROVED (active)
        â”‚
        â”œâ”€â”€ unused > 30 days â”€â”€â†’ still APPROVED but is_stale=true (skipped during matching)
        â”‚
        â””â”€â”€ deprecate() â”€â”€â†’ DEPRECATED (Mem0 vectors cleaned)
```

| Status | Meaning | Can be injected? |
|---|---|---|
| DRAFT | Auto-generated, not yet confirmed | No |
| PENDING_REVIEW | Submitted for user review | No |
| APPROVED | User confirmed, active | Yes (if not stale) |
| APPROVED + stale | Unused > 30 days | No (skipped at match time) |
| REJECTED | User declined | No |
| DEPRECATED | Previously approved, now retired | No |

## Two-Layer Matching (Precision-First)

Strategy matching follows the LLM-First principle with **precision over recall**: a false positive (injecting an irrelevant strategy) is worse than a false negative (missing a relevant one), because irrelevant hints can mislead the agent's tool selection and execution flow.

| Layer | Method | Latency | Purpose |
|---|---|---|---|
| **Layer 1** | `task_type` filter + staleness check | <1ms | Quick pre-filter: status=APPROVED, matches task_type, not stale (unused > 30 days). |
| **Layer 2** | Mem0 semantic search | ~50ms | Vector similarity + FTS5 keyword hybrid search. Deduplication by playbook_id. Score threshold â‰¥ 0.5. |

```python
# Layer 1: deterministic filter + staleness check
candidates = {
    id: entry for id, entry in entries.items()
    if entry.status == APPROVED
    and entry.matches_task_type(task_type)
    and not entry.is_stale()  # unused > 30 days â†’ skip
}

# Layer 2: semantic search via Mem0 (no prefix noise)
results = pool.search(user_id="playbook", query=query, limit=top_k * 2)

# Deduplicate by playbook_id, filter by min_score (0.5)
```

**Precision safeguards:**
- **min_score = 0.5** (raised from 0.3) â€” filters out weak/ambiguous matches.
- **No dangerous fallback** â€” if Mem0 is unavailable, returns empty (no guessing).
- **Deduplication by playbook_id** â€” prevents the same playbook appearing multiple times in results.
- **Staleness filter** â€” entries unused for 90+ days are excluded from matching.
- **Agent-side defense** â€” prompt instructs the agent to ignore hints with confidence < 0.5 and to trust its own judgment over hints.

## Context Injection

`PlaybookHintInjector` injects the best-matching strategy into Phase 2 (User Context):

```xml
<playbook_hint confidence="0.78">
ç±»ä¼¼ä»»åŠ¡çš„æˆåŠŸç­–ç•¥ï¼šAnalyze Excel data and generate visual charts
å»ºè®®å·¥å…·åºåˆ—ï¼šdata_analysis_skill â†’ chart_generation
å¹³å‡çº¦ 8 æ­¥ï¼ŒæˆåŠŸç‡ 100%
</playbook_hint>
```

**Key design decisions:**
- **Priority 80** â€” Lower than user memory (which has higher priority), ensuring personal context takes precedence.
- **Budget ~300 tokens** â€” Kept compact to avoid overwhelming the context window.
- **Non-mandatory** â€” The hint is a reference, not an instruction. The agent can choose to follow a different approach. The system prompt explicitly tells the agent: "confidence < 0.5 æ—¶å¿½ç•¥; å¦‚æœä½ çš„åˆ¤æ–­ä¸ hint å†²çªï¼Œä»¥ä½ çš„åˆ¤æ–­ä¸ºå‡†".
- **Top-1 only** â€” Only the single best match is injected, avoiding information overload.
- **SESSION cache** â€” The same hint is reused within a session, avoiding repeated Mem0 queries.
- **Fire-and-forget usage tracking** â€” On successful injection, `record_usage()` is called via `asyncio.create_task()`, updating `last_used_at` without adding any latency to the chat response.

## Background Extraction

The extraction task runs as a fire-and-forget background task after each chat response:

```
Chat response complete
  â†’ BackgroundTaskService schedules playbook_extraction
  â†’ Pre-filter checks:
      - Assistant response â‰¥ 100 chars?
      - User message â‰¥ 10 chars?
      - Conversation had tool calls?
  â†’ If all pass: build SessionReward, call extract_from_session()
  â†’ If entry created: push playbook_suggestion via WebSocket
  â†’ Failure is non-critical: logged and swallowed
```

**Deduplication**: If a playbook already exists for the same `session_id`, extraction is skipped.

**WebSocket delivery**: Background tasks run after the chat SSE stream is closed. The suggestion is delivered via the persistent WebSocket connection (`ConnectionManager.broadcast_notification()`), ensuring it reaches the frontend even after the chat response ends.

## Frontend Experience

The `PlaybookSuggestionCard` component appears inline in the chat:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ’¡  å­¦åˆ°äº†ä¸€ä¸ªæ–°æŠ€å·§                          â”‚
â”‚      å·¥å…·åºåˆ—: data_analysis â†’ chart_gen       â”‚
â”‚                                              â”‚
â”‚      [ è®°ä½ ]  [ å¿½ç•¥ ]                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- **"è®°ä½"** â†’ `POST /api/v1/playbook/{id}/action` with `action: "approve"` â†’ LLM regenerates description (light model, ~1s) â†’ Mem0 upsert â†’ Card shows "å·²è®°ä½ï¼š..."
- **"å¿½ç•¥"** â†’ `POST /api/v1/playbook/{id}/action` with `action: "dismiss"` â†’ Entry deleted + Mem0 cleaned â†’ Card fades out

**Non-blocking guarantee**: The card has its own `loading` state (button shows "..."), but the chat input (`ChatInputArea`) is never disabled. Users can continue typing and sending messages while the approve/dismiss HTTP request is pending. The `isCurrentLoading` flag that controls input availability only tracks conversation loading and session state â€” playbook actions are completely independent.

## API Endpoints

| Method | Endpoint | Purpose |
|---|---|---|
| GET | `/api/v1/playbook` | List all playbooks (filter by status/source) |
| GET | `/api/v1/playbook/{id}` | Get playbook details |
| POST | `/api/v1/playbook/{id}/action` | Execute action (approve/reject/dismiss) |
| DELETE | `/api/v1/playbook/{id}` | Delete a playbook |

## Storage

Playbooks are stored per-instance as JSON files:

```
data/instances/{name}/playbooks/
â”œâ”€â”€ index.json              # Entry list + stats
â”œâ”€â”€ a1b2c3d4e5f6.json      # Individual playbook entry
â”œâ”€â”€ f7e8d9c0b1a2.json
â””â”€â”€ ...
```

Additionally, each playbook's searchable text is indexed in **Mem0 vectors** (with `user_id="playbook"`) for semantic matching. This dual-storage approach keeps file-based CRUD simple while enabling vector similarity search.

## Key Files

| File | Purpose |
|---|---|
| `core/playbook/__init__.py` | Module exports |
| `core/playbook/manager.py` | `PlaybookManager` â€” CRUD, extraction, two-layer matching |
| `core/playbook/storage.py` | `FileStorage` â€” JSON file backend |
| `core/context/injectors/phase2/playbook_hint.py` | `PlaybookHintInjector` â€” strategy â†’ context injection |
| `utils/background_tasks/tasks/playbook_extraction.py` | Background extraction task |
| `routers/playbook.py` | REST API endpoints |
| `frontend/src/api/playbook.ts` | Frontend API client |
| `frontend/src/components/chat/PlaybookSuggestionCard.vue` | Inline suggestion card |

## Highlights

- **Closed-loop learning** â€” Extract â†’ Confirm â†’ Apply â†’ Expire. The agent gets better at recurring task types over time, and silently forgets strategies that are no longer used.
- **Human-in-the-loop** â€” No strategy is auto-applied. Users control what the agent "remembers", preventing bad patterns from persisting.
- **Precision-first matching** â€” Score threshold â‰¥ 0.5, no dangerous fallback, playbook_id deduplication, and staleness filtering. False positives (injecting irrelevant strategies) are treated as more harmful than false negatives (missing a match).
- **Automatic staleness** â€” Lazy evaluation: entries unused for 30+ days are silently skipped during matching. No cron jobs, no background scans. The entry stays in storage; users can see `is_stale` in the management UI.
- **Zero-blocking guarantee** â€” Every step is designed to never block the chat input:
  - Extraction: fire-and-forget background task
  - Approve/dismiss: frontend card has local loading state; `ChatInputArea` is independent
  - Usage tracking: `asyncio.create_task()` fire-and-forget
  - Injection: Phase 2 injector runs before the LLM call, not during user input
- **LLM-enhanced descriptions on approve** â€” When a user clicks "è®°ä½", the system uses a light model (Haiku-class) to regenerate the description with few-shot examples, improving semantic matching precision. This happens in ~1s and only on the card button â€” never delays the chat.
- **Mem0 data consistency** â€” Upsert semantics (delete-then-add) on every sync. approve/update/delete/deprecate all synchronize the Mem0 vector index. No stale or duplicate vectors.
- **Semantic matching** â€” Strategies are found by meaning (vector similarity + FTS5 hybrid), not keywords. "Analyze sales data" matches a playbook about "data analysis with charts".
- **Instance-isolated** â€” Each agent instance has its own playbook library. Strategies are not shared across instances.

## Limitations & Future Work

- **No cross-session learning** â€” Each playbook comes from a single session. Merging patterns across multiple similar sessions would produce more robust strategies.
- **No playbook management UI** â€” Users can only approve/dismiss via inline cards. A dedicated management page (list, edit, delete, search with `is_stale` indicators) is planned.
- **Fixed reward threshold** â€” The `min_reward_threshold=0.7` is static. Adaptive thresholds based on task type and historical data would improve extraction quality.
- **Single-strategy injection** â€” Only the top-1 match is injected. For complex tasks, multiple complementary strategies could be combined.
- **No quality feedback loop** â€” Usage count is tracked but ongoing success/failure rate after injection is not measured. Tracking post-injection outcomes would enable automatic deprecation of underperforming strategies.

---

[< Prev: Evaluation & Quality](11-evaluation.md) | [Back to Overview](README.md) | [Next: Cloud Collaboration >](13-cloud-collaboration.md)
