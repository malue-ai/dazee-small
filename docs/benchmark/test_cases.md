# 小搭子 vs clawdbot (OpenClaw) — 完整测试用例

> **测试目标**：面向小白用户，从效果、特色、Token 消耗、场景四个维度验证差异化
>
> **测试对象**：小搭子（ZenFlux xiaodazi）vs clawdbot/OpenClaw
>
> **注意**：两端均使用 Claude Sonnet 4.5 作为主模型，确保模型能力一致，仅对比框架差异

---

## 测试用例总览

| ID | 维度 | 类型 | 用例名称 | 轮次 | 核心验证点 |
|----|------|------|---------|------|----------|
| A1 | 效果 | 单轮 | 格式混乱 Excel 分析 | 1 | 回溯自愈 vs 报错停止 |
| A2 | 效果 | 多轮 | 论文润色 + 追问修改 | 3 | 追问理解 + 风格连贯 |
| A3 | 效果 | 单轮 | PDF 转 Word 出错恢复 | 1 | 错误分类 + 替代方案 |
| B1 | 特色 | 多轮 | 记忆学习 + 跨会话风格 | 5(跨3会话) | 三层记忆 vs 单层记忆 |
| B2 | 特色 | 单轮 | 环境感知 + 精准推荐 | 1 | OS 检测 + 应用扫描 |
| B3 | 特色 | 单轮 | 危险操作安全确认 | 1 | HITL 机制 vs 无保护 |
| B4 | 特色 | 多轮 | 长任务自动确认 | 4 | 长任务管理 + 费用控制 |
| **B5** | **特色** | **多轮** | **本地知识语义搜索** | **3** | **混合搜索 + 本地向量 + 隐私保护** |
| **B6** | **特色** | **多轮** | **用户画像累积构建** | **8(跨4会话)** | **FragmentExtractor 10维提取 + PersonaBuilder 画像聚合** |
| **B7** | **特色** | **多轮** | **记忆冲突检测与更新** | **4(跨2会话)** | **QualityController 冲突检测 + 决策 + TTL** |
| **B8** | **特色** | **多轮** | **个性化记忆驱动主动响应** | **6(跨3会话)** | **UserMemoryInjector + Reranker + 全链路闭环** |
| **B9** | **特色** | **多轮** | **文件修改异常退出自动回滚** | **3** | **Snapshot 磁盘持久化 + OperationLog 逆操作 + 崩溃恢复** |
| **B10** | **特色** | **多轮** | **文件修改用户中止选择性回滚** | **4** | **HITL 中止 + rollback_options 展示 + 全部/部分回滚** |
| C1 | Token | 单轮 | 简单问答 Token 对比 | 1 | 意图缓存 + prompt 缓存 |
| C2 | Token | 多轮 | 10 轮对话 Token 累积 | 10 | 上下文管理效率 |
| C3 | Token | 单轮 | 复杂工具调用 Token | 1 | 工具输出 compaction |
| D1 | 场景 | 单轮 | 24/7 后台自动化 | 1 | clawdbot 强项 |
| D2 | 场景 | 单轮 | 小白首次安装使用 | 1 | 小搭子强项 |
| D3 | 场景 | 单轮 | 多步骤内容创作 | 1 | 对等比较 |
| D4 | 场景 | 单轮 | 连续错误恢复 | 1 | 智能回溯 vs compaction 循环 |
| D5 | 场景 | 单轮 | 状态回滚安全网 | 1 | 快照/回滚 vs 无保护 |
| **D6** | **场景** | **单轮** | **离线知识问答** | **1** | **本地模型零网络 vs 云端依赖** |
| **E1** | **电脑操作** | **多轮** | **跨应用调研 → 整理 → 报告生成** | **12** | **多应用切换 + 长程规划 + 上下文连贯** |
| **E2** | **电脑操作** | **多轮** | **日程创建 + 文档协同 + 提醒通知** | **8** | **批量 GUI 操作 + 冲突恢复 + 回滚安全** |
| **E3** | **电脑操作** | **多轮** | **表单自动填写与数据迁移** | **10** | **数据提取 + GUI 逐字段填写 + 错误恢复** |
| **E4** | **电脑操作** | **多轮** | **应用崩溃中途恢复与断点续做** | **6** | **GUI 异常检测 + 状态恢复 + 断点续做** |

---

## 维度 A：效果差异化

### A1. 格式混乱 Excel 分析（单轮）

**测试数据**：`data/messy_sales.xlsx`

**用户输入**：
```
帮我分析这个表格的销售趋势，告诉我哪个产品卖得最好
```

**数据特征**（故意制造的问题）：
- 日期列：6 种格式混合（`2024-01-15`/`1月15日`/`01/15/2024` 等）
- 销售额列：数字和文本混合（`12345` vs `¥12,345`）
- 数量列：`int` 和 `str` 混合（`50` vs `50个`）
- 第 8、15、23 行为空行
- 第 10-12 行地区列为合并单元格
- 底部汇总行写的是"详见附表"（文本）

**预期对比**：

| 指标 | clawdbot | 小搭子 |
|------|---------|--------|
| **首次尝试** | 调用工具读取 Excel → 可能因格式问题报错 | `excel-analyzer` Skill 尝试解析 |
| **错误处理** | LLM 自行决定重试策略，无系统化回溯 | RVR-B `ErrorClassifier` → `PARAM_ADJUST` 回溯 → 自动清洗数据 |
| **compaction 风险** | 工具输出大 → 可能触发 auto-compaction → 丢失错误上下文 → 重试循环 | `tool_result` compaction 裁剪大型输出，上下文可控 |
| **最终输出** | 可能需要 2-3 轮用户干预才完成 | 1 轮：自动修复 → 输出分析报告 |

**量化指标**：

| 指标 | clawdbot 预期 | 小搭子预期 |
|------|-------------|----------|
| 用户交互轮数 | 2-4 | 1 |
| 任务完成率 | ~60%（首次成功） | ~90%（含回溯后成功） |
| Token 消耗 | ~15K-25K（含重试） | ~10K-15K |
| 耗时 | 3-5 分钟（含等待用户） | 1-2 分钟（全自动） |

**技术验证点**：
- [ ] `excel-analyzer` Skill 是否正确加载（lightweight，自动安装 pandas+openpyxl）
- [ ] `ErrorClassifier` 是否将格式解析错误分类为 `business_logic`（非 `infrastructure`）
- [ ] `BacktrackManager` 是否触发 `PARAM_ADJUST` 回溯（调整解析参数）
- [ ] 回溯后是否成功完成任务（不超过 `max_backtrack_attempts=3`）

---

### A2. 论文润色 + 追问修改（3 轮）

**测试数据**：`data/academic_abstract.txt`

**对话流程**：

```
轮次1：用户发送摘要文本 + "帮我润色这段论文摘要，学术风格"
轮次2："太正式了，保持学术但更简洁一些"
轮次3："把'本研究'都改成'本文'，同时加一句研究意义"
```

**预期对比**：

| 指标 | clawdbot | 小搭子 |
|------|---------|--------|
| **轮次1 理解** | 正确理解润色需求 | 正确理解，意图识别 `task_type=content_generation` |
| **轮次2 追问** | 依赖 context window 历史理解"太正式了" | `is_follow_up=true` → 复用 `plan_cache` → 只调整风格，不重新规划 |
| **轮次3 精确修改** | 可能重新生成全文（丢失轮次2的调整） | 在轮次2结果基础上精确修改（追问继承 task_type） |
| **风格连贯性** | 可能有风格漂移 | plan_cache 保证连贯 |

**Token 消耗对比**：

| 轮次 | clawdbot input | 小搭子 input | 差异原因 |
|------|---------------|-------------|---------|
| 1 | ~6K | ~4K | system prompt 缓存 |
| 2 | ~10K（含轮次1全量历史） | ~6K（intent 过滤：只取最近5条user + 截断assistant） | `_filter_for_intent` 过滤 |
| 3 | ~15K（含轮次1+2全量） | ~8K（同上 + prompt 缓存命中） | 累积上下文管理 |
| **总计** | **~31K** | **~18K** | **节省 42%** |

**技术验证点**：
- [ ] `IntentAnalyzer` 轮次2/3 是否识别为 `is_follow_up=true`
- [ ] 轮次2 是否复用轮次1 的 plan_cache（不重新规划）
- [ ] 轮次3 "本研究→本文"替换是否精确（不破坏其他修改）
- [ ] 3 轮总 Token 是否显著低于 clawdbot

---

### A3. PDF 转 Word 出错恢复（单轮）

**测试数据**：`data/scanned_contract.pdf`（需手动准备，参见 `scanned_pdf_note.md`）

**用户输入**：
```
把这个 PDF 转成 Word 文档
```

**场景设计**：PDF 第 3 页是扫描图片（纯图像），pypdf 无法提取文本。

**预期对比**：

| 阶段 | clawdbot | 小搭子 |
|------|---------|--------|
| **首次尝试** | 工具读取 PDF → 第 3 页返回空白或报错 | `nano-pdf` Skill 解析 → 第 3 页无文本 |
| **错误发现** | LLM 发现"第 3 页内容为空"，可能直接忽略或报错 | RVR-B `ErrorClassifier` 分类 → "方法问题"（`TOOL_REPLACE` 回溯） |
| **替代方案** | 需要用户指示"跳过图片页" | 自动尝试：跳过 → 标注"此页为扫描件" → 继续其他页 |
| **最终输出** | 可能缺少第 3 页内容，未标注 | Word 文档含所有可解析页 + 第 3 页标注"[扫描件，需 OCR]" |

**量化指标**：

| 指标 | clawdbot 预期 | 小搭子预期 |
|------|-------------|----------|
| 用户交互轮数 | 1-2（可能需追问如何处理扫描页） | 1（全自动） |
| 内容完整度 | 可能漏掉扫描页 | 全部页面（扫描页有标注） |
| 回溯类型 | 无 | `TOOL_REPLACE` 或 `PARAM_ADJUST` |

---

## 维度 B：特色差异化

### B1. 记忆学习 + 跨会话风格记忆（5 轮，跨 3 个会话）

**测试数据**：`data/coffee_article.txt` + `data/tea_culture_prompt.txt`

**对话流程**：

```
=== 会话 1 ===
轮次1：用户 "帮我写篇关于咖啡的文章"
      → 预期：通用风格的文章（还没学到偏好）

轮次2：用户 "不对，我喜欢毒舌+干货风格" + 附上 coffee_article.txt 样本
      → 预期：按毒舌风格重写
      → 关键：小搭子 style-learner Skill 提取风格特征

[结束会话1 → flush() 触发记忆提取]

=== 会话 2（新会话）===
轮次3：用户 "写篇关于茶文化的文章"（不再提风格！）
      → 预期（小搭子）：自动应用毒舌+干货风格 ✓
      → 预期（clawdbot）：可能回到通用风格 ✗

=== 会话 3（新会话）===
轮次4：用户 "小搭子你记住了什么关于我的写作偏好？"
      → 预期（小搭子）：读取 MEMORY.md 回答"您偏好毒舌+干货风格" ✓
      → 预期（clawdbot）：memory_search 可能召回，但回答不一定结构化

轮次5：用户 "我现在想换成温暖治愈风格"
      → 预期：更新记忆，后续文章应用新风格
```

**预期对比**：

| 指标 | clawdbot | 小搭子 |
|------|---------|--------|
| **记忆提取** | 依赖 memory 工具手动/半自动写入 | `flush()` → `FragmentExtractor` 自动提取 → `QualityController` 去重 |
| **存储结构** | MEMORY.md（无结构化分类） | MEMORY.md 按段落分类（preference/fact/workflow/style） |
| **跨会话召回** | `memory_search` 语义搜索（BM25 + 向量） | `recall()` 融合搜索（FTS5 BM25 + Mem0 向量），结果合并去重 |
| **记忆透明性** | 用户需要知道文件路径 | `get_memory_context()` 直接读取 → 可直接回答"记住了什么" |
| **记忆可编辑** | 可编辑但无引导 | MEMORY.md 分类清晰，编辑后下次 `recall()` 自动生效 |
| **项目隔离** | 无原生隔离 | `projects/{id}/MEMORY.md` 独立 |
| **冲突处理** | 新记忆覆盖旧记忆 | `QualityController` LLM 驱动的冲突检测 → 合并/替换/保留 |

**Token 消耗对比**：

| 操作 | clawdbot | 小搭子 |
|------|---------|--------|
| 记忆提取 | 依赖 LLM 决定何时写入 memory | `flush()` 后台异步，~500 tokens |
| 记忆召回（会话2） | `memory_search` 工具调用 ~1000 tokens | `recall()` 零 LLM 调用（BM25 + 向量检索） |
| 记忆注入 | 注入 system prompt → 可能影响缓存 | 注入 messages 层 → system prompt 缓存不受影响 |

**技术验证点**：
- [ ] 会话1结束后 `flush()` 是否提取了"毒舌+干货风格"记忆
- [ ] MEMORY.md 中是否出现"style"分类段落
- [ ] 会话2 `recall()` 是否召回风格记忆
- [ ] 会话2 输出是否自动应用毒舌风格（无需用户说明）
- [ ] 会话3 "记住了什么"问题是否正确回答
- [ ] 轮次5 更新风格后，`QualityController` 是否触发冲突检测

---

### B2. 环境感知 + 精准工具推荐（单轮）

**用户输入**：
```
帮我打开最近修改的那个 Word 文档
```

**预期对比**：

| 指标 | clawdbot | 小搭子 |
|------|---------|--------|
| **OS 检测** | 通过 shell 命令（`uname`）手动检测 | `RuntimeContextBuilder` 启动时自动注入 OS 信息到 system prompt |
| **应用扫描** | 无内置应用发现 | `AppScanner._scan_darwin()` 扫描 `/Applications` 已安装应用 |
| **工具选择** | LLM 自行选择 shell 命令（可能用 `open` 或 `explorer`） | `OSSkillMerger` 自动合并 common + darwin Skills → `macos-finder` + `macos-open` |
| **精准度** | 需要额外工具调用确认 OS | 首次请求即精准执行（环境信息已在 system prompt） |

**Token 消耗差异**：
- clawdbot：可能需要 1-2 轮工具调用确认环境 → 额外 ~3000 tokens
- 小搭子：环境信息一次性注入 system prompt（~200 tokens），零额外工具调用

**技术验证点**：
- [ ] `RuntimeContextBuilder` 是否在 system prompt 中注入了 OS 和已安装应用信息
- [ ] `OSSkillMerger` 是否正确合并了 macOS Skills
- [ ] `macos-finder` Skill 是否被正确调用（而非通用 shell 命令）

---

### B3. 危险操作安全确认 — HITL（单轮）

**用户输入**：
```
帮我删除桌面上所有的 .tmp 文件
```

**预期对比**：

| 指标 | clawdbot | 小搭子 |
|------|---------|--------|
| **确认机制** | 依赖 LLM 自主判断是否需要确认（不稳定） | `AdaptiveTerminator` HITL 检查：`delete` 匹配 `require_confirmation` → 强制弹窗确认 |
| **确认内容** | LLM 可能只文字确认"要删除吗？" | `emit_hitl_confirm()` SSE 事件 → 前端展示文件列表 + 确认/取消按钮 |
| **回滚能力** | 无（删除不可逆） | `ConsistencyManager.snapshot()` 任务前快照 + `OperationRecord` 逆操作 |
| **安全性** | 取决于 LLM 判断 | 确定性规则保证（`require_confirmation` 列表） |

**关键差异**：clawdbot 的安全确认依赖 LLM 判断（可能漏过），小搭子用确定性规则（`hitl.require_confirmation` 列表含 `delete`/`overwrite`/`send_email` 等关键词）。

**技术验证点**：
- [ ] `AdaptiveTerminator._check_hitl()` 是否拦截 `delete` 操作
- [ ] `emit_hitl_confirm()` 是否推送 SSE 事件
- [ ] 用户确认后是否正确执行删除
- [ ] 用户取消后是否正确中止（不执行任何删除）

---

### B4. 长任务自动确认（4 轮）

**测试数据**：`data/mixed_files/`（100 个文件）

**对话流程**：

```
轮次1：用户 "帮我整理这个文件夹里的所有文件，按类型分类移动到不同子文件夹"
      → 预期：开始执行文件分类（txt→笔记/、md→文档/、csv→数据/、json→配置/、log→日志/）

[执行到第20轮时...]
轮次2（系统自动）："已执行 20 轮，当前进度：已分类 65 个文件。是否继续？"
      → 这是 AdaptiveTerminator 的 long_running_confirm_after_turns=20 触发的

轮次3：用户 "继续"

轮次4（系统）：任务完成，"已将 100 个文件分类到 5 个子文件夹"
```

**预期对比**：

| 指标 | clawdbot | 小搭子 |
|------|---------|--------|
| **长任务管理** | 无自动确认，context window 满时触发 compaction | `long_running_confirm_after_turns=20` 主动确认 |
| **compaction 风险** | compaction 丢失执行上下文 → 可能重复操作已分类的文件 | 无 compaction，`_trim_messages_if_needed()` 保留关键消息 |
| **费用控制** | 无主动控制，用户不知道还要消耗多少 token | 确认点让用户决定是否继续 |
| **进度可见** | 无结构化进度 | `ProgressTransformer` + `emit_progress_update()` SSE 事件 |

**技术验证点**：
- [ ] `AdaptiveTerminator` 在第 20 轮是否触发 `long_running_confirm`
- [ ] 确认后是否继续执行（不重复已完成操作）
- [ ] `confirm_long_running()` 是否避免重复询问
- [ ] 任务完成后 `file-manager` Skill 创建的文件夹结构是否正确

---

### B5. 本地知识语义搜索（3 轮）

**测试目标**：验证小搭子的核心差异化能力 — 混合搜索（FTS5 关键词 + 向量语义并行 → 加权合并），对比 clawdbot 的顺序搜索策略。

**前置条件**：用户已在 config.yaml 配置 `knowledge.directories: ["~/Documents/工作"]`，目录内含 30+ 份 .md/.txt 文档（会议纪要、技术方案、需求文档等）。

**对话流程**：

```
轮次1（精确关键词搜索）：
  用户 "帮我找一下上次写的关于 FTS5 的技术方案"
  → 验证：FTS5 关键词直接命中 + 向量语义补充相关文档

轮次2（语义理解搜索 — 核心差异点）：
  用户 "那个讨论怎么让搜索更智能的文档在哪"
  → 注意：用户没说"语义搜索"、"向量"任何技术关键词
  → 验证：向量语义搜索理解"搜索更智能" ≈ "语义搜索/混合检索/向量"

轮次3（跨语言搜索）：
  用户 "find the document about performance optimization"
  → 验证：英文查询匹配中文文档"性能优化"
```

**预期对比**：

| 指标 | clawdbot | 小搭子 |
|------|---------|--------|
| **轮次1：精确搜索** | memory_search BM25 召回 → 可找到 | FTS5 + 向量并行 → 同样找到，且向量补充相关文档 |
| **轮次2：模糊语义** | BM25 "搜索更智能" 无精确匹配 → 可能靠向量兜底 | 向量语义直接理解"搜索更智能"≈"语义检索" → **准确召回** |
| **轮次3：跨语言** | 向量搜索可能支持，取决于 embedding 模型 | BGE-M3 原生中英文双语 → **performance optimization 匹配 性能优化** |
| **搜索策略** | 顺序搜索（FTS5 优先 → 向量降级） | **并行搜索 → 加权合并去重**（两路结果互补，不遗漏） |
| **数据隐私** | embedding 可能发送到云端（OpenAI API） | **本地 GGUF 模型，数据不出机器** |
| **离线能力** | 云端 embedding 需要网络 | **完全离线可用**（FTS5 零依赖 + GGUF 本地模型） |

**量化指标**：

| 指标 | clawdbot 预期 | 小搭子预期 |
|------|-------------|----------|
| 轮次1 召回率 | 高（精确关键词） | 高（关键词 + 语义双重命中） |
| 轮次2 召回率 | **低~中**（无精确关键词匹配） | **高**（向量语义理解） |
| 轮次3 跨语言召回 | 中（取决于 embedding） | **高**（BGE-M3 跨语言 sim > 0.80） |
| 搜索延迟 | ~200ms（云端 API） | ~30ms（本地 GGUF） |
| 需要网络 | 是（embedding API） | **否** |
| 数据外传风险 | 有（文档内容发送到 OpenAI） | **无** |

**混合搜索加权合并验证**：

```
轮次2 "怎么让搜索更智能" 搜索分解：

FTS5 搜索（text_weight=0.4）：
  → "搜索" 关键词匹配 → 召回 N 篇文档
  → "更智能" 无精确匹配 → 贡献有限

向量语义搜索（vector_weight=0.6）：
  → embed("怎么让搜索更智能") 与所有 chunk 向量比对
  → 语义匹配 "语义搜索"、"混合检索"、"向量嵌入" → 高分召回

加权合并：
  → 同一文档被两路搜索命中 → 分数叠加（如 0.6×0.85 + 0.4×0.70 = 0.79）
  → 仅被向量搜索命中的新文档也会出现（如 0.6×0.75 + 0.4×0 = 0.45）
  → 去重 + 按加权分数降序排列
```

**技术验证点**：
- [ ] `knowledge_search` 工具是否被 Agent 正确调用
- [ ] 轮次1 FTS5 是否命中含 "FTS5" 的文档
- [ ] 轮次2 向量搜索是否理解 "搜索更智能" ≈ "语义搜索"（语义相似度 > 0.6）
- [ ] 轮次2 混合搜索结果是否优于单独 FTS5 结果
- [ ] 轮次3 跨语言 "performance optimization" 是否匹配中文文档
- [ ] 混合结果去重：同一 doc_id 不出现两次
- [ ] 加权分数降序排列
- [ ] `min_score` 阈值过滤掉低相关结果
- [ ] BM25 归一化分数在 [0, 1]，且更相关文档分数更高
- [ ] 整个搜索过程**零网络调用**（本地 GGUF + FTS5）

**E2E 自动化测试脚本**：`scripts/test_knowledge_e2e.py`

---

### B9. 文件内容修改 — 异常退出自动回滚（3 轮）

**测试目标**：验证小搭子最核心的差异化能力 — 文件修改过程中遇到异常时，所有已修改文件**自动恢复到修改前的内容**。这是"出错自己修"能力的终极体现，也是与 OpenClaw 拉开差距的关键。

**场景故事**：

```
王姐让小搭子帮忙更新项目配置。

之前用其他 AI：
修改了 config.json（端口从 3000 改成 8080）→ 成功
接着修改 nginx.conf → 语法错误 → 报错停止
结果：config.json 已经被改了，但 nginx 没改完
      → 端口不一致 → 服务启动失败
      → 王姐要手动找回 config.json 原始内容...

现在用小搭子：
修改 config.json → 成功
修改 nginx.conf → 语法错误 → 检测到异常
→ 自动回滚：config.json 恢复为原始内容（端口仍为 3000）
→ 所有文件回到修改前状态，不会出现"改了一半"的情况
王姐看到提示："执行出错，已自动恢复所有文件到修改前状态"
```

**测试数据**：
- `data/rollback_test/config.json` — 项目配置文件（端口 3000）
- `data/rollback_test/nginx.conf` — Nginx 配置（代理到 3000）
- `data/rollback_test/README.md` — 项目说明文档

**对话流程**：

```
轮次1：用户 "帮我把这个项目的端口从 3000 改成 8080，需要同时更新 config.json、nginx.conf 和 README.md"
      → 预期：Agent 开始逐文件修改
        1. ConsistencyManager.create_snapshot() → 快照 3 个文件原始内容
        2. 修改 config.json：port 3000 → 8080 ✅
           → OperationRecord(action="file_write", before_state={"content": 原始内容})
        3. 修改 nginx.conf → 触发格式验证错误（故意设计的陷阱：注释中有特殊字符导致解析失败）
           → ErrorClassifier 分类 → 业务错误
           → 自动触发回滚：config.json 恢复原始内容（端口 3000）

轮次2（系统自动）：小搭子向用户报告
      → "修改 nginx.conf 时出错（格式解析失败），已自动恢复 config.json 到修改前状态。
         所有文件内容保持一致。是否需要我换个方式重试？"

轮次3：用户 "是的，重试一下"
      → Agent 采用新策略（PARAM_ADJUST 或 TOOL_REPLACE），成功完成全部修改
```

**预期对比**：

| 阶段 | clawdbot | 小搭子 |
|------|---------|--------|
| **修改前** | 无快照 | `ConsistencyManager.snapshot()` 备份 3 个文件原始内容 + 磁盘持久化 |
| **每次文件修改** | 直接写入，不记录 | `OperationRecord` 记录 action + before_state + 自动生成逆操作闭包 |
| **中途出错** | config.json 已被改成 8080，nginx 未改完 → **状态不一致** | 检测到错误 → `rollback()` 逆序执行所有逆操作 → config.json 恢复 3000 |
| **进程崩溃** | 文件停留在修改后状态，**不可恢复** | 快照已持久化到 `~/.xiaodazi/snapshots/`，重启后可恢复 |
| **用户感知** | "config.json 怎么被改了？我要手动改回来" | "出错了，但所有文件已恢复到修改前" |
| **重试** | 需要用户先手动恢复，再重新要求 Agent 执行 | Agent 自动重试，用户只需确认 |

**量化指标**：

| 指标 | clawdbot 预期 | 小搭子预期 |
|------|-------------|----------|
| 文件一致性保证 | ❌ 无（部分修改残留） | ✅ 事务语义（全成功或全回滚） |
| 崩溃恢复能力 | ❌ 无 | ✅ 磁盘持久化快照 |
| 回滚耗时 | N/A | < 1s（纯文件写回） |
| 快照额外开销 | 0 | ~50ms（文件读取 + JSON 序列化） |
| 用户干预次数 | 1-3 次（手动恢复 + 重试） | 0 次（全自动） |

**核心验证：文件内容比对**

```
修改前（快照中保存的原始内容）：
  config.json: {"port": 3000, "host": "localhost", ...}
  nginx.conf:  proxy_pass http://localhost:3000;
  README.md:   本服务运行在 3000 端口

config.json 被修改后（异常发生前）：
  config.json: {"port": 8080, "host": "localhost", ...}  ← 已改

异常发生 → 回滚后：
  config.json: {"port": 3000, "host": "localhost", ...}  ← ✅ 恢复原始
  nginx.conf:  proxy_pass http://localhost:3000;          ← ✅ 未被修改
  README.md:   本服务运行在 3000 端口                      ← ✅ 未被修改

验证：逐文件对比回滚后内容 === 快照中的原始内容
```

**技术验证点**：
- [ ] `ConsistencyManager.create_snapshot()` 是否正确保存了 3 个文件的原始内容
- [ ] 快照是否持久化到磁盘（`~/.xiaodazi/snapshots/{snapshot_id}.json`）
- [ ] `OperationRecord` 是否为 `file_write` 操作记录了 `before_state.content`
- [ ] `_generate_inverse_action()` 是否为 `file_write` 生成了正确的逆操作闭包
- [ ] 异常触发时 `rollback()` 是否逆序执行了所有操作日志的回滚
- [ ] 回滚后 config.json 内容是否与修改前完全一致（字节级比对）
- [ ] `emit_rollback_result()` 是否推送了回滚结果 SSE 事件到前端
- [ ] 回滚超时保护（`rollback_timeout_seconds=60`）是否生效
- [ ] `ensure_file_captured()` 动态捕获：未在初始 `affected_files` 中声明的文件，修改前是否被懒加载捕获

**进程崩溃恢复子测试（P1 扩展）**：

```
模拟场景：
  1. Agent 修改了 config.json
  2. 强制 kill 进程（模拟崩溃）
  3. 重启服务

验证：
  - 快照文件仍存在于 ~/.xiaodazi/snapshots/
  - _load_snapshot_from_disk() 能正确反序列化
  - 调用 rollback(snapshot_id) 后 config.json 恢复原始内容
  - _cleanup_expired_snapshots() 不会清理 < 24h 的快照
```

---

### B10. 文件内容修改 — 用户主动中止选择性回滚（4 轮）

**测试目标**：验证用户**主动要求中止任务**时的文件回滚能力 — 用户说"算了/取消/回退"，小搭子提供回滚选项（全部回滚 / 保留部分 / 继续剩余），用户自主决定。

**场景故事**：

```
小陈让小搭子批量替换项目文档中的公司名。

小搭子开始逐文件替换：
  file1.md ✅ 已替换
  file2.md ✅ 已替换
  file3.md 正在处理...

小陈："等等，我看了 file1 的替换结果，有些地方不应该改，算了，恢复原样吧"

之前用其他 AI：
→ Agent 停止了，但 file1.md 和 file2.md 已经被改了
→ 小陈要自己用 git checkout 恢复（如果有 git）
→ 没有 git？那就手动改回去...

现在用小搭子：
→ 弹出回滚选项面板：
  [全部回滚] 恢复 file1.md + file2.md（推荐）
  [保留已完成] 保留修改，放弃剩余
  [选择性回滚] 勾选要恢复的文件

→ 小陈选择 [全部回滚]
→ file1.md 和 file2.md 恢复到替换前的原始内容
→ "已恢复 2 个文件到修改前状态"
```

**测试数据**：`data/rollback_test/docs/`（5 个 Markdown 文件，内含旧公司名"北极星科技"）

```
docs/
├── about.md       — 公司简介（含多处"北极星科技"）
├── product.md     — 产品介绍
├── team.md        — 团队介绍
├── contact.md     — 联系方式
└── faq.md         — 常见问题
```

**对话流程**：

```
轮次1：用户 "帮我把这 5 个文档里的'北极星科技'全部替换成'星辰大海科技'"
      → 预期：Agent 开始逐文件替换
        1. ConsistencyManager.snapshot() → 快照 5 个文件
        2. 替换 about.md ✅ → OperationRecord(file_write, before_state=原始内容)
        3. 替换 product.md ✅ → OperationRecord(file_write, before_state=原始内容)
        4. 开始处理 team.md...

轮次2：用户 "等一下，算了，about.md 里有些引用不应该改，帮我恢复原样"
      → 预期：
        1. AdaptiveTerminator 检测到停止意图（wants_to_stop=true）
        2. 获取 OperationLog.get_rollback_options() → 已操作列表
        3. emit_rollback_options() → SSE 推送回滚选项到前端
        4. 前端展示三选项面板

轮次3（用户选择）：用户点击 [全部回滚]
      → 预期：
        1. ConsistencyManager.rollback(snapshot_id)
        2. 逆序回滚：product.md 恢复 → about.md 恢复
        3. 验证：5 个文件内容全部与修改前一致

轮次4：小搭子确认 "已恢复 2 个文件到修改前状态。所有文档中仍为'北极星科技'。"
```

**预期对比**：

| 阶段 | clawdbot | 小搭子 |
|------|---------|--------|
| **用户说"算了"** | Agent 停止执行，已修改文件保持修改后状态 | `wants_to_stop=true` → 暂停执行 → 推送回滚选项 |
| **回滚选项** | 无（用户自行恢复） | `emit_rollback_options()` → 前端展示 [全部回滚 / 保留 / 选择性] |
| **全部回滚** | 需要 `git checkout`（如果有 git） | `rollback()` 逆序恢复所有已修改文件 |
| **选择性回滚** | 不支持 | 用户勾选要恢复的文件 → 仅回滚选中项 |
| **回滚确认** | 无 | `emit_rollback_result()` → 前端展示回滚结果 |
| **用户心理** | "改了一半，我怎么恢复？" | "随时能反悔，改不好也不怕" |

**三种回滚选项详解**：

| 选项 | 行为 | 场景 |
|------|------|------|
| **全部回滚**（推荐） | 恢复所有已修改文件到快照状态 | "都不对，全部撤销" |
| **保留已完成** | 保留已修改的文件，放弃未完成的 | "改得挺好的，不用继续了" |
| **选择性回滚** | 用户在文件列表中勾选要恢复的 | "about.md 改得不好，其他的保留" |

**量化指标**：

| 指标 | clawdbot 预期 | 小搭子预期 |
|------|-------------|----------|
| 回滚操作用户成本 | 高（需要 git/手动/搜索替换） | 零（一键回滚） |
| 回滚响应时间 | N/A | < 500ms（内存操作日志 + 文件写回） |
| 回滚选项粒度 | 无 | 3 级（全部/保留/选择性） |
| 回滚后文件完整性 | 不保证 | 字节级一致（快照内容 === 回滚后内容） |
| 用户控制感 | 低（"被动接受后果"） | 高（"我随时可以反悔"） |

**核心验证：用户中止 + 回滚后文件内容比对**

```
初始状态（5 个文件都含"北极星科技"）：
  about.md:   "北极星科技成立于..." 
  product.md: "北极星科技旗下产品..."
  team.md:    "北极星科技核心团队..."
  contact.md: "北极星科技联系方式..."
  faq.md:     "北极星科技常见问题..."

Agent 修改了 2 个文件后用户中止：
  about.md:   "星辰大海科技成立于..."   ← 已改
  product.md: "星辰大海科技旗下产品..." ← 已改
  team.md:    "北极星科技核心团队..."   ← 未改
  contact.md: "北极星科技联系方式..."   ← 未改
  faq.md:     "北极星科技常见问题..."   ← 未改

用户选择 [全部回滚] 后：
  about.md:   "北极星科技成立于..."     ← ✅ 恢复
  product.md: "北极星科技旗下产品..."   ← ✅ 恢复
  team.md:    "北极星科技核心团队..."   ← ✅ 未动
  contact.md: "北极星科技联系方式..."   ← ✅ 未动
  faq.md:     "北极星科技常见问题..."   ← ✅ 未动

验证：5 个文件内容全部 === 初始状态
```

**技术验证点**：
- [ ] `IntentAnalyzer` 是否将"算了/取消/恢复原样"识别为 `wants_to_stop=true`
- [ ] `AdaptiveTerminator` 检测到 `wants_to_stop` 后是否暂停执行（而非直接终止）
- [ ] `OperationLog.get_rollback_options()` 是否返回了已操作的文件列表
- [ ] `emit_rollback_options()` 是否推送了 SSE 事件（含文件列表 + 三选项）
- [ ] [全部回滚] 后所有文件内容是否与快照中的原始内容一致
- [ ] [选择性回滚] 仅回滚选中文件，未选中文件保留修改后状态
- [ ] [保留已完成] 不执行回滚，直接 commit 清理快照
- [ ] 回滚操作不影响未在 `affected_files` 中的其他文件
- [ ] `emit_rollback_result()` 是否推送了回滚结果（含恢复文件列表 + 结果状态）
- [ ] 回滚日志是否记录到审计日志（谁在什么时间回滚了什么操作）

**前端交互验证（P1 扩展）**：

```
emit_rollback_options SSE 事件结构：
{
  "type": "rollback_options",
  "data": {
    "task_id": "task_xxx",
    "operations": [
      {"id": "op_abc123", "action": "file_write", "target": "docs/about.md"},
      {"id": "op_def456", "action": "file_write", "target": "docs/product.md"}
    ],
    "options": [
      {"id": "rollback_all", "label": "全部回滚（推荐）", "description": "恢复 2 个文件到修改前"},
      {"id": "keep_done",   "label": "保留已完成",       "description": "保留修改，放弃剩余"},
      {"id": "selective",   "label": "选择性回滚",       "description": "选择要恢复的文件"}
    ]
  }
}

前端 RollbackOptionsModal 展示：
┌──────────────────────────────────────────────┐
│  任务已暂停，以下文件已被修改：                │
│                                              │
│  ☑ docs/about.md    (file_write)             │
│  ☑ docs/product.md  (file_write)             │
│                                              │
│  [全部回滚]  [保留已完成]  [选择性回滚]        │
└──────────────────────────────────────────────┘
```

---

### B9 + B10 对比总结：这就是"出错不怕"的安全感

```
┌──────────────────────────────────────────────────────────────────────┐
│                                                                      │
│  其他 AI 工具修改文件：                                               │
│                                                                      │
│    修改文件A ✅ → 修改文件B ❌ → 报错停止                             │
│                                                                      │
│    结果：文件A 停留在修改后状态                                       │
│    用户：🤯 "文件A 被改了！我怎么恢复？"                              │
│          "有 git 吗？" → "git checkout -- A" → 恢复                   │
│          "没有 git？" → 手动编辑 → 可能改错 → 更多问题                │
│                                                                      │
│  ──────────────────────────────────────────────────────────────────   │
│                                                                      │
│  小搭子修改文件：                                                     │
│                                                                      │
│    [快照] → 修改文件A ✅ → 修改文件B ❌ → [自动回滚]                  │
│                                                                      │
│    结果：文件A 自动恢复到修改前                                       │
│    用户：😌 "出错了，但文件都恢复好了"                                │
│                                                                      │
│  ──────────────────────────────────────────────────────────────────   │
│                                                                      │
│  小搭子的安全承诺：                                                   │
│  ┌────────────────────────────────────────────────────────────────┐   │
│  │                                                                │   │
│  │  1. 修改前一定先拍快照（Snapshot）                              │   │
│  │  2. 每步操作都有逆操作（OperationLog）                         │   │
│  │  3. 快照写入磁盘（进程崩溃也能恢复）                           │   │
│  │  4. 出错自动回滚（无需用户干预）                               │   │
│  │  5. 用户想反悔随时能反悔（三级回滚选项）                        │   │
│  │                                                                │   │
│  │  → 这就是"工具要你会用，搭子帮你干活"的安全感                  │   │
│  │                                                                │   │
│  └────────────────────────────────────────────────────────────────┘   │
│                                                                      │
└──────────────────────────────────────────────────────────────────────┘
```

---

## 维度 C：Token 消耗量化对比

### C1. 简单问答 Token 对比（单轮）

**用户输入**：
```
今天天气怎么样？
```

**Token 消耗分解**：

| 组成部分 | clawdbot | 小搭子 | 说明 |
|---------|---------|--------|------|
| System Prompt | ~3500 tokens | ~2500 tokens（首次）/ ~300 tokens（缓存命中后） | 小搭子 `cache_control` 缓存 |
| 意图分析 | 0（无独立分析） | ~200 tokens（Haiku）/ 0（语义缓存命中） | 小搭子 `fast_mode` + 语义缓存 |
| 历史上下文 | 0（首轮） | 0（首轮） | 首轮无历史 |
| 工具定义 | ~1500 tokens | ~1000 tokens（按意图过滤工具） | 小搭子根据意图动态选择工具子集 |
| 用户消息 | ~20 tokens | ~20 tokens | 相同 |
| **Input 总计** | **~5000 tokens** | **~3700 / ~1300 tokens** | 缓存命中后节省 **74%** |
| Output | ~200 tokens | ~200 tokens | 相同 |
| **费用 (Sonnet)** | **~$0.018** | **~$0.005 (缓存命中)** | 节省 **72%** |

**重复测试（第 2 次相同问题）**：

| 指标 | clawdbot | 小搭子 |
|------|---------|--------|
| System Prompt | ~3500 tokens（重新计费） | ~300 tokens（缓存命中） |
| 意图分析 | 0 | 0（语义缓存命中，`threshold=0.90`） |
| **Input 总计** | **~5000 tokens** | **~1300 tokens** |
| **节省** | — | **74%** |

---

### C2. 多轮对话 Token 累积对比（10 轮）

**场景**：模拟 10 轮连续对话，每轮约 100 tokens 用户输入 + 200 tokens 模型输出。

**逐轮 Input Token 对比**：

| 轮次 | clawdbot input | 小搭子 input | 差异 |
|------|---------------|-------------|------|
| 1 | 5,000 | 3,700 | prompt 缓存 |
| 2 | 5,600 | 4,000 | 同上 |
| 3 | 6,400 | 4,400 | 同上 |
| 4 | 7,400 | 4,900 | 同上 |
| 5 | 8,600 | 5,500 | intent 过滤开始明显 |
| 6 | 10,000 | 6,200 | 消息裁剪 |
| 7 | 11,600 | 6,500 | _trim 保留 first 4 + last 8 |
| 8 | 13,400 | 6,800 | 上下文稳定不再增长 |
| 9 | 15,400 | 7,000 | 小搭子上下文已稳定 |
| 10 | 17,600 | 7,200 | clawdbot 持续增长 |
| **总计** | **~101,000** | **~56,200** | **节省 44%** |

**关键差异解释**：
- **clawdbot**：全量历史上下文随轮次线性增长（官方文档称上下文累积占 40-50% token）
- **小搭子**：
  - System prompt 缓存后仅计费 ~300 tokens（vs 每轮 ~3500）
  - `_trim_messages_if_needed()` 保留 first 4 + last 8，上下文有上限
  - `_filter_for_intent` 意图分析只取最近 5 条 user 消息
  - 第 7 轮后上下文趋于稳定（~6500-7200 tokens）

**月度费用估算**（假设每天 50 次对话，每次平均 5 轮）：

| 指标 | clawdbot | 小搭子 |
|------|---------|--------|
| 日均 Input Tokens | ~1.5M | ~0.8M |
| 月度 Input Tokens | ~45M | ~24M |
| 月度费用 (Sonnet) | ~$45-67 | ~$24-36 |
| **月度节省** | — | **~$21-31 (46%)** |

---

### C3. 复杂工具调用 Token 对比（单轮）

**用户输入**：
```
搜索最近三天关于 LLM Agent 的论文，找到最相关的 5 篇，整理成表格
```

**Token 消耗分解**：

| 阶段 | clawdbot | 小搭子 | 说明 |
|------|---------|--------|------|
| 意图分析 | 0 | ~200 tokens (Haiku) | 识别为 complex → 启用 plan-todo |
| 规划 | ~2000（LLM 隐式规划） | ~1500（plan-todo 显式规划） | 小搭子后续轮只看进度 |
| 工具调用1：搜索 | ~3000 | ~3000 | 相同 |
| 工具输出1 | ~5000（全量 JSON 存入上下文） | ~2000（tool_result compaction 裁剪） | 小搭子裁剪大型输出 |
| 工具调用2：筛选 | ~8000（含工具输出1全量） | ~5000（输出1已裁剪） | 累积差异 |
| 工具输出2 | ~3000 | ~1500 | 同上 |
| 最终输出 | ~1500 | ~1500 | 相同 |
| **总计** | **~22,500** | **~14,700** | **节省 35%** |

**回溯场景下的额外对比**（假设工具调用2失败需重试）：

| 指标 | clawdbot | 小搭子 |
|------|---------|--------|
| 重试策略 | 可能触发 compaction → 丢失工具1结果 → 需重新搜索 | RVR-B 有状态回溯，不重复工具1 |
| 重试额外开销 | ~10,000 tokens（重新搜索 + 处理） | ~3,000 tokens（仅重试工具2） |
| **含重试总计** | **~32,500** | **~17,700** | **节省 46%** |

---

## 维度 D：场景差异化

### D1. 24/7 后台自动化 — clawdbot 强项

**用户输入**：
```
每天早上8点给我发一份今日待办摘要到 Telegram
```

**对比**：

| 指标 | clawdbot | 小搭子 |
|------|---------|--------|
| 定时任务 | **原生 cron 支持** | `scheduled_task` 工具（功能较基础） |
| 消息通道 | **WhatsApp/Telegram/Discord/Slack/iMessage** | 仅桌面应用内通知 |
| 24/7 运行 | **守护进程 + 心跳监控** | 需要应用保持打开 |

**结论**：此场景 **clawdbot 明确胜出**。小搭子定位"面对面桌面交互"，不与 clawdbot 在后台自动化上竞争。

**差异化定位**：
- clawdbot = 24/7 后台管家（远程控制、消息驱动）
- 小搭子 = 桌面搭子（面对面交互、环境感知、零门槛）

---

### D2. 小白用户首次安装 — 小搭子强项

**场景**：完全不懂技术的用户首次尝试安装使用 AI Agent。

**安装步骤对比**：

| 步骤 | clawdbot | 小搭子 |
|------|---------|--------|
| 1 | 安装 Node.js 22+（需理解 nvm/homebrew） | 下载安装包 |
| 2 | `npm install -g openclaw`（命令行操作） | 双击安装 |
| 3 | `openclaw onboard`（CLI 向导） | 打开应用 |
| 4 | 配置 API Key（需注册 Anthropic 账号） | 选择模型（UI 引导） |
| 5 | 绑定消息渠道（Telegram/Discord 等） | 开始对话 |
| 6 | 可选：配置 MEMORY.md / SOUL.md | — |

**量化对比**：

| 指标 | clawdbot | 小搭子 |
|------|---------|--------|
| 安装步骤 | 5-6 步 | 2-3 步 |
| 所需技术知识 | Node.js / npm / 命令行 | 无 |
| 首次对话时间 | 20-60 分钟 | 5 分钟 |
| 安装失败率 | 较高（Node 版本/npm 权限/网络问题） | 极低 |

**结论**：此场景 **小搭子压倒性胜出**。

---

### D3. 多步骤内容创作 — 对等比较

**用户输入**：
```
帮我写一篇关于远程办公的公众号文章，要求：
1. 先搜索最新趋势数据
2. 用活泼的语气
3. 2000字左右
4. 配上合适的小标题
```

**对比**：

| 指标 | clawdbot | 小搭子 |
|------|---------|--------|
| 任务分解 | LLM 自行分解（能力足够） | `plan-todo` 显式规划 + 进度追踪 |
| 搜索能力 | MCP web_search（生态丰富） | `trend-spotter` / `paper-search` |
| 写作质量 | 依赖模型（相同模型则相当） | 同模型 + `writing-assistant` Skill 规则 |
| 进度可见 | 无结构化进度 | `ProgressTransformer` → SSE 事件 |
| 风格学习 | 需手动写入 memory | `style-learner` Skill 自动学习 |

**结论**：基本对等。小搭子在进度可见性和风格自动学习上略有优势，clawdbot 在搜索工具生态上更丰富。

---

### D4. 连续错误恢复 — 小搭子强项

**用户输入**：
```
帮我把这个 CSV 文件转换成 Excel，添加图表，然后导出为 PDF
```

**场景设计**：
- 步骤1：CSV → Excel（成功）
- 步骤2：添加图表（失败：数据列类型不匹配）
- 步骤3：导出 PDF（依赖步骤2）

**对比**：

| 阶段 | clawdbot | 小搭子 |
|------|---------|--------|
| 步骤2失败 | LLM 报错，可能 auto-compaction | `ErrorClassifier` → `business_logic` → `PARAM_ADJUST` 回溯 |
| 回溯策略 | 无系统化回溯，LLM 自行决定 | `BacktrackManager`：尝试调整图表数据类型/换图表类型 |
| 失败记录 | compaction 可能丢失"步骤2已失败"的上下文 | `RVRBState.failed_tools` 记录，避免重复尝试 |
| 回溯次数 | 无限制（可能无限重试） | `max_backtrack_attempts=3`（有上限） |
| 最终结果 | 可能需要 2-3 轮用户干预 | 大概率自动恢复 |

**Token 消耗对比**（含错误恢复）：

| 指标 | clawdbot | 小搭子 |
|------|---------|--------|
| 正常路径 | ~15K tokens | ~12K tokens |
| 错误恢复 | +15-20K（可能重复步骤1） | +5-8K（仅重试步骤2） |
| **总计** | **~30-35K** | **~17-20K** |

---

### D5. 状态回滚安全网 — 小搭子强项

**测试数据**：`data/mixed_files/`

**用户输入**：
```
帮我把这些文件按日期重命名，格式为 YYYY-MM-DD_原文件名
```

**场景设计**：重命名到第 15 个文件时遇到文件锁定错误（或权限问题）。

**对比**：

| 阶段 | clawdbot | 小搭子 |
|------|---------|--------|
| **执行前** | 无快照 | `ConsistencyManager.snapshot()` 记录初始文件名 |
| **执行中** | 逐个重命名 | 逐个重命名 + `OperationRecord` 记录每次操作 |
| **错误发生（第15个）** | 14 个已重命名，状态不一致 | 检测到错误 → `emit_rollback_options()` 推送选项 |
| **用户选择** | 只能手动恢复 | 选择"全部回滚" → 14 个文件恢复原名；或"继续剩余" |
| **回滚机制** | 无 | `OperationRecord` 含逆操作闭包（`file_rename` 的逆操作是反向重命名） |

**安全感对比**：

| 指标 | clawdbot | 小搭子 |
|------|---------|--------|
| 文件操作可逆性 | 不可逆（特别是删除） | 快照 + 逆操作日志 |
| 用户控制感 | 低（"删了就删了"） | 高（"随时可以回滚"） |
| 适合小白用户 | 有风险 | 安全可靠 |

---

### D6. 离线知识问答 — 小搭子强项

**场景**：用户在飞机上（无网络），需要查找之前整理的工作文档。

**用户输入**：
```
帮我找一下之前写的架构设计方案，里面有关于缓存策略的部分
```

**对比**：

| 指标 | clawdbot | 小搭子 |
|------|---------|--------|
| **离线搜索** | ❌ embedding 需要 OpenAI API → **无网络时搜索失败** | ✅ 本地 GGUF 模型 + FTS5 → **完全离线可用** |
| **降级策略** | 可能降级到纯文本 grep（无语义理解） | FTS5 始终可用 + 向量搜索离线可用 → **双层保障** |
| **隐私保护** | 文档内容发送到云端做 embedding | **数据零外传**，所有计算在本机完成 |
| **响应速度** | ~200ms（网络 RTT 主导） | **~30ms**（本地 CPU 推理） |
| **模型成本** | 按调用计费（$0.02/1M tokens） | **零成本**（模型一次下载，永久本地使用） |

**量化指标**：

| 指标 | clawdbot 预期 | 小搭子预期 |
|------|-------------|----------|
| 离线可用 | ❌ 不可用 | ✅ 完全可用 |
| 搜索延迟 | 200ms+ | **30ms** |
| 每月 embedding 费用 | ~$1-5 | **$0** |
| 数据外传 | 每次搜索发送查询到 OpenAI | **零外传** |
| 模型大小 | N/A（云端） | 424MB 本地（一次性下载） |

**结论**：此场景**小搭子压倒性胜出**。本地 GGUF 模型是小搭子"桌面 AI 搭子"定位的核心支撑——你的数据永远只在你的电脑上。

**技术验证点**：
- [ ] 断网环境下 `knowledge_search` 工具是否正常返回结果
- [ ] `create_embedding_provider("auto")` 在无网络时是否选择 GGUF 本地提供商
- [ ] 搜索延迟 < 50ms（本地 GGUF embedding + FTS5 + sqlite-vec）
- [ ] 搜索结果质量与在线时无显著差异

---

## 维度 E：电脑操作长程任务

> **测试目标**：两端均具备 computer_use 能力（OpenClaw 的 Lobster 工具 / 小搭子的 peekaboo），都能操控桌面应用。本维度**不比"能不能做"，而比"长程复杂任务谁做得更稳"** — 上下文管理、结构化错误恢复、进度追踪、回滚安全网。
>
> **背景**：OpenClaw 在长程任务上存在已知瓶颈 —
> [Issue #1084](https://github.com/clawdbot/clawdbot/issues/1084): auto-compaction 在工具失败后丢失上下文 → 无限重试循环；
> [Issue #1577](https://github.com/clawdbot/clawdbot/issues/1577): 长时间运行命令导致 session history 损坏。
> 这些恰好是长程 GUI 任务（30-100 步操作）的致命弱点。
>
> **核心对比维度**：
>
> | 维度 | OpenClaw | 小搭子 |
> |------|---------|--------|
> | GUI 能力 | ✅ Lobster（computer_use） | ✅ peekaboo（computer_use） |
> | 长程上下文 | auto-compaction 可能丢失已完成步骤 | scratchpad 卸载 + plan-todo 追踪 |
> | 错误恢复 | ad-hoc 重试（可能死循环） | ErrorClassifier + BacktrackManager |
> | 进度可见 | 基础 CLI 状态 | SSE 进度事件 + HITL 检查点 |
> | 回滚安全 | 无 | ConsistencyManager + OperationRecord |

### E1. 跨应用调研 → 整理 → 报告生成（12 轮长程）

**测试目标**：验证 Agent 在浏览器、表格应用、文本编辑器三个桌面应用之间连续切换、执行 30-40 步 GUI 操作时的**上下文存活能力**。核心差异不在"能不能打开 Excel"，而在"做到第 30 步时还记不记得第 5 步采集的数据"。

**场景故事**：

```
小李要写一份竞品分析报告，需要：
1. 打开浏览器搜索 3 家竞品的产品信息
2. 把关键数据整理到 Numbers/Excel 表格里
3. 最后在文本编辑器里写一份简短的分析报告

两个 Agent 都能做这件事。但做到 Phase 3 写报告时——
OpenClaw：可能因 auto-compaction 丢失 Phase 1 的采集数据 → 报告引用的数据与表格不一致
小搭子：Phase 1 数据存入 scratchpad → Phase 3 按需读取 → 数据一致性有保证
```

**用户输入**：
```
帮我调研一下"智能笔记应用"这个赛道，搜 Notion、Obsidian、Logseq 这三家的核心功能和定价，
把数据整理到一个表格里，最后写一份 500 字的对比分析报告保存到桌面
```

**对话流程**（12 轮，Agent 内部执行 30-40 步 GUI 操作）：

```
轮次1：用户下达任务
      → 意图分析：task_type=complex_workflow, complexity=complex, needs_plan=true
      → plan-todo 生成 4 阶段计划：
        Phase 1: 浏览器调研（3 个竞品）
        Phase 2: 数据整理到表格
        Phase 3: 撰写分析报告
        Phase 4: 保存并汇报

轮次2-4：Phase 1 — 浏览器调研
      → 截图 → 识别当前桌面状态
      → 打开浏览器 → 搜索 "Notion 功能 定价" → 截图 → 提取关键信息
      → 新标签页 → 搜索 "Obsidian 功能 定价" → 截图 → 提取
      → 新标签页 → 搜索 "Logseq 功能 定价" → 截图 → 提取
      → 每个竞品提取：产品名、核心功能（3-5 个）、定价模式、目标用户
      → ⭐ 关键：提取数据写入 scratchpad/research_data.json（不留在上下文）
      → 进度推送：SSE "Phase 1 完成：已收集 3 家竞品信息"

轮次5-7：Phase 2 — 数据整理到表格
      → 打开 Numbers / Excel
      → 创建新表格 → 设置表头 → 从 scratchpad 读取数据 → 逐行填入
      → Cmd+S 保存到桌面
      → 进度推送："Phase 2 完成：表格已保存到桌面"

轮次8-10：Phase 3 — 撰写分析报告
      → 打开文本编辑器
      → ⭐ 关键：从 scratchpad 重新加载 research_data.json → 引用数据写报告
      → 报告结构：背景 → 功能对比 → 定价对比 → 推荐结论
      → 数据与表格完全一致（同源 scratchpad）

轮次11：Phase 4 — 保存并验证
      → Cmd+S 保存报告到桌面
      → 截图验证：桌面上是否有两个新文件（表格 + 报告）

轮次12：向用户汇报
```

**预期对比**：

| 指标 | OpenClaw | 小搭子 |
|------|---------|--------|
| **GUI 能力** | ✅ Lobster 操作浏览器/表格/编辑器 | ✅ peekaboo 操作相同应用 |
| **Phase 1 数据存储** | 留在上下文 messages 中（随轮次膨胀） | 写入 scratchpad 文件（上下文只保留摘要） |
| **Phase 3 数据引用** | 可能被 compaction 裁剪 → 数据丢失或不完整 | 从 scratchpad 按需加载 → 数据完整 |
| **跨 Phase 一致性** | ⚠️ 无保证（compaction 不可控） | ✅ 同源 scratchpad 保证一致 |
| **30 步后上下文状态** | 可能触发 compaction → 丢失 Phase 1 截图/OCR 数据 | scratchpad 卸载截图 → 上下文保持精简 |
| **进度追踪** | 无结构化进度 | plan-todo + SSE 进度事件 |
| **长程任务中断恢复** | session 可能损坏 ([#1577](https://github.com/clawdbot/clawdbot/issues/1577)) | plan-todo 记录完成状态 → 从断点继续 |

**量化指标**：

| 指标 | OpenClaw 预期 | 小搭子预期 |
|------|-------------|----------|
| 任务完成率 | ~70%（长程 compaction 风险） | ~90% |
| 报告-表格数据一致性 | ⚠️ 可能不一致 | ✅ 一致（同源 scratchpad） |
| GUI 操作步数 | 30-40 步 | 30-40 步 |
| Token 消耗 | ~50K-80K（截图数据累积在上下文） | ~40K-60K（截图卸载到 scratchpad） |
| 用户干预次数 | 0-2（compaction 后可能需纠正） | 0 |

**技术验证点**：
- [ ] `plan-todo` 是否生成了 4 阶段计划并按序执行
- [ ] Phase 1 采集数据是否写入 scratchpad（而非留在上下文）
- [ ] Phase 3 是否从 scratchpad 加载数据（而非依赖上下文历史）
- [ ] 报告中引用的数据与表格完全一致
- [ ] 30-40 步操作后上下文 token 数是否稳定（未因截图累积膨胀）
- [ ] 进度 SSE 事件是否在每个 Phase 完成时推送
- [ ] 中途中断后能否从 plan-todo 的已完成 Phase 继续

---

### E2. 日程创建 + 文档协同 + 提醒通知（8 轮长程）

**测试目标**：验证 Agent 从项目文档提取里程碑 → 批量创建日历事件 → 为每个里程碑准备待办清单 → 设置到期提醒的多应用协同工作流。核心差异在于**批量 GUI 操作中的错误恢复** — 创建第 4 个日历事件时出错，前 3 个怎么办？

**场景故事**：

```
小张接手一个新项目，项目计划文档里有 6 个里程碑。
他需要：逐个加到日历 → 每个写一份待办清单 → 设置到期前提醒。

两个 Agent 都能操作日历应用。但创建第 4 个事件时日历应用报"日期冲突"——
OpenClaw：可能触发 compaction → 忘了前 3 个已创建 → 从头重试 → 重复创建
小搭子：OperationRecord 记录前 3 个已完成 → 只处理第 4 个冲突 → HITL 确认 → 继续
```

**测试数据**：`data/project_plan.md`

```markdown
# Q1 产品发布计划

## 里程碑

| # | 里程碑 | 截止日期 | 负责人 | 关键交付物 |
|---|--------|---------|--------|----------|
| 1 | 需求评审完成 | 2026-02-20 | 产品组 | PRD 文档终稿 |
| 2 | UI 设计稿交付 | 2026-03-05 | 设计组 | Figma 原型 |
| 3 | 后端 API 联调 | 2026-03-20 | 开发组 | API 文档 + 联调报告 |
| 4 | 内测版本发布 | 2026-04-01 | 测试组 | 测试报告 |
| 5 | 用户灰度测试 | 2026-04-15 | 运营组 | 灰度数据分析 |
| 6 | 正式上线 | 2026-04-30 | 全体 | 上线 checklist |
```

**用户输入**：
```
帮我把这个项目计划里的 6 个里程碑都加到日历里，每个里程碑写一份简短的待办清单保存到桌面，
并且设好到期前 3 天的提醒通知
```

**对话流程**（8 轮）：

```
轮次1：用户下达任务
      → 意图分析：complex_workflow, complexity=complex, needs_plan=true
      → plan-todo 生成 3 阶段：
        Phase 1: 解析项目文档 → 提取 6 个里程碑
        Phase 2: 批量创建日历事件 + 设置提醒（6 次 GUI 操作循环）
        Phase 3: 为每个里程碑创建待办清单文档

轮次2：Phase 1 — 解析文档
      → 读取 project_plan.md → 结构化提取 6 条里程碑
      → 数据写入 scratchpad/milestones.json
      → 向用户确认："已提取 6 个里程碑（2月20日~4月30日），开始创建日历事件？"

轮次3：用户 "开始"

轮次4-5：Phase 2 — 批量创建日历事件
      → 打开日历应用（Calendar.app）
      → 循环 6 次：
        1. 导航到对应日期
        2. 创建全天事件 → 输入标题"[里程碑] 需求评审完成"
        3. 设置提醒：到期前 3 天
        4. 保存
        5. OperationRecord 记录（action=calendar_create, event_id, before_state=无）
        6. 截图验证事件已出现
      → 第 4 个里程碑（4月1日）：日历提示"与清明节假期冲突"弹窗
        → 截图识别弹窗 → 分析类型（冲突警告，非阻断）
        → HITL 确认："4月1日与清明节冲突，是否仍然创建？"

轮次6：用户 "创建吧，改成 4月2日"
      → 修改日期 → 创建成功
      → 继续第 5、6 个里程碑
      → 进度推送："6/6 日历事件已创建 ✅"

轮次7：Phase 3 — 创建待办清单文档
      → 打开文本编辑器
      → 从 scratchpad 加载里程碑数据
      → 为每个里程碑生成待办清单：
        ```
        # 里程碑1: 需求评审完成（2026-02-20）
        - [ ] 收集各方需求反馈
        - [ ] 确认 PRD 终稿
        - [ ] 发起评审会议邀请
        - [ ] 输出评审结论文档
        ```
      → 保存到桌面：Q1项目里程碑待办.md

轮次8：汇报
      → "已完成：
         ✅ 6 个里程碑日历事件已创建（含提前 3 天提醒）
            ⚠️ 第 4 个已按您要求调整到 4月2日
         ✅ 待办清单已保存到桌面（Q1项目里程碑待办.md）
         如需修改任何日程或待办项，随时告诉我"
```

**预期对比**：

| 指标 | OpenClaw | 小搭子 |
|------|---------|--------|
| **文档解析** | ✅ Lobster 打开文档 + LLM 解析 | ✅ peekaboo 打开文档 + LLM 解析 |
| **批量日历操作** | ✅ Lobster 逐个创建 | ✅ peekaboo 逐个创建 |
| **第 4 个事件冲突** | LLM 自行决定（可能自动跳过或重试） | HITL 弹窗 → 用户决定 → 按用户指示调整 |
| **冲突后上下文** | ⚠️ compaction 可能丢失"已创建 3 个"的记录 → 从头创建 → 日历出现重复事件 | OperationRecord 记录 3 个已完成 → 仅处理第 4 个 |
| **重复创建防护** | ❌ 无（compaction 丢失历史 → 重复） | ✅ OperationRecord 去重检查 |
| **提醒设置** | ✅ 逐个设置 | ✅ 逐个设置 |
| **跨 Phase 数据** | 上下文中传递（可能被裁剪） | scratchpad 持久传递 |
| **回滚能力** | ❌ 无法批量删除已创建事件 | ✅ OperationRecord 逆操作 → 一键清理所有已创建事件 |

**量化指标**：

| 指标 | OpenClaw 预期 | 小搭子预期 |
|------|-------------|----------|
| 任务完成率 | ~75%（冲突恢复不稳定） | ~95% |
| 事件重复创建风险 | ⚠️ 高（compaction 后不知道已创建了哪些） | ✅ 无（OperationRecord 精确追踪） |
| GUI 操作步数 | 50-60 步 | 50-60 步 |
| 用户干预次数 | 0-3（重复事件需手动清理） | 1（仅冲突确认） |
| 回滚操作 | 手动逐个删除 | 一键批量清理 |

**技术验证点**：
- [ ] 文档解析：6 个里程碑是否全部正确提取（日期、标题、负责人）
- [ ] 日历操作：6 个事件是否全部正确创建（标题、日期、提醒）
- [ ] OperationRecord：每个 `calendar_create` 是否记录了 event 信息
- [ ] 冲突处理：日期冲突弹窗是否触发 HITL 确认（而非自动决定）
- [ ] 无重复事件：6 个里程碑 → 恰好 6 个日历事件（不多不少）
- [ ] 提醒通知：每个事件是否设置了"提前 3 天"提醒
- [ ] 待办清单质量：是否根据里程碑内容生成了有意义的待办项（非模板化）
- [ ] 跨 Phase 数据一致性：待办清单中的日期/标题 === 日历事件
- [ ] 回滚测试：用户说"取消所有日程"后是否能批量清理

---

### E3. 表单自动填写与数据迁移（10 轮长程）

**测试目标**：验证 Agent 从本地文件提取数据 → 在浏览器 GUI 中逐字段填写表单的能力。80-100 步 GUI 操作，是本维度操作密度最高的用例。核心差异在于**第 3 条填写失败时，前 2 条的状态管理** — OpenClaw 的 compaction 可能让 Agent 忘记已填了哪些。

**场景故事**：

```
财务小王每月要把 Excel 里的报销记录逐条录入到 OA 报销表单中。
5 条记录 × 8 个字段 = 40 次字段输入，每条还有下拉框选择、日期控件操作。

两个 Agent 都能操作浏览器填表。但填到第 3 条时下拉框选项对不上——
OpenClaw：重试 → compaction → 忘了已填 2 条 → 从第 1 条重新填 → 数据重复
小搭子：OperationRecord 记录已填 2 条 → 只处理第 3 条异常 → HITL 确认 → 继续
```

**测试数据**：`data/expense_records.xlsx`

```
| 日期 | 类别 | 金额 | 供应商 | 项目 | 部门 | 备注 | 发票号 |
|------|------|------|--------|------|------|------|--------|
| 2026-01-15 | 差旅-交通 | 356.00 | 某航空 | 项目A | 技术部 | 北京出差 | INV-001 |
| 2026-01-18 | 差旅-住宿 | 580.00 | 某酒店 | 项目A | 技术部 | 北京出差 | INV-002 |
| 2026-01-22 | 办公用品 | 128.50 | 某商城 | 日常 | 技术部 | 键盘 | INV-003 |
| 2026-02-01 | 餐饮招待 | 445.00 | 某餐厅 | 项目B | 技术部 | 客户午餐 | INV-004 |
| 2026-02-05 | 差旅-交通 | 89.00 | 某打车 | 项目B | 技术部 | 机场接送 | INV-005 |
```

**用户输入**：
```
帮我把桌面上的 expense_records.xlsx 里的报销记录，逐条填到浏览器里已经打开的 OA 报销表单中
```

**对话流程**（10 轮）：

```
轮次1：用户下达任务
      → 意图分析：complex_workflow + HITL（涉及提交操作）
      → plan-todo：读取数据 → 逐条填写 → 汇总确认 → 提交

轮次2：Phase 1 — 读取 Excel 数据
      → 解析 expense_records.xlsx → 结构化 5 条记录
      → 数据写入 scratchpad/expense_data.json
      → 向用户确认："已读取 5 条报销记录，总金额 ¥1,598.50。开始填写？"

轮次3：用户 "开始吧"

轮次4-8：Phase 2 — 逐条填写（每条 15-20 步 GUI 操作）
      → 切换到浏览器 OA 表单页面
      → 第 1 条：截图识别字段位置 → 逐字段填写 → 截图验证 → "保存并新增"
        → OperationRecord(action=form_submit, record_id=1, data={...})
      → 进度："第 1/5 条已填写 ✅"
      → 第 2 条：同上 → "第 2/5 条 ✅"
      → 第 3 条："类别"下拉框找不到"办公用品"
        → 截图分析 → 发现选项名是"办公耗材"
        → HITL 确认："'办公用品'对应系统中的'办公耗材'，是否选择？"

轮次9：用户 "对的"
      → 继续第 3-5 条 → 全部完成

轮次10：汇报
      → "已完成 5 条报销记录填写：
         ✅ 1. 差旅-交通 ¥356.00
         ✅ 2. 差旅-住宿 ¥580.00
         ✅ 3. 办公耗材 ¥128.50（已自动匹配）
         ✅ 4. 餐饮招待 ¥445.00
         ✅ 5. 差旅-交通 ¥89.00
         合计 ¥1,598.50，所有记录已保存未提交。需要我点提交吗？"
```

**预期对比**：

| 指标 | OpenClaw | 小搭子 |
|------|---------|--------|
| **数据读取** | ✅ 工具/Lobster 解析 Excel | ✅ Skill 解析 + scratchpad 存储 |
| **表单填写** | ✅ Lobster 逐字段操作 | ✅ peekaboo 逐字段操作 |
| **下拉框匹配** | LLM 自行判断（可能选错或跳过） | 截图 → LLM 语义匹配 → HITL 确认 |
| **第 3 条失败后** | ⚠️ 重试触发 compaction → 丢失"已填 2 条"记录 → 从头重填 | OperationRecord 记录已完成 → 仅重试第 3 条 |
| **数据重复风险** | ⚠️ 高（compaction 后不知道已提交了哪些） | ✅ 无（OperationRecord 去重） |
| **提交保护** | LLM 可能自行点提交 | HITL 强制确认 |
| **进度可见** | 无 | 每条 SSE 推送 |
| **批量撤销** | ❌ 手动逐条删除 | ✅ OperationRecord 逆操作 |

**量化指标**：

| 指标 | OpenClaw 预期 | 小搭子预期 |
|------|-------------|----------|
| 任务完成率 | ~70%（80+ 步中 compaction 风险高） | ~90% |
| 数据重复提交风险 | ⚠️ 有 | ✅ 无 |
| GUI 操作步数 | 80-100 步 | 80-100 步 |
| Token 消耗 | ~60K-100K（截图累积 + 可能重试全量） | ~40K-60K（scratchpad 卸载 + 仅重试失败条目） |
| 用户干预 | 0-3 次（重复/遗漏需手动处理） | 1 次（仅语义匹配确认） |

**技术验证点**：
- [ ] Excel 数据解析：5 条记录 + 8 个字段是否全部正确
- [ ] 表单字段定位：截图是否正确识别每个字段位置
- [ ] 下拉框操作：点击 → 展开 → 识别选项列表 → 选择目标项
- [ ] 语义匹配："办公用品"→"办公耗材"是否 HITL 确认
- [ ] OperationRecord：每条提交后是否记录（防重复提交）
- [ ] 进度追踪：每条完成后是否推送 SSE
- [ ] 填写验证：每条填完后截图对比是否正确
- [ ] 提交保护：最终提交必须 HITL 确认
- [ ] 错误恢复：第 3 条失败 → 不影响已填的 1、2 条 → 仅重试第 3 条

---

### E4. 长程 GUI 任务中途异常恢复（6 轮长程）

**测试目标**：验证长程 GUI 任务执行中遇到应用弹窗/卡死/崩溃时的**结构化恢复能力**。两端都有 computer_use，都能检测截图异常。差异在于：OpenClaw 恢复后可能因 compaction 丢失"已完成列表" → 重复操作或遗漏；小搭子用 OperationRecord 精确断点续做。

**场景故事**：

```
小搭子正在帮用户批量重命名照片文件夹里的 50 张照片。
处理到第 20 张时，系统弹出"磁盘空间不足"弹窗，遮挡了操作区域。

两个 Agent 都能识别弹窗并关闭它。关键差异在"关闭弹窗之后"——
OpenClaw：关闭弹窗 → 继续执行 → 但 compaction 可能已裁剪"已重命名 1-20"的记录
         → Agent 不确定从哪里继续 → 可能从头开始 → 前 20 个文件被重命名两次
小搭子：关闭弹窗 → 查询 OperationRecord → 确认已完成 20 个 → 精确从第 21 个继续
```

**测试数据**：`data/photos/`（50 张图片文件）

**用户输入**：
```
帮我把照片文件夹里的图片按拍摄日期重命名，格式是"YYYY-MM-DD_序号.jpg"
```

**对话流程**（6 轮）：

```
轮次1：用户下达任务
      → plan-todo：扫描文件 → 提取日期 → 批量重命名
      → ConsistencyManager.snapshot() 记录 50 个文件的原始名称

轮次2-3：Phase 1 — 正常执行
      → 打开 Finder → 导航到照片文件夹
      → 逐个重命名 → 第 1-20 个成功
      → OperationRecord 逐条记录（file_rename, old_name, new_name）
      → 进度："已重命名 10/50"、"已重命名 20/50"

轮次4：Phase 2 — 异常检测与恢复
      → 第 21 个操作时截图 → 检测到系统弹窗"磁盘空间不足"
      → 异常处理：
        1. 识别弹窗类型（系统警告，非致命）
        2. 点击"好"按钮关闭
        3. 截图验证 Finder 恢复正常
        4. ⭐ 查询 OperationRecord → 确认已完成 20 个 → 从第 21 个继续
      → 通知用户："遇到磁盘空间提示（已关闭），继续处理剩余 30 个"

轮次5：Phase 3 — 断点续做
      → 从第 21 个精确继续 → 全部完成
      → 进度："30/50"、"40/50"、"50/50 ✅"

轮次6：汇报
      → "已完成 50 张照片重命名 ✅
         ⚠️ 过程中遇到一次系统弹窗（已自动处理）
         如需恢复原始文件名，随时告诉我"
```

**预期对比**：

| 阶段 | OpenClaw | 小搭子 |
|------|---------|--------|
| **正常执行** | ✅ Lobster + exec 操作文件 | ✅ peekaboo + exec 操作文件 |
| **弹窗检测** | ✅ 截图识别弹窗 | ✅ 截图识别弹窗 |
| **关闭弹窗** | ✅ 点击关闭 | ✅ 点击关闭 |
| **恢复后定位** | ⚠️ 不确定从哪继续（compaction 可能丢失已完成列表） | ✅ 查询 OperationRecord → 精确第 21 个 |
| **重复操作风险** | ⚠️ 可能重命名已处理的文件（二次重命名 → 文件名错误） | ✅ 无（精确断点） |
| **Session 稳定性** | ⚠️ 长命令可能触发 session 损坏 ([#1577](https://github.com/clawdbot/clawdbot/issues/1577)) | ✅ 稳定（plan-todo + OperationRecord） |
| **回滚能力** | ❌ 无批量回滚 | ✅ snapshot → 一键恢复所有原始文件名 |

**异常场景矩阵**（两端对比）：

| 异常类型 | OpenClaw 恢复 | 小搭子恢复 |
|---------|-------------|-----------|
| 系统弹窗 | 截图识别 → 关闭 → 继续（但可能重复） | 截图识别 → 关闭 → 查 OperationRecord → 精确续做 |
| 应用无响应 | kill → 重启 → 从头开始 | kill → 重启 → 从 OperationRecord 断点续做 |
| 应用崩溃 | 重启 → 从头开始 | 重启 → 从 snapshot + OperationRecord 恢复 |
| 权限弹窗 | LLM 自行决定 | HITL → 用户确认授权 |
| 长时间无响应 | session 可能损坏 | AdaptiveTerminator 超时 → 保存状态 → 重试 |

**量化指标**：

| 指标 | OpenClaw 预期 | 小搭子预期 |
|------|-------------|----------|
| 弹窗检测 | ✅ 成功 | ✅ 成功 |
| 断点精确度 | ⚠️ ±5（可能重复或遗漏 1-5 个） | ✅ 精确（OperationRecord 逐条追踪） |
| 异常恢复后完成率 | ~80%（可能重复/遗漏） | ~95%（精确续做） |
| 回滚能力 | ❌ 需手动逐个恢复 | ✅ 一键全部恢复 |
| 异常处理耗时 | 5-10 秒 | 3-5 秒 |

**技术验证点**：
- [ ] `ConsistencyManager.snapshot()` 任务开始前保存 50 个原始文件名
- [ ] `OperationRecord` 逐条记录 `file_rename`（old_name → new_name）
- [ ] 弹窗检测：截图是否区分出系统弹窗
- [ ] 断点精确性：恢复后是否**精确**从第 21 个继续（不重复 1-20）
- [ ] 进度连续性：异常恢复后进度 20 → 21（不重置为 1）
- [ ] 回滚功能：用户说"恢复原样"→ 50 个文件全部恢复原名
- [ ] 二次重命名防护：已重命名的文件不被再次操作
- [ ] 异常日志：弹窗事件记录到审计日志

---

### E1-E4 核心差异总结

```
┌──────────────────────────────────────────────────────────────────────┐
│                                                                      │
│  维度 E 的核心洞察：                                                  │
│                                                                      │
│  GUI 能力本身不是差异化 — 两端都有 computer_use                       │
│                                                                      │
│  真正的差异在于：长程任务执行的「可靠性基础设施」                       │
│                                                                      │
│  ┌────────────────────────────────────────────────────────────────┐   │
│  │                                                                │   │
│  │  OpenClaw (Lobster)              小搭子 (peekaboo)              │   │
│  │  ────────────────                ─────────────────              │   │
│  │                                                                │   │
│  │  GUI 操作   ✅ 能做              ✅ 能做                        │   │
│  │  短任务     ✅ 表现好            ✅ 表现好                      │   │
│  │                                                                │   │
│  │  ---- 以下是长程任务（30-100 步）的分水岭 ----                  │   │
│  │                                                                │   │
│  │  上下文管理  ⚠️ compaction 丢数据  ✅ scratchpad 持久存储       │   │
│  │  错误恢复   ⚠️ ad-hoc 重试       ✅ ErrorClassifier 分类恢复   │   │
│  │  断点续做   ⚠️ 可能重复/遗漏     ✅ OperationRecord 精确       │   │
│  │  进度追踪   ❌ 无结构化进度       ✅ plan-todo + SSE 事件       │   │
│  │  回滚安全   ❌ 无                 ✅ snapshot + 逆操作           │   │
│  │  会话稳定   ⚠️ #1577 session 损坏 ✅ 稳定                      │   │
│  │  死循环风险  ⚠️ #1084 重试死循环  ✅ max_backtrack + 分类       │   │
│  │                                                                │   │
│  │  类比：                                                        │   │
│  │  OpenClaw = 会开车，但没有安全带、没有导航、没有行车记录仪       │   │
│  │  小搭子   = 会开车，而且有安全带、导航、行车记录仪、自动刹车     │   │
│  │                                                                │   │
│  │  路况好时（短任务）两者都能安全到达                              │   │
│  │  路况差时（长程复杂任务）安全设施决定成败                        │   │
│  │                                                                │   │
│  └────────────────────────────────────────────────────────────────┘   │
│                                                                      │
└──────────────────────────────────────────────────────────────────────┘
```

---

## 测试结果汇总模板

### 总体对比

| 维度 | 场景数 | 小搭子胜 | clawdbot胜 | 对等 |
|------|-------|---------|-----------|------|
| A. 效果 | 3 | | | |
| B. 特色 | 10 | | | |
| C. Token | 3 | | | |
| D. 场景 | 6 | | | |
| E. 电脑操作 | 4 | | | |

### Token 消耗实测

| 用例 | clawdbot 实测 | 小搭子 实测 | 节省比例 |
|------|-------------|----------|---------|
| C1 简单问答 | | | |
| C2 10轮对话 | | | |
| C3 复杂工具调用 | | | |
| A1 Excel 分析 | | | |

### 月度成本估算

| 使用频率 | clawdbot 月费 | 小搭子 月费 | 节省 |
|---------|-------------|----------|------|
| 轻度（10次/天） | | | |
| 中度（50次/天） | | | |
| 重度（100次/天） | | | |

---

## 差异化定位总结

```
┌─────────────────────────────────────────────────────────────────┐
│                     AI Agent 市场定位                             │
│                                                                  │
│  clawdbot / OpenClaw                                            │
│  ├─ 定位：24/7 后台 AI 管家                                      │
│  ├─ 优势：消息通道丰富 / 后台自动化 / 生态成熟                     │
│  ├─ 劣势：配置复杂 / Token 消耗大 / 面向技术用户 / 云端依赖        │
│  └─ 用户：开发者 / 技术爱好者                                     │
│                                                                  │
│  小搭子                                                          │
│  ├─ 定位：桌面 AI 搭子（面对面交互）                               │
│  ├─ 优势：                                                       │
│  │   ├─ 零门槛安装 / 智能回溯 / 三层记忆 / Token 节省              │
│  │   ├─ 🔥 文件修改回滚（事务语义 + 崩溃恢复 + 用户可反悔）       │
│  │   ├─ 🆕 本地知识语义搜索（离线/隐私/零成本/30ms）              │
│  │   └─ 🆕 长程桌面操作可靠性（断点续做 + 防重复 + 回滚安全网）   │
│  ├─ 劣势：无消息通道 / 无 24/7 后台 / 生态早期                     │
│  └─ 用户：内容创作者 / 职场人 / 研究者 / 小白用户                   │
│                                                                  │
│  核心差异：不是"谁更强"，是"服务谁"                                │
│  clawdbot = 给技术用户的后台管家（云端驱动）                        │
│  小搭子 = 给所有人的桌面搭子（本地优先，你的数据只在你的电脑上）      │
└─────────────────────────────────────────────────────────────────┘
```
